{"Event":"SparkListenerLogStart","Spark Version":"2.4.4"}
{"Event":"SparkListenerExecutorAdded","Timestamp":1629344507471,"Executor ID":"driver","Executor Info":{"Host":"localhost","Total Cores":1,"Log Urls":{}}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"driver","Host":"172.30.1.16","Port":65258},"Maximum Memory":2101975449,"Timestamp":1629344507520,"Maximum Onheap Memory":2101975449,"Maximum Offheap Memory":0}
{"Event":"SparkListenerEnvironmentUpdate","JVM Information":{"Java Home":"/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre","Java Version":"1.8.0_121 (Oracle Corporation)","Scala Version":"version 2.11.12"},"Spark Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.scheduler.mode":"FIFO","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"},"System Properties":{"java.io.tmpdir":"/var/folders/sn/9w29mxrs4ns43lqdh678wsgw0000gp/T/","line.separator":"\n","path.separator":":","sun.management.compiler":"HotSpot 64-Bit Tiered Compilers","sun.cpu.endian":"little","java.specification.version":"1.8","java.vm.specification.name":"Java Virtual Machine Specification","java.vendor":"Oracle Corporation","java.vm.specification.version":"1.8","user.home":"/Users/jinju","file.encoding.pkg":"sun.io","sun.nio.ch.bugLevel":"","ftp.nonProxyHosts":"local|*.local|169.254/16|*.169.254/16|lx.astxsvc.com|*.lx.astxsvc.com|localhost|*.localhost","sun.arch.data.model":"64","sun.boot.library.path":"/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib","user.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc","java.library.path":"/Users/jinju/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.","sun.cpu.isalist":"","os.arch":"x86_64","java.vm.version":"25.121-b13","jetty.git.hash":"unknown","java.endorsed.dirs":"/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/endorsed","java.runtime.version":"1.8.0_121-b13","java.vm.info":"mixed mode","java.ext.dirs":"/Users/jinju/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java","java.runtime.name":"Java(TM) SE Runtime Environment","file.separator":"/","java.class.version":"52.0","java.specification.name":"Java Platform API Specification","sun.boot.class.path":"/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/classes","file.encoding":"UTF-8","user.timezone":"Asia/Seoul","java.specification.vendor":"Oracle Corporation","sun.java.launcher":"SUN_STANDARD","os.version":"10.15.7","sun.os.patch.level":"unknown","gopherProxySet":"false","user.language.format":"ko-Kore","java.vm.specification.vendor":"Oracle Corporation","user.country":"KR","sun.jnu.encoding":"UTF-8","http.nonProxyHosts":"local|*.local|169.254/16|*.169.254/16|lx.astxsvc.com|*.lx.astxsvc.com|localhost|*.localhost","user.language":"ko","socksNonProxyHosts":"local|*.local|169.254/16|*.169.254/16|lx.astxsvc.com|*.lx.astxsvc.com|localhost|*.localhost","java.vendor.url":"http://java.oracle.com/","java.awt.printerjob":"sun.lwawt.macosx.CPrinterJob","java.awt.graphicsenv":"sun.awt.CGraphicsEnvironment","awt.toolkit":"sun.lwawt.macosx.LWCToolkit","os.name":"Mac OS X","java.vm.vendor":"Oracle Corporation","java.vendor.url.bug":"http://bugreport.sun.com/bugreport/","user.name":"jinju","java.vm.name":"Java HotSpot(TM) 64-Bit Server VM","sun.java.command":"AnalyzeDCApp","java.home":"/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre","java.version":"1.8.0_121","sun.io.unicode.encoding":"UnicodeBig"},"Classpath Entries":{"/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-compress/1.8.1/commons-compress-1.8.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-sketch_2.11/2.4.4/spark-sketch_2.11-2.4.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/ext/sunec.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-api/2.6.5/hadoop-yarn-api-2.6.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-graphx_2.11/2.4.4/spark-graphx_2.11-2.4.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-launcher_2.11/2.4.4/spark-launcher_2.11-2.4.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/jitpack.io/com/github/shin285/KOMORAN/3.3.4/KOMORAN-3.3.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-auth/2.6.5/hadoop-auth-2.6.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/3.1.5/metrics-core-3.1.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-mllib_2.11/2.4.4/spark-mllib_2.11-2.4.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/htrace/htrace-core/3.0.4/htrace-core-3.0.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-json/3.1.5/metrics-json-3.1.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-memory/0.10.0/arrow-memory-0.10.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/2.6.5/hadoop-annotations-2.6.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-scalap_2.11/3.5.3/json4s-scalap_2.11-3.5.3.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-common/1.10.1/parquet-common-1.10.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-client/2.6.5/hadoop-yarn-client-2.6.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.16/slf4j-log4j12-1.7.16.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/lib/tools.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/jce.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-mllib-local_2.11/2.4.4/spark-mllib-local_2.11-2.4.4.jar":"System Classpath","/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-digester/commons-digester/1.8/commons-digester-1.8.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet/2.22.2/jersey-container-servlet-2.22.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-jvm/3.1.5/metrics-jvm-3.1.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro/1.8.2/avro-1.8.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/esotericsoftware/kryo-shaded/4.0.2/kryo-shaded-4.0.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/external/javax.inject/2.4.0-b34/javax.inject-2.4.0-b34.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-catalyst_2.11/2.4.4/spark-catalyst_2.11-2.4.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-column/1.10.1/parquet-column-1.10.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/jitpack.io/com/github/shineware/commons/1.0.1/commons-1.0.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/inject/guice/3.0/guice-3.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/ext/dnsns.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-format/2.4.0/parquet-format-2.4.0.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/javaws.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/media/jersey-media-jaxb/2.22.2/jersey-media-jaxb-2.22.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/tukaani/xz/1.5/xz-1.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/typelevel/macro-compat_2.11/1.1.1/macro-compat_2.11-1.1.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.11/1.0.6/scala-xml_2.11-1.0.6.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/vlkan/flatbuffers/1.2.0-3f79e055/flatbuffers-1.2.0-3f79e055.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-paranamer/2.7.9/jackson-module-paranamer-2.7.9.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/airlift/aircompressor/0.10/aircompressor-0.10.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/jsse.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-streaming_2.11/2.4.4/spark-streaming_2.11-2.4.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-core/2.6.5/hadoop-mapreduce-client-core-2.6.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/deploy.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-annotations/2.6.7/jackson-annotations-2.6.7.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-core_2.11/3.5.3/json4s-core_2.11-3.5.3.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-net/commons-net/3.1/commons-net-3.1.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/lib/sa-jdi.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/rt.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/xmlenc/xmlenc/0.52/xmlenc-0.52.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-hadoop/1.10.1/parquet-hadoop-1.10.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.5/commons-lang3-3.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/ext/localedata.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-all/4.1.17.Final/netty-all-4.1.17.Final.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-codec/commons-codec/1.10/commons-codec-1.10.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/janino/janino/3.0.9/janino-3.0.9.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/ext/nashorn.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/lib/jconsole.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-vector/0.10.0/arrow-vector-0.10.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-format/0.10.0/arrow-format-0.10.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-scala_2.11/2.6.7.1/jackson-module-scala_2.11-2.6.7.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.6.5/hadoop-common-2.6.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/external/aopalliance-repackaged/2.4.0-b34/aopalliance-repackaged-2.4.0-b34.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-sql_2.11/2.4.4/spark-sql_2.11-2.4.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/ext/zipfs.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-ast_2.11/3.5.3/json4s-ast_2.11-3.5.3.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-encoding/1.10.1/parquet-encoding-1.10.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/objenesis/objenesis/2.5.1/objenesis-2.5.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/spire-math/spire-macros_2.11/0.13.0/spire-macros_2.11-0.13.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.6.5/hadoop-yarn-server-nodemanager-2.6.5.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/ext/cldrdata.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/lib/packager.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/github/rwl/jtransforms/2.4.0/jtransforms-2.4.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/github/luben/zstd-jni/1.3.2-2/zstd-jni-1.3.2-2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-kvstore_2.11/2.4.4/spark-kvstore_2.11-2.4.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.6.5/hadoop-mapreduce-client-app-2.6.5.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/resources.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-common/2.6.5/hadoop-yarn-server-common-2.6.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-common/2.6.5/hadoop-yarn-common-2.6.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-api/2.4.0-b34/hk2-api-2.4.0-b34.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-mapreduce/1.5.5/orc-mapreduce-1.5.5-nohive.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/bundles/repackaged/jersey-guava/2.22.2/jersey-guava-2.22.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/univocity/univocity-parsers/2.7.3/univocity-parsers-2.7.3.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/activation/activation/1.1.1/activation-1.1.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-common/2.6.5/hadoop-mapreduce-client-common-2.6.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/net/sourceforge/f2j/arpack_combined_all/0.1/arpack_combined_all-0.1.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/jfxswt.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-lang/commons-lang/2.6/commons-lang-2.6.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.6.5/hadoop-mapreduce-client-shuffle-2.6.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/github/fommil/netlib/core/1.1.2/core-1.1.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/janino/commons-compiler/3.0.9/commons-compiler-3.0.9.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-client/2.6.0/curator-client-2.6.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jline/jline/0.9.94/jline-0.9.94.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.7/antlr4-runtime-4.7.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/jfr.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-jackson/1.10.1/parquet-jackson-1.10.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.7.3/snappy-java-1.1.7.3.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-databind/2.6.7.1/jackson-databind-2.6.7.1.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/lib/dt.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-network-common_2.11/2.4.4/spark-network-common_2.11-2.4.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-framework/2.6.0/curator-framework-2.6.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/jitpack.io/com/github/shineware/aho-corasick/1.0.9/aho-corasick-1.0.9.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/ext/jfxrt.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.7.9/jackson-core-2.7.9.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/inject/javax.inject/1/javax.inject-1.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/plugin.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/ext/jaccess.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/twitter/chill_2.11/0.9.3/chill_2.11-0.9.3.jar":"System Classpath","/Users/jinju/Documents/study/ss-spark/project/analyze_dc/target/scala-2.11/classes":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-network-shuffle_2.11/2.4.4/spark-network-shuffle_2.11-2.4.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/spire-math/spire_2.11/0.13.0/spire_2.11-0.13.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-parser-combinators_2.11/1.1.0/scala-parser-combinators_2.11-1.1.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-jackson_2.11/3.5.3/json4s-jackson_2.11-3.5.3.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalanlp/breeze-macros_2.11/0.13.2/breeze-macros_2.11-0.13.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.6.1/machinist_2.11-0.6.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.6.5/hadoop-mapreduce-client-jobclient-2.6.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/guava/guava/16.0.1/guava-16.0.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-io/commons-io/2.4/commons-io-2.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.6.5/hadoop-hdfs-2.6.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/chuusai/shapeless_2.11/2.3.2/shapeless_2.11-2.3.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-utils/2.4.0-b34/hk2-utils-2.4.0-b34.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.11/2.4.4/spark-unsafe_2.11-2.4.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-tags_2.11/2.4.4/spark-tags_2.11-2.4.4.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/lib/ant-javafx.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/management-agent.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty/3.9.9.Final/netty-3.9.9.Final.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/lib/javafx-mx.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-client/2.6.5/hadoop-client-2.6.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-core_2.11/2.4.4/spark-core_2.11-2.4.4.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-locator/2.4.0-b34/hk2-locator-2.4.0-b34.jar":"System Classpath","/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/jre/lib/charsets.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-core/1.5.5/orc-core-1.5.5-nohive.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalanlp/breeze_2.11/0.13.2/breeze_2.11-0.13.2.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-shims/1.5.5/orc-shims-1.5.5.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar":"System Classpath","/Users/jinju/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/roaringbitmap/shims/0.7.45/shims-0.7.45.jar":"System Classpath"}}
{"Event":"SparkListenerApplicationStart","App Name":"AnalyzeDC","App ID":"local-1629344507389","Timestamp":1629344505892,"User":"jinju"}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":0,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#9, None)) > 0)\n      +- Project [value#9]\n         +- Relation[value#9] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#9, None)) > 0)\n      +- Project [value#9]\n         +- Relation[value#9] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#9, None)) > 0)\n      +- Relation[value#9] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#9, None)) > 0)\n   +- *(1) FileScan text [value#9] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/programming...., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#9, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#9] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/programming...., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/programming.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2,"metricType":"sum"},{"name":"number of files","accumulatorId":3,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":0,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344509406}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":0,"accumUpdates":[[3,1],[4,1]]}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1629344510360,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":2,"Name":"FileScanRDD","Scope":"{\"id\":\"1\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[0],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"0","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":2,"Name":"FileScanRDD","Scope":"{\"id\":\"1\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344510379,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"0","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1629344510447,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1629344510447,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344510586,"Failed":false,"Killed":false,"Accumulables":[{"ID":1,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":28,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":27,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":10,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":9,"Name":"internal.metrics.executorCpuTime","Update":80392000,"Value":80392000,"Internal":true,"Count Failed Values":true},{"ID":8,"Name":"internal.metrics.executorRunTime","Update":85,"Value":85,"Internal":true,"Count Failed Values":true},{"ID":7,"Name":"internal.metrics.executorDeserializeCpuTime","Update":18327000,"Value":18327000,"Internal":true,"Count Failed Values":true},{"ID":6,"Name":"internal.metrics.executorDeserializeTime","Update":19,"Value":19,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":19,"Executor Deserialize CPU Time":18327000,"Executor Run Time":85,"Executor CPU Time":80392000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"5\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":2,"Name":"FileScanRDD","Scope":"{\"id\":\"1\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344510379,"Completion Time":1629344510595,"Accumulables":[{"ID":8,"Name":"internal.metrics.executorRunTime","Value":85,"Internal":true,"Count Failed Values":true},{"ID":2,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":7,"Name":"internal.metrics.executorDeserializeCpuTime","Value":18327000,"Internal":true,"Count Failed Values":true},{"ID":1,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":28,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":10,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":27,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":9,"Name":"internal.metrics.executorCpuTime","Value":80392000,"Internal":true,"Count Failed Values":true},{"ID":6,"Name":"internal.metrics.executorDeserializeTime","Value":19,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1629344510600,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":0,"time":1629344510607}
{"Event":"SparkListenerJobStart","Job ID":1,"Submission Time":1629344510765,"Stage Infos":[{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"14\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"13\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"FileScanRDD","Scope":"{\"id\":\"11\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"10\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"11\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[1],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"15\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"14\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"13\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"FileScanRDD","Scope":"{\"id\":\"11\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"10\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"11\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344510766,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"15\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Launch Time":1629344510776,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Launch Time":1629344510776,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344510959,"Failed":false,"Killed":false,"Accumulables":[{"ID":31,"Name":"number of output rows","Update":"3229","Value":"3229","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":35,"Name":"duration total (min, med, max)","Update":"161","Value":"160","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":58,"Name":"internal.metrics.input.recordsRead","Update":3229,"Value":3229,"Internal":true,"Count Failed Values":true},{"ID":57,"Name":"internal.metrics.input.bytesRead","Update":232573,"Value":232573,"Internal":true,"Count Failed Values":true},{"ID":42,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":40,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":39,"Name":"internal.metrics.executorCpuTime","Update":162003000,"Value":162003000,"Internal":true,"Count Failed Values":true},{"ID":38,"Name":"internal.metrics.executorRunTime","Update":164,"Value":164,"Internal":true,"Count Failed Values":true},{"ID":37,"Name":"internal.metrics.executorDeserializeCpuTime","Update":5412000,"Value":5412000,"Internal":true,"Count Failed Values":true},{"ID":36,"Name":"internal.metrics.executorDeserializeTime","Update":6,"Value":6,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":6,"Executor Deserialize CPU Time":5412000,"Executor Run Time":164,"Executor CPU Time":162003000,"Result Size":1571,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":232573,"Records Read":3229},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"14\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"13\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"FileScanRDD","Scope":"{\"id\":\"11\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"10\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"11\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344510766,"Completion Time":1629344510960,"Accumulables":[{"ID":35,"Name":"duration total (min, med, max)","Value":"160","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":38,"Name":"internal.metrics.executorRunTime","Value":164,"Internal":true,"Count Failed Values":true},{"ID":31,"Name":"number of output rows","Value":"3229","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":58,"Name":"internal.metrics.input.recordsRead","Value":3229,"Internal":true,"Count Failed Values":true},{"ID":40,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true},{"ID":37,"Name":"internal.metrics.executorDeserializeCpuTime","Value":5412000,"Internal":true,"Count Failed Values":true},{"ID":36,"Name":"internal.metrics.executorDeserializeTime","Value":6,"Internal":true,"Count Failed Values":true},{"ID":57,"Name":"internal.metrics.input.bytesRead","Value":232573,"Internal":true,"Count Failed Values":true},{"ID":39,"Name":"internal.metrics.executorCpuTime","Value":162003000,"Internal":true,"Count Failed Values":true},{"ID":42,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":1,"Completion Time":1629344510960,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":1,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#46, None)) > 0)\n      +- Project [value#46]\n         +- Relation[value#46] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#46, None)) > 0)\n      +- Project [value#46]\n         +- Relation[value#46] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#46, None)) > 0)\n      +- Relation[value#46] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#46, None)) > 0)\n   +- *(1) FileScan text [value#46] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ironmen.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#46, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#46] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ironmen.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ironmen.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":63,"metricType":"sum"},{"name":"number of files","accumulatorId":64,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":65,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":66,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":62,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":61,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344511250}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":1,"accumUpdates":[[64,1],[65,0]]}
{"Event":"SparkListenerJobStart","Job ID":2,"Submission Time":1629344511300,"Stage Infos":[{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"25\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"FileScanRDD","Scope":"{\"id\":\"21\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"24\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[2],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"1","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"25\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"FileScanRDD","Scope":"{\"id\":\"21\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"24\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344511301,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"1","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Launch Time":1629344511313,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":2,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Launch Time":1629344511313,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344511332,"Failed":false,"Killed":false,"Accumulables":[{"ID":62,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":63,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":89,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":88,"Name":"internal.metrics.input.bytesRead","Update":1676,"Value":1676,"Internal":true,"Count Failed Values":true},{"ID":71,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":70,"Name":"internal.metrics.executorCpuTime","Update":4326000,"Value":4326000,"Internal":true,"Count Failed Values":true},{"ID":69,"Name":"internal.metrics.executorRunTime","Update":7,"Value":7,"Internal":true,"Count Failed Values":true},{"ID":68,"Name":"internal.metrics.executorDeserializeCpuTime","Update":3928000,"Value":3928000,"Internal":true,"Count Failed Values":true},{"ID":67,"Name":"internal.metrics.executorDeserializeTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":3,"Executor Deserialize CPU Time":3928000,"Executor Run Time":7,"Executor CPU Time":4326000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1676,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"25\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"FileScanRDD","Scope":"{\"id\":\"21\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"24\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344511301,"Completion Time":1629344511333,"Accumulables":[{"ID":68,"Name":"internal.metrics.executorDeserializeCpuTime","Value":3928000,"Internal":true,"Count Failed Values":true},{"ID":62,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":89,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":71,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":67,"Name":"internal.metrics.executorDeserializeTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":88,"Name":"internal.metrics.input.bytesRead","Value":1676,"Internal":true,"Count Failed Values":true},{"ID":70,"Name":"internal.metrics.executorCpuTime","Value":4326000,"Internal":true,"Count Failed Values":true},{"ID":69,"Name":"internal.metrics.executorRunTime","Value":7,"Internal":true,"Count Failed Values":true},{"ID":63,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":2,"Completion Time":1629344511333,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":1,"time":1629344511334}
{"Event":"SparkListenerJobStart","Job ID":3,"Submission Time":1629344511400,"Stage Infos":[{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"34\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"33\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[17],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"30\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"31\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"FileScanRDD","Scope":"{\"id\":\"31\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[3],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"35\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"34\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"33\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[17],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"30\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"31\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"FileScanRDD","Scope":"{\"id\":\"31\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344511402,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"35\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Launch Time":1629344511420,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Launch Time":1629344511420,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344511449,"Failed":false,"Killed":false,"Accumulables":[{"ID":92,"Name":"number of output rows","Update":"28","Value":"28","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":96,"Name":"duration total (min, med, max)","Update":"6","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":119,"Name":"internal.metrics.input.recordsRead","Update":28,"Value":28,"Internal":true,"Count Failed Values":true},{"ID":118,"Name":"internal.metrics.input.bytesRead","Update":1676,"Value":1676,"Internal":true,"Count Failed Values":true},{"ID":101,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":100,"Name":"internal.metrics.executorCpuTime","Update":8963000,"Value":8963000,"Internal":true,"Count Failed Values":true},{"ID":99,"Name":"internal.metrics.executorRunTime","Update":10,"Value":10,"Internal":true,"Count Failed Values":true},{"ID":98,"Name":"internal.metrics.executorDeserializeCpuTime","Update":4852000,"Value":4852000,"Internal":true,"Count Failed Values":true},{"ID":97,"Name":"internal.metrics.executorDeserializeTime","Update":7,"Value":7,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":7,"Executor Deserialize CPU Time":4852000,"Executor Run Time":10,"Executor CPU Time":8963000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1676,"Records Read":28},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"34\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"33\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[17],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"30\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"31\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"FileScanRDD","Scope":"{\"id\":\"31\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344511402,"Completion Time":1629344511450,"Accumulables":[{"ID":92,"Name":"number of output rows","Value":"28","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":119,"Name":"internal.metrics.input.recordsRead","Value":28,"Internal":true,"Count Failed Values":true},{"ID":101,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":98,"Name":"internal.metrics.executorDeserializeCpuTime","Value":4852000,"Internal":true,"Count Failed Values":true},{"ID":118,"Name":"internal.metrics.input.bytesRead","Value":1676,"Internal":true,"Count Failed Values":true},{"ID":100,"Name":"internal.metrics.executorCpuTime","Value":8963000,"Internal":true,"Count Failed Values":true},{"ID":97,"Name":"internal.metrics.executorDeserializeTime","Value":7,"Internal":true,"Count Failed Values":true},{"ID":96,"Name":"duration total (min, med, max)","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":99,"Name":"internal.metrics.executorRunTime","Value":10,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":3,"Completion Time":1629344511451,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":2,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#83, None)) > 0)\n      +- Project [value#83]\n         +- Relation[value#83] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#83, None)) > 0)\n      +- Project [value#83]\n         +- Relation[value#83] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#83, None)) > 0)\n      +- Relation[value#83] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#83, None)) > 0)\n   +- *(1) FileScan text [value#83] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/bitcoins.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#83, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#83] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/bitcoins.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/bitcoins.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":124,"metricType":"sum"},{"name":"number of files","accumulatorId":125,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":126,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":127,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":123,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":122,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344511531}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":2,"accumUpdates":[[125,1],[126,0]]}
{"Event":"SparkListenerJobStart","Job ID":4,"Submission Time":1629344511593,"Stage Infos":[{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"45\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":20,"Name":"FileScanRDD","Scope":"{\"id\":\"41\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"44\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"41\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[20],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[4],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"2","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"45\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":20,"Name":"FileScanRDD","Scope":"{\"id\":\"41\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"44\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"41\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[20],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344511594,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"2","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":4,"Stage Attempt ID":0,"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Launch Time":1629344511604,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":4,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Launch Time":1629344511604,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344511618,"Failed":false,"Killed":false,"Accumulables":[{"ID":123,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":124,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":150,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":149,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":132,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":131,"Name":"internal.metrics.executorCpuTime","Update":4278000,"Value":4278000,"Internal":true,"Count Failed Values":true},{"ID":130,"Name":"internal.metrics.executorRunTime","Update":7,"Value":7,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1868000,"Value":1868000,"Internal":true,"Count Failed Values":true},{"ID":128,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1868000,"Executor Run Time":7,"Executor CPU Time":4278000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"45\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":20,"Name":"FileScanRDD","Scope":"{\"id\":\"41\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"44\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"41\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[20],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344511594,"Completion Time":1629344511620,"Accumulables":[{"ID":128,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":149,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":131,"Name":"internal.metrics.executorCpuTime","Value":4278000,"Internal":true,"Count Failed Values":true},{"ID":124,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":130,"Name":"internal.metrics.executorRunTime","Value":7,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1868000,"Internal":true,"Count Failed Values":true},{"ID":123,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":150,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":132,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":4,"Completion Time":1629344511620,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":2,"time":1629344511622}
{"Event":"SparkListenerJobStart","Job ID":5,"Submission Time":1629344511684,"Stage Infos":[{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"54\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"51\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"50\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"FileScanRDD","Scope":"{\"id\":\"51\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"53\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[26],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[5],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"55\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"54\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"51\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"50\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"FileScanRDD","Scope":"{\"id\":\"51\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"53\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[26],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344511685,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"55\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":5,"Stage Attempt ID":0,"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Launch Time":1629344511694,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":5,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Launch Time":1629344511694,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344512286,"Failed":false,"Killed":false,"Accumulables":[{"ID":153,"Name":"number of output rows","Update":"49697","Value":"49697","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":157,"Name":"duration total (min, med, max)","Update":"583","Value":"582","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":180,"Name":"internal.metrics.input.recordsRead","Update":49697,"Value":49697,"Internal":true,"Count Failed Values":true},{"ID":179,"Name":"internal.metrics.input.bytesRead","Update":3663691,"Value":3663691,"Internal":true,"Count Failed Values":true},{"ID":162,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":161,"Name":"internal.metrics.executorCpuTime","Update":580952000,"Value":580952000,"Internal":true,"Count Failed Values":true},{"ID":160,"Name":"internal.metrics.executorRunTime","Update":585,"Value":585,"Internal":true,"Count Failed Values":true},{"ID":159,"Name":"internal.metrics.executorDeserializeCpuTime","Update":3183000,"Value":3183000,"Internal":true,"Count Failed Values":true},{"ID":158,"Name":"internal.metrics.executorDeserializeTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":4,"Executor Deserialize CPU Time":3183000,"Executor Run Time":585,"Executor CPU Time":580952000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":3663691,"Records Read":49697},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"54\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"51\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"50\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"FileScanRDD","Scope":"{\"id\":\"51\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"53\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[26],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344511685,"Completion Time":1629344512287,"Accumulables":[{"ID":158,"Name":"internal.metrics.executorDeserializeTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":160,"Name":"internal.metrics.executorRunTime","Value":585,"Internal":true,"Count Failed Values":true},{"ID":157,"Name":"duration total (min, med, max)","Value":"582","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":180,"Name":"internal.metrics.input.recordsRead","Value":49697,"Internal":true,"Count Failed Values":true},{"ID":159,"Name":"internal.metrics.executorDeserializeCpuTime","Value":3183000,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"number of output rows","Value":"49697","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":162,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":179,"Name":"internal.metrics.input.bytesRead","Value":3663691,"Internal":true,"Count Failed Values":true},{"ID":161,"Name":"internal.metrics.executorCpuTime","Value":580952000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":5,"Completion Time":1629344512287,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":3,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#120, None)) > 0)\n      +- Project [value#120]\n         +- Relation[value#120] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#120, None)) > 0)\n      +- Project [value#120]\n         +- Relation[value#120] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#120, None)) > 0)\n      +- Relation[value#120] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#120, None)) > 0)\n   +- *(1) FileScan text [value#120] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/monsterhunte..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#120, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#120] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/monsterhunte..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/monsterhunter.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":185,"metricType":"sum"},{"name":"number of files","accumulatorId":186,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":187,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":188,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":184,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":183,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344512347}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":3,"accumUpdates":[[186,1],[187,0]]}
{"Event":"SparkListenerJobStart","Job ID":6,"Submission Time":1629344512388,"Stage Infos":[{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"65\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"FileScanRDD","Scope":"{\"id\":\"61\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"64\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":30,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"61\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[29],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[6],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"3","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"65\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"FileScanRDD","Scope":"{\"id\":\"61\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"64\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":30,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"61\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[29],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344512389,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"3","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":6,"Stage Attempt ID":0,"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Launch Time":1629344512396,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":6,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Launch Time":1629344512396,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344512406,"Failed":false,"Killed":false,"Accumulables":[{"ID":184,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":185,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":211,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":210,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":195,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":193,"Name":"internal.metrics.resultSize","Update":1324,"Value":1324,"Internal":true,"Count Failed Values":true},{"ID":192,"Name":"internal.metrics.executorCpuTime","Update":3254000,"Value":3254000,"Internal":true,"Count Failed Values":true},{"ID":191,"Name":"internal.metrics.executorRunTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true},{"ID":190,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1315000,"Value":1315000,"Internal":true,"Count Failed Values":true},{"ID":189,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1315000,"Executor Run Time":5,"Executor CPU Time":3254000,"Result Size":1324,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"65\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"FileScanRDD","Scope":"{\"id\":\"61\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"64\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":30,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"61\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[29],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344512389,"Completion Time":1629344512406,"Accumulables":[{"ID":191,"Name":"internal.metrics.executorRunTime","Value":5,"Internal":true,"Count Failed Values":true},{"ID":185,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":184,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":211,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":193,"Name":"internal.metrics.resultSize","Value":1324,"Internal":true,"Count Failed Values":true},{"ID":190,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1315000,"Internal":true,"Count Failed Values":true},{"ID":189,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":210,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":192,"Name":"internal.metrics.executorCpuTime","Value":3254000,"Internal":true,"Count Failed Values":true},{"ID":195,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":6,"Completion Time":1629344512406,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":3,"time":1629344512407}
{"Event":"SparkListenerJobStart","Job ID":7,"Submission Time":1629344512462,"Stage Infos":[{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"74\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"70\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"73\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[35],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"71\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"FileScanRDD","Scope":"{\"id\":\"71\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[7],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"75\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"74\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"70\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"73\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[35],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"71\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"FileScanRDD","Scope":"{\"id\":\"71\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344512463,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"75\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":7,"Stage Attempt ID":0,"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Launch Time":1629344512473,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":7,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Launch Time":1629344512473,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344512527,"Failed":false,"Killed":false,"Accumulables":[{"ID":214,"Name":"number of output rows","Update":"4682","Value":"4682","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":218,"Name":"duration total (min, med, max)","Update":"45","Value":"44","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":241,"Name":"internal.metrics.input.recordsRead","Update":4682,"Value":4682,"Internal":true,"Count Failed Values":true},{"ID":240,"Name":"internal.metrics.input.bytesRead","Update":337885,"Value":337885,"Internal":true,"Count Failed Values":true},{"ID":225,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":223,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":222,"Name":"internal.metrics.executorCpuTime","Update":45431000,"Value":45431000,"Internal":true,"Count Failed Values":true},{"ID":221,"Name":"internal.metrics.executorRunTime","Update":47,"Value":47,"Internal":true,"Count Failed Values":true},{"ID":220,"Name":"internal.metrics.executorDeserializeCpuTime","Update":2095000,"Value":2095000,"Internal":true,"Count Failed Values":true},{"ID":219,"Name":"internal.metrics.executorDeserializeTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":3,"Executor Deserialize CPU Time":2095000,"Executor Run Time":47,"Executor CPU Time":45431000,"Result Size":1571,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":337885,"Records Read":4682},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"74\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"70\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"73\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[35],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"71\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"FileScanRDD","Scope":"{\"id\":\"71\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344512463,"Completion Time":1629344512527,"Accumulables":[{"ID":218,"Name":"duration total (min, med, max)","Value":"44","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":220,"Name":"internal.metrics.executorDeserializeCpuTime","Value":2095000,"Internal":true,"Count Failed Values":true},{"ID":214,"Name":"number of output rows","Value":"4682","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":241,"Name":"internal.metrics.input.recordsRead","Value":4682,"Internal":true,"Count Failed Values":true},{"ID":223,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true},{"ID":240,"Name":"internal.metrics.input.bytesRead","Value":337885,"Internal":true,"Count Failed Values":true},{"ID":225,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":219,"Name":"internal.metrics.executorDeserializeTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":222,"Name":"internal.metrics.executorCpuTime","Value":45431000,"Internal":true,"Count Failed Values":true},{"ID":221,"Name":"internal.metrics.executorRunTime","Value":47,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":7,"Completion Time":1629344512528,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":4,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#157, None)) > 0)\n      +- Project [value#157]\n         +- Relation[value#157] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#157, None)) > 0)\n      +- Project [value#157]\n         +- Relation[value#157] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#157, None)) > 0)\n      +- Relation[value#157] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#157, None)) > 0)\n   +- *(1) FileScan text [value#157] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/nba.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#157, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#157] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/nba.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/nba.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":246,"metricType":"sum"},{"name":"number of files","accumulatorId":247,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":248,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":249,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":245,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":244,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344512598}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":4,"accumUpdates":[[247,1],[248,0]]}
{"Event":"SparkListenerJobStart","Job ID":8,"Submission Time":1629344512644,"Stage Infos":[{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"85\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"FileScanRDD","Scope":"{\"id\":\"81\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"84\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"81\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[8],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"4","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"85\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"FileScanRDD","Scope":"{\"id\":\"81\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"84\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"81\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344512645,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"4","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":8,"Stage Attempt ID":0,"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Launch Time":1629344512657,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":8,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Launch Time":1629344512657,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344512668,"Failed":false,"Killed":false,"Accumulables":[{"ID":245,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":246,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":272,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":271,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":254,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":253,"Name":"internal.metrics.executorCpuTime","Update":4176000,"Value":4176000,"Internal":true,"Count Failed Values":true},{"ID":252,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":251,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1882000,"Value":1882000,"Internal":true,"Count Failed Values":true},{"ID":250,"Name":"internal.metrics.executorDeserializeTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":3,"Executor Deserialize CPU Time":1882000,"Executor Run Time":4,"Executor CPU Time":4176000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"85\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"FileScanRDD","Scope":"{\"id\":\"81\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"84\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"81\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344512645,"Completion Time":1629344512669,"Accumulables":[{"ID":245,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":254,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":271,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":253,"Name":"internal.metrics.executorCpuTime","Value":4176000,"Internal":true,"Count Failed Values":true},{"ID":250,"Name":"internal.metrics.executorDeserializeTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":252,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":246,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":272,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":251,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1882000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":8,"Completion Time":1629344512670,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":4,"time":1629344512670}
{"Event":"SparkListenerJobStart","Job ID":9,"Submission Time":1629344512742,"Stage Infos":[{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"94\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"91\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"FileScanRDD","Scope":"{\"id\":\"91\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"93\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"90\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[9],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"95\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"94\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"91\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"FileScanRDD","Scope":"{\"id\":\"91\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"93\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"90\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344512743,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"95\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":9,"Stage Attempt ID":0,"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Launch Time":1629344512756,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":9,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Launch Time":1629344512756,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344512855,"Failed":false,"Killed":false,"Accumulables":[{"ID":275,"Name":"number of output rows","Update":"3892","Value":"3892","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":279,"Name":"duration total (min, med, max)","Update":"86","Value":"85","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":302,"Name":"internal.metrics.input.recordsRead","Update":3892,"Value":3892,"Internal":true,"Count Failed Values":true},{"ID":301,"Name":"internal.metrics.input.bytesRead","Update":297083,"Value":297083,"Internal":true,"Count Failed Values":true},{"ID":285,"Name":"internal.metrics.jvmGCTime","Update":11,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":284,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":283,"Name":"internal.metrics.executorCpuTime","Update":70782000,"Value":70782000,"Internal":true,"Count Failed Values":true},{"ID":282,"Name":"internal.metrics.executorRunTime","Update":89,"Value":89,"Internal":true,"Count Failed Values":true},{"ID":281,"Name":"internal.metrics.executorDeserializeCpuTime","Update":3073000,"Value":3073000,"Internal":true,"Count Failed Values":true},{"ID":280,"Name":"internal.metrics.executorDeserializeTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":4,"Executor Deserialize CPU Time":3073000,"Executor Run Time":89,"Executor CPU Time":70782000,"Result Size":1571,"JVM GC Time":11,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":297083,"Records Read":3892},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"94\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"91\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"FileScanRDD","Scope":"{\"id\":\"91\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"93\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"90\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344512743,"Completion Time":1629344512857,"Accumulables":[{"ID":280,"Name":"internal.metrics.executorDeserializeTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":301,"Name":"internal.metrics.input.bytesRead","Value":297083,"Internal":true,"Count Failed Values":true},{"ID":283,"Name":"internal.metrics.executorCpuTime","Value":70782000,"Internal":true,"Count Failed Values":true},{"ID":285,"Name":"internal.metrics.jvmGCTime","Value":11,"Internal":true,"Count Failed Values":true},{"ID":279,"Name":"duration total (min, med, max)","Value":"85","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":282,"Name":"internal.metrics.executorRunTime","Value":89,"Internal":true,"Count Failed Values":true},{"ID":281,"Name":"internal.metrics.executorDeserializeCpuTime","Value":3073000,"Internal":true,"Count Failed Values":true},{"ID":275,"Name":"number of output rows","Value":"3892","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":302,"Name":"internal.metrics.input.recordsRead","Value":3892,"Internal":true,"Count Failed Values":true},{"ID":284,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":9,"Completion Time":1629344512857,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":5,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#194, None)) > 0)\n      +- Project [value#194]\n         +- Relation[value#194] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#194, None)) > 0)\n      +- Project [value#194]\n         +- Relation[value#194] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#194, None)) > 0)\n      +- Relation[value#194] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#194, None)) > 0)\n   +- *(1) FileScan text [value#194] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/cs_new1.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#194, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#194] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/cs_new1.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/cs_new1.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":307,"metricType":"sum"},{"name":"number of files","accumulatorId":308,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":309,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":310,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":306,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":305,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344512936}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":5,"accumUpdates":[[308,1],[309,0]]}
{"Event":"SparkListenerJobStart","Job ID":10,"Submission Time":1629344512979,"Stage Infos":[{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"105\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"FileScanRDD","Scope":"{\"id\":\"101\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"101\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"104\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[10],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"5","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"105\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"FileScanRDD","Scope":"{\"id\":\"101\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"101\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"104\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344512980,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"5","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":10,"Stage Attempt ID":0,"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Launch Time":1629344512988,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":10,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Launch Time":1629344512988,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344512996,"Failed":false,"Killed":false,"Accumulables":[{"ID":306,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":307,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":333,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":332,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":315,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":314,"Name":"internal.metrics.executorCpuTime","Update":2644000,"Value":2644000,"Internal":true,"Count Failed Values":true},{"ID":313,"Name":"internal.metrics.executorRunTime","Update":6,"Value":6,"Internal":true,"Count Failed Values":true},{"ID":312,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1160000,"Value":1160000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":1160000,"Executor Run Time":6,"Executor CPU Time":2644000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"105\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"FileScanRDD","Scope":"{\"id\":\"101\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"101\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"104\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344512980,"Completion Time":1629344512997,"Accumulables":[{"ID":313,"Name":"internal.metrics.executorRunTime","Value":6,"Internal":true,"Count Failed Values":true},{"ID":307,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":312,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1160000,"Internal":true,"Count Failed Values":true},{"ID":306,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":333,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":315,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":332,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":314,"Name":"internal.metrics.executorCpuTime","Value":2644000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":10,"Completion Time":1629344512998,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":5,"time":1629344512998}
{"Event":"SparkListenerJobStart","Job ID":11,"Submission Time":1629344513046,"Stage Infos":[{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"114\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"113\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"110\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":51,"Name":"FileScanRDD","Scope":"{\"id\":\"111\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"111\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[11],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"115\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"114\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"113\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"110\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":51,"Name":"FileScanRDD","Scope":"{\"id\":\"111\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"111\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513047,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"115\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":11,"Stage Attempt ID":0,"Task Info":{"Task ID":11,"Index":0,"Attempt":0,"Launch Time":1629344513056,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":11,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":11,"Index":0,"Attempt":0,"Launch Time":1629344513056,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344513154,"Failed":false,"Killed":false,"Accumulables":[{"ID":336,"Name":"number of output rows","Update":"11702","Value":"11702","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":340,"Name":"duration total (min, med, max)","Update":"89","Value":"88","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":363,"Name":"internal.metrics.input.recordsRead","Update":11702,"Value":11702,"Internal":true,"Count Failed Values":true},{"ID":362,"Name":"internal.metrics.input.bytesRead","Update":772564,"Value":772564,"Internal":true,"Count Failed Values":true},{"ID":345,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":344,"Name":"internal.metrics.executorCpuTime","Update":87718000,"Value":87718000,"Internal":true,"Count Failed Values":true},{"ID":343,"Name":"internal.metrics.executorRunTime","Update":92,"Value":92,"Internal":true,"Count Failed Values":true},{"ID":342,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1714000,"Value":1714000,"Internal":true,"Count Failed Values":true},{"ID":341,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1714000,"Executor Run Time":92,"Executor CPU Time":87718000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":772564,"Records Read":11702},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"114\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"113\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"110\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":51,"Name":"FileScanRDD","Scope":"{\"id\":\"111\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"111\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513047,"Completion Time":1629344513155,"Accumulables":[{"ID":340,"Name":"duration total (min, med, max)","Value":"88","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":343,"Name":"internal.metrics.executorRunTime","Value":92,"Internal":true,"Count Failed Values":true},{"ID":336,"Name":"number of output rows","Value":"11702","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":363,"Name":"internal.metrics.input.recordsRead","Value":11702,"Internal":true,"Count Failed Values":true},{"ID":345,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":342,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1714000,"Internal":true,"Count Failed Values":true},{"ID":341,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":362,"Name":"internal.metrics.input.bytesRead","Value":772564,"Internal":true,"Count Failed Values":true},{"ID":344,"Name":"internal.metrics.executorCpuTime","Value":87718000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":11,"Completion Time":1629344513155,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":6,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#231, None)) > 0)\n      +- Project [value#231]\n         +- Relation[value#231] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#231, None)) > 0)\n      +- Project [value#231]\n         +- Relation[value#231] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#231, None)) > 0)\n      +- Relation[value#231] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#231, None)) > 0)\n   +- *(1) FileScan text [value#231] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/samsunglions..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#231, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#231] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/samsunglions..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/samsunglions_new.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":368,"metricType":"sum"},{"name":"number of files","accumulatorId":369,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":370,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":371,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":367,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":366,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344513227}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":6,"accumUpdates":[[369,1],[370,0]]}
{"Event":"SparkListenerJobStart","Job ID":12,"Submission Time":1629344513267,"Stage Infos":[{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"125\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"FileScanRDD","Scope":"{\"id\":\"121\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"121\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"124\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[12],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"6","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"125\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"FileScanRDD","Scope":"{\"id\":\"121\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"121\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"124\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513269,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"6","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":12,"Stage Attempt ID":0,"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Launch Time":1629344513276,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":12,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Launch Time":1629344513276,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344513286,"Failed":false,"Killed":false,"Accumulables":[{"ID":367,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":368,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":394,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":393,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":378,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":376,"Name":"internal.metrics.resultSize","Update":1324,"Value":1324,"Internal":true,"Count Failed Values":true},{"ID":375,"Name":"internal.metrics.executorCpuTime","Update":4078000,"Value":4078000,"Internal":true,"Count Failed Values":true},{"ID":374,"Name":"internal.metrics.executorRunTime","Update":6,"Value":6,"Internal":true,"Count Failed Values":true},{"ID":373,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1766000,"Value":1766000,"Internal":true,"Count Failed Values":true},{"ID":372,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1766000,"Executor Run Time":6,"Executor CPU Time":4078000,"Result Size":1324,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"125\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"FileScanRDD","Scope":"{\"id\":\"121\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"121\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"124\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513269,"Completion Time":1629344513287,"Accumulables":[{"ID":373,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1766000,"Internal":true,"Count Failed Values":true},{"ID":367,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":394,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":376,"Name":"internal.metrics.resultSize","Value":1324,"Internal":true,"Count Failed Values":true},{"ID":378,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":372,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":393,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":375,"Name":"internal.metrics.executorCpuTime","Value":4078000,"Internal":true,"Count Failed Values":true},{"ID":368,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":374,"Name":"internal.metrics.executorRunTime","Value":6,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":12,"Completion Time":1629344513287,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":6,"time":1629344513288}
{"Event":"SparkListenerJobStart","Job ID":13,"Submission Time":1629344513335,"Stage Infos":[{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":64,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"134\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[63],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":63,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"133\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[62],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":60,"Name":"FileScanRDD","Scope":"{\"id\":\"131\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"131\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"130\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[13],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"135\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":64,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"134\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[63],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":63,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"133\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[62],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":60,"Name":"FileScanRDD","Scope":"{\"id\":\"131\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"131\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"130\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513336,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"135\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":13,"Stage Attempt ID":0,"Task Info":{"Task ID":13,"Index":0,"Attempt":0,"Launch Time":1629344513341,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":13,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":13,"Index":0,"Attempt":0,"Launch Time":1629344513341,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344513432,"Failed":false,"Killed":false,"Accumulables":[{"ID":397,"Name":"number of output rows","Update":"12125","Value":"12125","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":401,"Name":"duration total (min, med, max)","Update":"84","Value":"83","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":424,"Name":"internal.metrics.input.recordsRead","Update":12125,"Value":12125,"Internal":true,"Count Failed Values":true},{"ID":423,"Name":"internal.metrics.input.bytesRead","Update":848884,"Value":848884,"Internal":true,"Count Failed Values":true},{"ID":406,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":405,"Name":"internal.metrics.executorCpuTime","Update":84086000,"Value":84086000,"Internal":true,"Count Failed Values":true},{"ID":404,"Name":"internal.metrics.executorRunTime","Update":85,"Value":85,"Internal":true,"Count Failed Values":true},{"ID":403,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1767000,"Value":1767000,"Internal":true,"Count Failed Values":true},{"ID":402,"Name":"internal.metrics.executorDeserializeTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":3,"Executor Deserialize CPU Time":1767000,"Executor Run Time":85,"Executor CPU Time":84086000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":848884,"Records Read":12125},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":64,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"134\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[63],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":63,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"133\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[62],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":60,"Name":"FileScanRDD","Scope":"{\"id\":\"131\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"131\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"130\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513336,"Completion Time":1629344513432,"Accumulables":[{"ID":424,"Name":"internal.metrics.input.recordsRead","Value":12125,"Internal":true,"Count Failed Values":true},{"ID":406,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":403,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1767000,"Internal":true,"Count Failed Values":true},{"ID":397,"Name":"number of output rows","Value":"12125","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":423,"Name":"internal.metrics.input.bytesRead","Value":848884,"Internal":true,"Count Failed Values":true},{"ID":405,"Name":"internal.metrics.executorCpuTime","Value":84086000,"Internal":true,"Count Failed Values":true},{"ID":402,"Name":"internal.metrics.executorDeserializeTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":401,"Name":"duration total (min, med, max)","Value":"83","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":404,"Name":"internal.metrics.executorRunTime","Value":85,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":13,"Completion Time":1629344513432,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":7,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#268, None)) > 0)\n      +- Project [value#268]\n         +- Relation[value#268] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#268, None)) > 0)\n      +- Project [value#268]\n         +- Relation[value#268] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#268, None)) > 0)\n      +- Relation[value#268] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#268, None)) > 0)\n   +- *(1) FileScan text [value#268] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/government.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#268, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#268] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/government.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/government.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":429,"metricType":"sum"},{"name":"number of files","accumulatorId":430,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":431,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":432,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":428,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":427,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344513499}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":7,"accumUpdates":[[430,1],[431,0]]}
{"Event":"SparkListenerJobStart","Job ID":14,"Submission Time":1629344513533,"Stage Infos":[{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"145\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":66,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"141\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"FileScanRDD","Scope":"{\"id\":\"141\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"144\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[14],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"7","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"145\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":66,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"141\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"FileScanRDD","Scope":"{\"id\":\"141\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"144\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513534,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"7","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":14,"Stage Attempt ID":0,"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Launch Time":1629344513540,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":14,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Launch Time":1629344513540,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344513548,"Failed":false,"Killed":false,"Accumulables":[{"ID":428,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":429,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":455,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":454,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":437,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":436,"Name":"internal.metrics.executorCpuTime","Update":2448000,"Value":2448000,"Internal":true,"Count Failed Values":true},{"ID":435,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":434,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1209000,"Value":1209000,"Internal":true,"Count Failed Values":true},{"ID":433,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1209000,"Executor Run Time":4,"Executor CPU Time":2448000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"145\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":66,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"141\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"FileScanRDD","Scope":"{\"id\":\"141\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"144\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513534,"Completion Time":1629344513548,"Accumulables":[{"ID":433,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":454,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":436,"Name":"internal.metrics.executorCpuTime","Value":2448000,"Internal":true,"Count Failed Values":true},{"ID":429,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":435,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":428,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":455,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":437,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":434,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1209000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":14,"Completion Time":1629344513548,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":7,"time":1629344513549}
{"Event":"SparkListenerJobStart","Job ID":15,"Submission Time":1629344513595,"Stage Infos":[{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"154\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":70,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"151\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[69],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"153\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[71],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":71,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"150\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[70],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":69,"Name":"FileScanRDD","Scope":"{\"id\":\"151\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[15],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"155\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"154\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":70,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"151\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[69],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"153\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[71],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":71,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"150\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[70],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":69,"Name":"FileScanRDD","Scope":"{\"id\":\"151\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513596,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"155\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":15,"Stage Attempt ID":0,"Task Info":{"Task ID":15,"Index":0,"Attempt":0,"Launch Time":1629344513602,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":15,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":15,"Index":0,"Attempt":0,"Launch Time":1629344513602,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344513662,"Failed":false,"Killed":false,"Accumulables":[{"ID":458,"Name":"number of output rows","Update":"4675","Value":"4675","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":462,"Name":"duration total (min, med, max)","Update":"51","Value":"50","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":485,"Name":"internal.metrics.input.recordsRead","Update":4675,"Value":4675,"Internal":true,"Count Failed Values":true},{"ID":484,"Name":"internal.metrics.input.bytesRead","Update":352494,"Value":352494,"Internal":true,"Count Failed Values":true},{"ID":467,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":466,"Name":"internal.metrics.executorCpuTime","Update":51576000,"Value":51576000,"Internal":true,"Count Failed Values":true},{"ID":465,"Name":"internal.metrics.executorRunTime","Update":53,"Value":53,"Internal":true,"Count Failed Values":true},{"ID":464,"Name":"internal.metrics.executorDeserializeCpuTime","Update":3080000,"Value":3080000,"Internal":true,"Count Failed Values":true},{"ID":463,"Name":"internal.metrics.executorDeserializeTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":3,"Executor Deserialize CPU Time":3080000,"Executor Run Time":53,"Executor CPU Time":51576000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":352494,"Records Read":4675},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"154\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":70,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"151\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[69],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"153\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[71],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":71,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"150\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[70],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":69,"Name":"FileScanRDD","Scope":"{\"id\":\"151\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513596,"Completion Time":1629344513663,"Accumulables":[{"ID":463,"Name":"internal.metrics.executorDeserializeTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":465,"Name":"internal.metrics.executorRunTime","Value":53,"Internal":true,"Count Failed Values":true},{"ID":462,"Name":"duration total (min, med, max)","Value":"50","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":464,"Name":"internal.metrics.executorDeserializeCpuTime","Value":3080000,"Internal":true,"Count Failed Values":true},{"ID":458,"Name":"number of output rows","Value":"4675","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":485,"Name":"internal.metrics.input.recordsRead","Value":4675,"Internal":true,"Count Failed Values":true},{"ID":467,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":484,"Name":"internal.metrics.input.bytesRead","Value":352494,"Internal":true,"Count Failed Values":true},{"ID":466,"Name":"internal.metrics.executorCpuTime","Value":51576000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":15,"Completion Time":1629344513663,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":8,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#305, None)) > 0)\n      +- Project [value#305]\n         +- Relation[value#305] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#305, None)) > 0)\n      +- Project [value#305]\n         +- Relation[value#305] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#305, None)) > 0)\n      +- Relation[value#305] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#305, None)) > 0)\n   +- *(1) FileScan text [value#305] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/touhou.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#305, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#305] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/touhou.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/touhou.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":490,"metricType":"sum"},{"name":"number of files","accumulatorId":491,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":492,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":493,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":489,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":488,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344513724}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":8,"accumUpdates":[[491,1],[492,0]]}
{"Event":"SparkListenerJobStart","Job ID":16,"Submission Time":1629344513761,"Stage Infos":[{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"165\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"164\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[75],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":74,"Name":"FileScanRDD","Scope":"{\"id\":\"161\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":75,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"161\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[74],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[16],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"8","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"165\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"164\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[75],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":74,"Name":"FileScanRDD","Scope":"{\"id\":\"161\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":75,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"161\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[74],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513761,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"8","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":16,"Stage Attempt ID":0,"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Launch Time":1629344513765,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":16,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Launch Time":1629344513765,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344513773,"Failed":false,"Killed":false,"Accumulables":[{"ID":489,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":490,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":516,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":515,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":498,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":497,"Name":"internal.metrics.executorCpuTime","Update":2250000,"Value":2250000,"Internal":true,"Count Failed Values":true},{"ID":496,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":495,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1082000,"Value":1082000,"Internal":true,"Count Failed Values":true},{"ID":494,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1082000,"Executor Run Time":4,"Executor CPU Time":2250000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"165\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"164\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[75],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":74,"Name":"FileScanRDD","Scope":"{\"id\":\"161\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":75,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"161\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[74],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513761,"Completion Time":1629344513773,"Accumulables":[{"ID":496,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":490,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":489,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":516,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":498,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":495,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1082000,"Internal":true,"Count Failed Values":true},{"ID":515,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":497,"Name":"internal.metrics.executorCpuTime","Value":2250000,"Internal":true,"Count Failed Values":true},{"ID":494,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":16,"Completion Time":1629344513773,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":8,"time":1629344513774}
{"Event":"SparkListenerJobStart","Job ID":17,"Submission Time":1629344513813,"Stage Infos":[{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":82,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"174\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[81],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":81,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"173\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":79,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"171\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[78],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":78,"Name":"FileScanRDD","Scope":"{\"id\":\"171\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"170\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[79],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[17],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"175\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":82,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"174\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[81],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":81,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"173\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":79,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"171\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[78],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":78,"Name":"FileScanRDD","Scope":"{\"id\":\"171\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"170\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[79],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513814,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"175\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":17,"Stage Attempt ID":0,"Task Info":{"Task ID":17,"Index":0,"Attempt":0,"Launch Time":1629344513821,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":17,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":17,"Index":0,"Attempt":0,"Launch Time":1629344513821,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344513857,"Failed":false,"Killed":false,"Accumulables":[{"ID":519,"Name":"number of output rows","Update":"3531","Value":"3531","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":523,"Name":"duration total (min, med, max)","Update":"30","Value":"29","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":546,"Name":"internal.metrics.input.recordsRead","Update":3531,"Value":3531,"Internal":true,"Count Failed Values":true},{"ID":545,"Name":"internal.metrics.input.bytesRead","Update":222103,"Value":222103,"Internal":true,"Count Failed Values":true},{"ID":528,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":527,"Name":"internal.metrics.executorCpuTime","Update":29870000,"Value":29870000,"Internal":true,"Count Failed Values":true},{"ID":526,"Name":"internal.metrics.executorRunTime","Update":31,"Value":31,"Internal":true,"Count Failed Values":true},{"ID":525,"Name":"internal.metrics.executorDeserializeCpuTime","Update":2137000,"Value":2137000,"Internal":true,"Count Failed Values":true},{"ID":524,"Name":"internal.metrics.executorDeserializeTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":3,"Executor Deserialize CPU Time":2137000,"Executor Run Time":31,"Executor CPU Time":29870000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":222103,"Records Read":3531},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":82,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"174\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[81],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":81,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"173\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":79,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"171\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[78],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":78,"Name":"FileScanRDD","Scope":"{\"id\":\"171\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"170\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[79],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513814,"Completion Time":1629344513858,"Accumulables":[{"ID":523,"Name":"duration total (min, med, max)","Value":"29","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":525,"Name":"internal.metrics.executorDeserializeCpuTime","Value":2137000,"Internal":true,"Count Failed Values":true},{"ID":519,"Name":"number of output rows","Value":"3531","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":546,"Name":"internal.metrics.input.recordsRead","Value":3531,"Internal":true,"Count Failed Values":true},{"ID":528,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":524,"Name":"internal.metrics.executorDeserializeTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":545,"Name":"internal.metrics.input.bytesRead","Value":222103,"Internal":true,"Count Failed Values":true},{"ID":527,"Name":"internal.metrics.executorCpuTime","Value":29870000,"Internal":true,"Count Failed Values":true},{"ID":526,"Name":"internal.metrics.executorRunTime","Value":31,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":17,"Completion Time":1629344513858,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":9,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#342, None)) > 0)\n      +- Project [value#342]\n         +- Relation[value#342] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#342, None)) > 0)\n      +- Project [value#342]\n         +- Relation[value#342] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#342, None)) > 0)\n      +- Relation[value#342] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#342, None)) > 0)\n   +- *(1) FileScan text [value#342] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/bicycle.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#342, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#342] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/bicycle.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/bicycle.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":551,"metricType":"sum"},{"name":"number of files","accumulatorId":552,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":553,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":554,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":550,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":549,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344513917}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":9,"accumUpdates":[[552,1],[553,0]]}
{"Event":"SparkListenerJobStart","Job ID":18,"Submission Time":1629344513953,"Stage Infos":[{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":86,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"185\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[85],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"181\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"FileScanRDD","Scope":"{\"id\":\"181\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":85,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"184\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[18],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"9","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":86,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"185\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[85],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"181\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"FileScanRDD","Scope":"{\"id\":\"181\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":85,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"184\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513953,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"9","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":18,"Stage Attempt ID":0,"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Launch Time":1629344513960,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":18,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Launch Time":1629344513960,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344513969,"Failed":false,"Killed":false,"Accumulables":[{"ID":550,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":551,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":577,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":576,"Name":"internal.metrics.input.bytesRead","Update":31539,"Value":31539,"Internal":true,"Count Failed Values":true},{"ID":559,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":558,"Name":"internal.metrics.executorCpuTime","Update":2875000,"Value":2875000,"Internal":true,"Count Failed Values":true},{"ID":557,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":556,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1592000,"Value":1592000,"Internal":true,"Count Failed Values":true},{"ID":555,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1592000,"Executor Run Time":4,"Executor CPU Time":2875000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":31539,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":86,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"185\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[85],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"181\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"FileScanRDD","Scope":"{\"id\":\"181\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":85,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"184\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344513953,"Completion Time":1629344513970,"Accumulables":[{"ID":550,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":577,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":559,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":576,"Name":"internal.metrics.input.bytesRead","Value":31539,"Internal":true,"Count Failed Values":true},{"ID":558,"Name":"internal.metrics.executorCpuTime","Value":2875000,"Internal":true,"Count Failed Values":true},{"ID":555,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":557,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":551,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":556,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1592000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":18,"Completion Time":1629344513970,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":9,"time":1629344513970}
{"Event":"SparkListenerJobStart","Job ID":19,"Submission Time":1629344514012,"Stage Infos":[{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":91,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"194\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[90],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":88,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"191\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[87],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":87,"Name":"FileScanRDD","Scope":"{\"id\":\"191\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":90,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"193\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[89],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":89,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"190\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[88],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[19],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"195\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":91,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"194\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[90],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":88,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"191\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[87],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":87,"Name":"FileScanRDD","Scope":"{\"id\":\"191\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":90,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"193\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[89],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":89,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"190\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[88],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514013,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"195\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":19,"Stage Attempt ID":0,"Task Info":{"Task ID":19,"Index":0,"Attempt":0,"Launch Time":1629344514019,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":19,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":19,"Index":0,"Attempt":0,"Launch Time":1629344514019,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344514029,"Failed":false,"Killed":false,"Accumulables":[{"ID":580,"Name":"number of output rows","Update":"443","Value":"443","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":584,"Name":"duration total (min, med, max)","Update":"3","Value":"2","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":607,"Name":"internal.metrics.input.recordsRead","Update":443,"Value":443,"Internal":true,"Count Failed Values":true},{"ID":606,"Name":"internal.metrics.input.bytesRead","Update":31539,"Value":31539,"Internal":true,"Count Failed Values":true},{"ID":589,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":588,"Name":"internal.metrics.executorCpuTime","Update":5361000,"Value":5361000,"Internal":true,"Count Failed Values":true},{"ID":587,"Name":"internal.metrics.executorRunTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true},{"ID":586,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1453000,"Value":1453000,"Internal":true,"Count Failed Values":true},{"ID":585,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1453000,"Executor Run Time":5,"Executor CPU Time":5361000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":31539,"Records Read":443},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":91,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"194\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[90],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":88,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"191\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[87],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":87,"Name":"FileScanRDD","Scope":"{\"id\":\"191\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":90,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"193\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[89],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":89,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"190\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[88],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514013,"Completion Time":1629344514029,"Accumulables":[{"ID":585,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":606,"Name":"internal.metrics.input.bytesRead","Value":31539,"Internal":true,"Count Failed Values":true},{"ID":588,"Name":"internal.metrics.executorCpuTime","Value":5361000,"Internal":true,"Count Failed Values":true},{"ID":584,"Name":"duration total (min, med, max)","Value":"2","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":587,"Name":"internal.metrics.executorRunTime","Value":5,"Internal":true,"Count Failed Values":true},{"ID":586,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1453000,"Internal":true,"Count Failed Values":true},{"ID":580,"Name":"number of output rows","Value":"443","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":607,"Name":"internal.metrics.input.recordsRead","Value":443,"Internal":true,"Count Failed Values":true},{"ID":589,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":19,"Completion Time":1629344514029,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":10,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#379, None)) > 0)\n      +- Project [value#379]\n         +- Relation[value#379] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#379, None)) > 0)\n      +- Project [value#379]\n         +- Relation[value#379] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#379, None)) > 0)\n      +- Relation[value#379] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#379, None)) > 0)\n   +- *(1) FileScan text [value#379] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lgtwins_new...., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#379, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#379] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lgtwins_new...., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lgtwins_new.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":612,"metricType":"sum"},{"name":"number of files","accumulatorId":613,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":614,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":615,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":611,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":610,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344514080}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":10,"accumUpdates":[[613,1],[614,0]]}
{"Event":"SparkListenerJobStart","Job ID":20,"Submission Time":1629344514116,"Stage Infos":[{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":95,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"205\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[94],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":93,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"201\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[92],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":94,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"204\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[93],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":92,"Name":"FileScanRDD","Scope":"{\"id\":\"201\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[20],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"10","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":95,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"205\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[94],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":93,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"201\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[92],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":94,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"204\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[93],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":92,"Name":"FileScanRDD","Scope":"{\"id\":\"201\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514117,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"10","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":20,"Stage Attempt ID":0,"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Launch Time":1629344514123,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":20,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Launch Time":1629344514123,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344514130,"Failed":false,"Killed":false,"Accumulables":[{"ID":611,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":612,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":638,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":637,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":622,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":620,"Name":"internal.metrics.resultSize","Update":1324,"Value":1324,"Internal":true,"Count Failed Values":true},{"ID":619,"Name":"internal.metrics.executorCpuTime","Update":2473000,"Value":2473000,"Internal":true,"Count Failed Values":true},{"ID":618,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":617,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1132000,"Value":1132000,"Internal":true,"Count Failed Values":true},{"ID":616,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1132000,"Executor Run Time":4,"Executor CPU Time":2473000,"Result Size":1324,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":95,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"205\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[94],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":93,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"201\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[92],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":94,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"204\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[93],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":92,"Name":"FileScanRDD","Scope":"{\"id\":\"201\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514117,"Completion Time":1629344514131,"Accumulables":[{"ID":618,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":612,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":617,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1132000,"Internal":true,"Count Failed Values":true},{"ID":611,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":638,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":620,"Name":"internal.metrics.resultSize","Value":1324,"Internal":true,"Count Failed Values":true},{"ID":622,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":616,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":637,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":619,"Name":"internal.metrics.executorCpuTime","Value":2473000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":20,"Completion Time":1629344514131,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":10,"time":1629344514132}
{"Event":"SparkListenerJobStart","Job ID":21,"Submission Time":1629344514182,"Stage Infos":[{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":100,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"214\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[99],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":99,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"213\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[98],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":98,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"210\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[97],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":97,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"211\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[96],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":96,"Name":"FileScanRDD","Scope":"{\"id\":\"211\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[21],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"215\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":100,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"214\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[99],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":99,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"213\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[98],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":98,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"210\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[97],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":97,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"211\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[96],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":96,"Name":"FileScanRDD","Scope":"{\"id\":\"211\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514182,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"215\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":21,"Stage Attempt ID":0,"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Launch Time":1629344514205,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":21,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Launch Time":1629344514205,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344514394,"Failed":false,"Killed":false,"Accumulables":[{"ID":641,"Name":"number of output rows","Update":"16708","Value":"16708","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":645,"Name":"duration total (min, med, max)","Update":"181","Value":"180","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":668,"Name":"internal.metrics.input.recordsRead","Update":16708,"Value":16708,"Internal":true,"Count Failed Values":true},{"ID":667,"Name":"internal.metrics.input.bytesRead","Update":1233361,"Value":1233361,"Internal":true,"Count Failed Values":true},{"ID":650,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":649,"Name":"internal.metrics.executorCpuTime","Update":165490000,"Value":165490000,"Internal":true,"Count Failed Values":true},{"ID":648,"Name":"internal.metrics.executorRunTime","Update":183,"Value":183,"Internal":true,"Count Failed Values":true},{"ID":647,"Name":"internal.metrics.executorDeserializeCpuTime","Update":2264000,"Value":2264000,"Internal":true,"Count Failed Values":true},{"ID":646,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":2264000,"Executor Run Time":183,"Executor CPU Time":165490000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1233361,"Records Read":16708},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":100,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"214\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[99],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":99,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"213\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[98],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":98,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"210\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[97],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":97,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"211\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[96],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":96,"Name":"FileScanRDD","Scope":"{\"id\":\"211\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514182,"Completion Time":1629344514395,"Accumulables":[{"ID":645,"Name":"duration total (min, med, max)","Value":"180","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":648,"Name":"internal.metrics.executorRunTime","Value":183,"Internal":true,"Count Failed Values":true},{"ID":641,"Name":"number of output rows","Value":"16708","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":668,"Name":"internal.metrics.input.recordsRead","Value":16708,"Internal":true,"Count Failed Values":true},{"ID":650,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":647,"Name":"internal.metrics.executorDeserializeCpuTime","Value":2264000,"Internal":true,"Count Failed Values":true},{"ID":646,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":667,"Name":"internal.metrics.input.bytesRead","Value":1233361,"Internal":true,"Count Failed Values":true},{"ID":649,"Name":"internal.metrics.executorCpuTime","Value":165490000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":21,"Completion Time":1629344514395,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":11,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#416, None)) > 0)\n      +- Project [value#416]\n         +- Relation[value#416] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#416, None)) > 0)\n      +- Project [value#416]\n         +- Relation[value#416] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#416, None)) > 0)\n      +- Relation[value#416] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#416, None)) > 0)\n   +- *(1) FileScan text [value#416] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/immovables.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#416, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#416] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/immovables.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/immovables.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":673,"metricType":"sum"},{"name":"number of files","accumulatorId":674,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":675,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":676,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":672,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":671,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344514448}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":11,"accumUpdates":[[674,1],[675,0]]}
{"Event":"SparkListenerJobStart","Job ID":22,"Submission Time":1629344514477,"Stage Infos":[{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":104,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"225\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[103],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":101,"Name":"FileScanRDD","Scope":"{\"id\":\"221\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":102,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"221\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[101],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":103,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"224\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[102],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[22],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"11","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":104,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"225\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[103],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":101,"Name":"FileScanRDD","Scope":"{\"id\":\"221\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":102,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"221\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[101],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":103,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"224\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[102],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514477,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"11","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":22,"Stage Attempt ID":0,"Task Info":{"Task ID":22,"Index":0,"Attempt":0,"Launch Time":1629344514481,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":22,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":22,"Index":0,"Attempt":0,"Launch Time":1629344514481,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344514489,"Failed":false,"Killed":false,"Accumulables":[{"ID":672,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":673,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":699,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":698,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":681,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":680,"Name":"internal.metrics.executorCpuTime","Update":2222000,"Value":2222000,"Internal":true,"Count Failed Values":true},{"ID":679,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":678,"Name":"internal.metrics.executorDeserializeCpuTime","Update":971000,"Value":971000,"Internal":true,"Count Failed Values":true},{"ID":677,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":971000,"Executor Run Time":4,"Executor CPU Time":2222000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":104,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"225\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[103],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":101,"Name":"FileScanRDD","Scope":"{\"id\":\"221\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":102,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"221\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[101],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":103,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"224\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[102],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514477,"Completion Time":1629344514489,"Accumulables":[{"ID":678,"Name":"internal.metrics.executorDeserializeCpuTime","Value":971000,"Internal":true,"Count Failed Values":true},{"ID":672,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":699,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":681,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":677,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":698,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":680,"Name":"internal.metrics.executorCpuTime","Value":2222000,"Internal":true,"Count Failed Values":true},{"ID":673,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":679,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":22,"Completion Time":1629344514489,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":11,"time":1629344514490}
{"Event":"SparkListenerJobStart","Job ID":23,"Submission Time":1629344514526,"Stage Infos":[{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":109,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"234\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[108],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":105,"Name":"FileScanRDD","Scope":"{\"id\":\"231\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":107,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"230\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[106],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":106,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"231\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[105],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":108,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"233\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[107],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[23],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"235\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":109,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"234\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[108],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":105,"Name":"FileScanRDD","Scope":"{\"id\":\"231\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":107,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"230\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[106],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":106,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"231\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[105],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":108,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"233\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[107],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514526,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"235\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":23,"Stage Attempt ID":0,"Task Info":{"Task ID":23,"Index":0,"Attempt":0,"Launch Time":1629344514530,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":23,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":23,"Index":0,"Attempt":0,"Launch Time":1629344514530,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344514585,"Failed":false,"Killed":false,"Accumulables":[{"ID":702,"Name":"number of output rows","Update":"6546","Value":"6546","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":706,"Name":"duration total (min, med, max)","Update":"47","Value":"46","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":729,"Name":"internal.metrics.input.recordsRead","Update":6546,"Value":6546,"Internal":true,"Count Failed Values":true},{"ID":728,"Name":"internal.metrics.input.bytesRead","Update":533643,"Value":533643,"Internal":true,"Count Failed Values":true},{"ID":711,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":710,"Name":"internal.metrics.executorCpuTime","Update":46515000,"Value":46515000,"Internal":true,"Count Failed Values":true},{"ID":709,"Name":"internal.metrics.executorRunTime","Update":49,"Value":49,"Internal":true,"Count Failed Values":true},{"ID":708,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1568000,"Value":1568000,"Internal":true,"Count Failed Values":true},{"ID":707,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1568000,"Executor Run Time":49,"Executor CPU Time":46515000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":533643,"Records Read":6546},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":109,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"234\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[108],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":105,"Name":"FileScanRDD","Scope":"{\"id\":\"231\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":107,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"230\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[106],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":106,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"231\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[105],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":108,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"233\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[107],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514526,"Completion Time":1629344514585,"Accumulables":[{"ID":729,"Name":"internal.metrics.input.recordsRead","Value":6546,"Internal":true,"Count Failed Values":true},{"ID":708,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1568000,"Internal":true,"Count Failed Values":true},{"ID":702,"Name":"number of output rows","Value":"6546","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":711,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":728,"Name":"internal.metrics.input.bytesRead","Value":533643,"Internal":true,"Count Failed Values":true},{"ID":710,"Name":"internal.metrics.executorCpuTime","Value":46515000,"Internal":true,"Count Failed Values":true},{"ID":707,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":706,"Name":"duration total (min, med, max)","Value":"46","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":709,"Name":"internal.metrics.executorRunTime","Value":49,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":23,"Completion Time":1629344514585,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":12,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#453, None)) > 0)\n      +- Project [value#453]\n         +- Relation[value#453] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#453, None)) > 0)\n      +- Project [value#453]\n         +- Relation[value#453] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#453, None)) > 0)\n      +- Relation[value#453] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#453, None)) > 0)\n   +- *(1) FileScan text [value#453] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/giants_new2...., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#453, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#453] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/giants_new2...., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/giants_new2.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":734,"metricType":"sum"},{"name":"number of files","accumulatorId":735,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":736,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":737,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":733,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":732,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344514636}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":12,"accumUpdates":[[735,1],[736,0]]}
{"Event":"SparkListenerJobStart","Job ID":24,"Submission Time":1629344514671,"Stage Infos":[{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":113,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"245\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[112],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":110,"Name":"FileScanRDD","Scope":"{\"id\":\"241\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":111,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"241\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[110],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":112,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"244\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[111],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[24],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"12","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":113,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"245\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[112],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":110,"Name":"FileScanRDD","Scope":"{\"id\":\"241\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":111,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"241\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[110],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":112,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"244\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[111],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514671,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"12","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":24,"Stage Attempt ID":0,"Task Info":{"Task ID":24,"Index":0,"Attempt":0,"Launch Time":1629344514676,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":24,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":24,"Index":0,"Attempt":0,"Launch Time":1629344514676,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344514690,"Failed":false,"Killed":false,"Accumulables":[{"ID":733,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":734,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":760,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":759,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":742,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":741,"Name":"internal.metrics.executorCpuTime","Update":2582000,"Value":2582000,"Internal":true,"Count Failed Values":true},{"ID":740,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":739,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1252000,"Value":1252000,"Internal":true,"Count Failed Values":true},{"ID":738,"Name":"internal.metrics.executorDeserializeTime","Update":7,"Value":7,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":7,"Executor Deserialize CPU Time":1252000,"Executor Run Time":4,"Executor CPU Time":2582000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":113,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"245\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[112],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":110,"Name":"FileScanRDD","Scope":"{\"id\":\"241\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":111,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"241\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[110],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":112,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"244\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[111],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514671,"Completion Time":1629344514691,"Accumulables":[{"ID":738,"Name":"internal.metrics.executorDeserializeTime","Value":7,"Internal":true,"Count Failed Values":true},{"ID":759,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":741,"Name":"internal.metrics.executorCpuTime","Value":2582000,"Internal":true,"Count Failed Values":true},{"ID":740,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":734,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":733,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":760,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":742,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":739,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1252000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":24,"Completion Time":1629344514691,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":12,"time":1629344514692}
{"Event":"SparkListenerJobStart","Job ID":25,"Submission Time":1629344514739,"Stage Infos":[{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":118,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"254\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[117],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":116,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"250\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[115],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":114,"Name":"FileScanRDD","Scope":"{\"id\":\"251\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":117,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"253\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[116],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":115,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"251\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[114],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[25],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"255\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":118,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"254\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[117],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":116,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"250\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[115],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":114,"Name":"FileScanRDD","Scope":"{\"id\":\"251\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":117,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"253\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[116],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":115,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"251\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[114],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514740,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"255\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":25,"Stage Attempt ID":0,"Task Info":{"Task ID":25,"Index":0,"Attempt":0,"Launch Time":1629344514748,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":25,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":25,"Index":0,"Attempt":0,"Launch Time":1629344514748,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344514894,"Failed":false,"Killed":false,"Accumulables":[{"ID":763,"Name":"number of output rows","Update":"21437","Value":"21437","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":767,"Name":"duration total (min, med, max)","Update":"138","Value":"137","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":790,"Name":"internal.metrics.input.recordsRead","Update":21437,"Value":21437,"Internal":true,"Count Failed Values":true},{"ID":789,"Name":"internal.metrics.input.bytesRead","Update":1507746,"Value":1507746,"Internal":true,"Count Failed Values":true},{"ID":772,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":771,"Name":"internal.metrics.executorCpuTime","Update":137766000,"Value":137766000,"Internal":true,"Count Failed Values":true},{"ID":770,"Name":"internal.metrics.executorRunTime","Update":140,"Value":140,"Internal":true,"Count Failed Values":true},{"ID":769,"Name":"internal.metrics.executorDeserializeCpuTime","Update":3167000,"Value":3167000,"Internal":true,"Count Failed Values":true},{"ID":768,"Name":"internal.metrics.executorDeserializeTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":3,"Executor Deserialize CPU Time":3167000,"Executor Run Time":140,"Executor CPU Time":137766000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1507746,"Records Read":21437},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":118,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"254\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[117],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":116,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"250\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[115],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":114,"Name":"FileScanRDD","Scope":"{\"id\":\"251\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":117,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"253\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[116],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":115,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"251\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[114],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514740,"Completion Time":1629344514895,"Accumulables":[{"ID":768,"Name":"internal.metrics.executorDeserializeTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":771,"Name":"internal.metrics.executorCpuTime","Value":137766000,"Internal":true,"Count Failed Values":true},{"ID":770,"Name":"internal.metrics.executorRunTime","Value":140,"Internal":true,"Count Failed Values":true},{"ID":767,"Name":"duration total (min, med, max)","Value":"137","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":769,"Name":"internal.metrics.executorDeserializeCpuTime","Value":3167000,"Internal":true,"Count Failed Values":true},{"ID":763,"Name":"number of output rows","Value":"21437","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":790,"Name":"internal.metrics.input.recordsRead","Value":21437,"Internal":true,"Count Failed Values":true},{"ID":772,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":789,"Name":"internal.metrics.input.bytesRead","Value":1507746,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":25,"Completion Time":1629344514895,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":13,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#490, None)) > 0)\n      +- Project [value#490]\n         +- Relation[value#490] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#490, None)) > 0)\n      +- Project [value#490]\n         +- Relation[value#490] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#490, None)) > 0)\n      +- Relation[value#490] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#490, None)) > 0)\n   +- *(1) FileScan text [value#490] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/doosanbears_..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#490, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#490] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/doosanbears_..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/doosanbears_new1.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":795,"metricType":"sum"},{"name":"number of files","accumulatorId":796,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":797,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":798,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":794,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":793,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344514946}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":13,"accumUpdates":[[796,1],[797,0]]}
{"Event":"SparkListenerJobStart","Job ID":26,"Submission Time":1629344514975,"Stage Infos":[{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":122,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"265\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[121],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":119,"Name":"FileScanRDD","Scope":"{\"id\":\"261\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":120,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"261\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[119],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":121,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"264\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[120],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[26],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"13","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":122,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"265\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[121],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":119,"Name":"FileScanRDD","Scope":"{\"id\":\"261\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":120,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"261\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[119],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":121,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"264\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[120],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514976,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"13","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":26,"Stage Attempt ID":0,"Task Info":{"Task ID":26,"Index":0,"Attempt":0,"Launch Time":1629344514979,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":26,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":26,"Index":0,"Attempt":0,"Launch Time":1629344514979,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344514987,"Failed":false,"Killed":false,"Accumulables":[{"ID":794,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":795,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":821,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":820,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":803,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":802,"Name":"internal.metrics.executorCpuTime","Update":2432000,"Value":2432000,"Internal":true,"Count Failed Values":true},{"ID":801,"Name":"internal.metrics.executorRunTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true},{"ID":800,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1317000,"Value":1317000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":1317000,"Executor Run Time":5,"Executor CPU Time":2432000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":122,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"265\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[121],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":119,"Name":"FileScanRDD","Scope":"{\"id\":\"261\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":120,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"261\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[119],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":121,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"264\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[120],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344514976,"Completion Time":1629344514987,"Accumulables":[{"ID":801,"Name":"internal.metrics.executorRunTime","Value":5,"Internal":true,"Count Failed Values":true},{"ID":795,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":821,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":803,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":800,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1317000,"Internal":true,"Count Failed Values":true},{"ID":794,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":820,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":802,"Name":"internal.metrics.executorCpuTime","Value":2432000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":26,"Completion Time":1629344514987,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":13,"time":1629344514988}
{"Event":"SparkListenerJobStart","Job ID":27,"Submission Time":1629344515031,"Stage Infos":[{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":127,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"274\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[126],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":123,"Name":"FileScanRDD","Scope":"{\"id\":\"271\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":126,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"273\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[125],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":125,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"270\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[124],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":124,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"271\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[123],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[27],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"275\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":127,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"274\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[126],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":123,"Name":"FileScanRDD","Scope":"{\"id\":\"271\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":126,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"273\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[125],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":125,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"270\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[124],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":124,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"271\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[123],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515032,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"275\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":27,"Stage Attempt ID":0,"Task Info":{"Task ID":27,"Index":0,"Attempt":0,"Launch Time":1629344515036,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":27,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":27,"Index":0,"Attempt":0,"Launch Time":1629344515036,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344515090,"Failed":false,"Killed":false,"Accumulables":[{"ID":824,"Name":"number of output rows","Update":"5750","Value":"5750","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":828,"Name":"duration total (min, med, max)","Update":"47","Value":"46","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":851,"Name":"internal.metrics.input.recordsRead","Update":5750,"Value":5750,"Internal":true,"Count Failed Values":true},{"ID":850,"Name":"internal.metrics.input.bytesRead","Update":414286,"Value":414286,"Internal":true,"Count Failed Values":true},{"ID":833,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":832,"Name":"internal.metrics.executorCpuTime","Update":46147000,"Value":46147000,"Internal":true,"Count Failed Values":true},{"ID":831,"Name":"internal.metrics.executorRunTime","Update":49,"Value":49,"Internal":true,"Count Failed Values":true},{"ID":830,"Name":"internal.metrics.executorDeserializeCpuTime","Update":2237000,"Value":2237000,"Internal":true,"Count Failed Values":true},{"ID":829,"Name":"internal.metrics.executorDeserializeTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":3,"Executor Deserialize CPU Time":2237000,"Executor Run Time":49,"Executor CPU Time":46147000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":414286,"Records Read":5750},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":127,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"274\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[126],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":123,"Name":"FileScanRDD","Scope":"{\"id\":\"271\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":126,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"273\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[125],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":125,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"270\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[124],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":124,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"271\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[123],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515032,"Completion Time":1629344515090,"Accumulables":[{"ID":828,"Name":"duration total (min, med, max)","Value":"46","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":831,"Name":"internal.metrics.executorRunTime","Value":49,"Internal":true,"Count Failed Values":true},{"ID":830,"Name":"internal.metrics.executorDeserializeCpuTime","Value":2237000,"Internal":true,"Count Failed Values":true},{"ID":824,"Name":"number of output rows","Value":"5750","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":851,"Name":"internal.metrics.input.recordsRead","Value":5750,"Internal":true,"Count Failed Values":true},{"ID":833,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":829,"Name":"internal.metrics.executorDeserializeTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":850,"Name":"internal.metrics.input.bytesRead","Value":414286,"Internal":true,"Count Failed Values":true},{"ID":832,"Name":"internal.metrics.executorCpuTime","Value":46147000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":27,"Completion Time":1629344515090,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":14,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#527, None)) > 0)\n      +- Project [value#527]\n         +- Relation[value#527] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#527, None)) > 0)\n      +- Project [value#527]\n         +- Relation[value#527] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#527, None)) > 0)\n      +- Relation[value#527] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#527, None)) > 0)\n   +- *(1) FileScan text [value#527] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/mabi_heroes2..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#527, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#527] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/mabi_heroes2..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/mabi_heroes2.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":856,"metricType":"sum"},{"name":"number of files","accumulatorId":857,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":858,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":859,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":855,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":854,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344515145}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":14,"accumUpdates":[[857,1],[858,0]]}
{"Event":"SparkListenerJobStart","Job ID":28,"Submission Time":1629344515173,"Stage Infos":[{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":131,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"285\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[130],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":130,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"284\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[129],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":128,"Name":"FileScanRDD","Scope":"{\"id\":\"281\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":129,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"281\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[128],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[28],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"14","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":131,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"285\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[130],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":130,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"284\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[129],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":128,"Name":"FileScanRDD","Scope":"{\"id\":\"281\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":129,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"281\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[128],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515174,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"14","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":28,"Stage Attempt ID":0,"Task Info":{"Task ID":28,"Index":0,"Attempt":0,"Launch Time":1629344515178,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":28,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":28,"Index":0,"Attempt":0,"Launch Time":1629344515178,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344515185,"Failed":false,"Killed":false,"Accumulables":[{"ID":855,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":856,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":882,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":881,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":864,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":863,"Name":"internal.metrics.executorCpuTime","Update":2238000,"Value":2238000,"Internal":true,"Count Failed Values":true},{"ID":862,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":861,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1109000,"Value":1109000,"Internal":true,"Count Failed Values":true},{"ID":860,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1109000,"Executor Run Time":4,"Executor CPU Time":2238000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":131,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"285\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[130],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":130,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"284\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[129],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":128,"Name":"FileScanRDD","Scope":"{\"id\":\"281\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":129,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"281\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[128],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515174,"Completion Time":1629344515186,"Accumulables":[{"ID":855,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":882,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":864,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":881,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":863,"Name":"internal.metrics.executorCpuTime","Value":2238000,"Internal":true,"Count Failed Values":true},{"ID":860,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":862,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":856,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":861,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1109000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":28,"Completion Time":1629344515186,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":14,"time":1629344515186}
{"Event":"SparkListenerJobStart","Job ID":29,"Submission Time":1629344515238,"Stage Infos":[{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":136,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"294\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[135],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":134,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"290\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[133],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":133,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"291\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[132],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":132,"Name":"FileScanRDD","Scope":"{\"id\":\"291\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":135,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"293\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[134],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[29],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"295\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":136,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"294\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[135],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":134,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"290\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[133],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":133,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"291\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[132],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":132,"Name":"FileScanRDD","Scope":"{\"id\":\"291\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":135,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"293\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[134],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515239,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"295\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":29,"Stage Attempt ID":0,"Task Info":{"Task ID":29,"Index":0,"Attempt":0,"Launch Time":1629344515245,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":29,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":29,"Index":0,"Attempt":0,"Launch Time":1629344515245,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344515306,"Failed":false,"Killed":false,"Accumulables":[{"ID":885,"Name":"number of output rows","Update":"6752","Value":"6752","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":889,"Name":"duration total (min, med, max)","Update":"55","Value":"54","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":912,"Name":"internal.metrics.input.recordsRead","Update":6752,"Value":6752,"Internal":true,"Count Failed Values":true},{"ID":911,"Name":"internal.metrics.input.bytesRead","Update":450604,"Value":450604,"Internal":true,"Count Failed Values":true},{"ID":896,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":894,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":893,"Name":"internal.metrics.executorCpuTime","Update":55192000,"Value":55192000,"Internal":true,"Count Failed Values":true},{"ID":892,"Name":"internal.metrics.executorRunTime","Update":57,"Value":57,"Internal":true,"Count Failed Values":true},{"ID":891,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1508000,"Value":1508000,"Internal":true,"Count Failed Values":true},{"ID":890,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1508000,"Executor Run Time":57,"Executor CPU Time":55192000,"Result Size":1571,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":450604,"Records Read":6752},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":136,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"294\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[135],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":134,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"290\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[133],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":133,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"291\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[132],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":132,"Name":"FileScanRDD","Scope":"{\"id\":\"291\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":135,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"293\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[134],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515239,"Completion Time":1629344515307,"Accumulables":[{"ID":891,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1508000,"Internal":true,"Count Failed Values":true},{"ID":890,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":911,"Name":"internal.metrics.input.bytesRead","Value":450604,"Internal":true,"Count Failed Values":true},{"ID":893,"Name":"internal.metrics.executorCpuTime","Value":55192000,"Internal":true,"Count Failed Values":true},{"ID":896,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":889,"Name":"duration total (min, med, max)","Value":"54","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":892,"Name":"internal.metrics.executorRunTime","Value":57,"Internal":true,"Count Failed Values":true},{"ID":885,"Name":"number of output rows","Value":"6752","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":912,"Name":"internal.metrics.input.recordsRead","Value":6752,"Internal":true,"Count Failed Values":true},{"ID":894,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":29,"Completion Time":1629344515307,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":15,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#564, None)) > 0)\n      +- Project [value#564]\n         +- Relation[value#564] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#564, None)) > 0)\n      +- Project [value#564]\n         +- Relation[value#564] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#564, None)) > 0)\n      +- Relation[value#564] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#564, None)) > 0)\n   +- *(1) FileScan text [value#564] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/granblue.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#564, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#564] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/granblue.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/granblue.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":917,"metricType":"sum"},{"name":"number of files","accumulatorId":918,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":919,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":920,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":916,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":915,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344515361}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":15,"accumUpdates":[[918,1],[919,0]]}
{"Event":"SparkListenerJobStart","Job ID":30,"Submission Time":1629344515396,"Stage Infos":[{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":140,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"305\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[139],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":137,"Name":"FileScanRDD","Scope":"{\"id\":\"301\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":139,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"304\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[138],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":138,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"301\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[137],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[30],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"15","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":140,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"305\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[139],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":137,"Name":"FileScanRDD","Scope":"{\"id\":\"301\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":139,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"304\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[138],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":138,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"301\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[137],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515396,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"15","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":30,"Stage Attempt ID":0,"Task Info":{"Task ID":30,"Index":0,"Attempt":0,"Launch Time":1629344515402,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":30,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":30,"Index":0,"Attempt":0,"Launch Time":1629344515402,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344515408,"Failed":false,"Killed":false,"Accumulables":[{"ID":916,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":917,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":943,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":942,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":925,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":924,"Name":"internal.metrics.executorCpuTime","Update":1988000,"Value":1988000,"Internal":true,"Count Failed Values":true},{"ID":923,"Name":"internal.metrics.executorRunTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true},{"ID":922,"Name":"internal.metrics.executorDeserializeCpuTime","Update":935000,"Value":935000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":935000,"Executor Run Time":5,"Executor CPU Time":1988000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":140,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"305\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[139],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":137,"Name":"FileScanRDD","Scope":"{\"id\":\"301\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":139,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"304\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[138],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":138,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"301\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[137],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515396,"Completion Time":1629344515409,"Accumulables":[{"ID":923,"Name":"internal.metrics.executorRunTime","Value":5,"Internal":true,"Count Failed Values":true},{"ID":917,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":922,"Name":"internal.metrics.executorDeserializeCpuTime","Value":935000,"Internal":true,"Count Failed Values":true},{"ID":916,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":943,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":925,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":942,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":924,"Name":"internal.metrics.executorCpuTime","Value":1988000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":30,"Completion Time":1629344515409,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":15,"time":1629344515409}
{"Event":"SparkListenerJobStart","Job ID":31,"Submission Time":1629344515454,"Stage Infos":[{"Stage ID":31,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":145,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"314\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[144],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":143,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"310\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[142],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":141,"Name":"FileScanRDD","Scope":"{\"id\":\"311\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":142,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"311\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[141],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":144,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"313\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[143],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[31],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"315\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":31,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":145,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"314\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[144],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":143,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"310\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[142],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":141,"Name":"FileScanRDD","Scope":"{\"id\":\"311\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":142,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"311\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[141],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":144,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"313\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[143],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515455,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"315\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":31,"Stage Attempt ID":0,"Task Info":{"Task ID":31,"Index":0,"Attempt":0,"Launch Time":1629344515460,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":31,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":31,"Index":0,"Attempt":0,"Launch Time":1629344515460,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344515581,"Failed":false,"Killed":false,"Accumulables":[{"ID":946,"Name":"number of output rows","Update":"12560","Value":"12560","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":950,"Name":"duration total (min, med, max)","Update":"115","Value":"114","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":973,"Name":"internal.metrics.input.recordsRead","Update":12560,"Value":12560,"Internal":true,"Count Failed Values":true},{"ID":972,"Name":"internal.metrics.input.bytesRead","Update":848601,"Value":848601,"Internal":true,"Count Failed Values":true},{"ID":957,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":956,"Name":"internal.metrics.jvmGCTime","Update":7,"Value":7,"Internal":true,"Count Failed Values":true},{"ID":955,"Name":"internal.metrics.resultSize","Update":1614,"Value":1614,"Internal":true,"Count Failed Values":true},{"ID":954,"Name":"internal.metrics.executorCpuTime","Update":106262000,"Value":106262000,"Internal":true,"Count Failed Values":true},{"ID":953,"Name":"internal.metrics.executorRunTime","Update":118,"Value":118,"Internal":true,"Count Failed Values":true},{"ID":952,"Name":"internal.metrics.executorDeserializeCpuTime","Update":2140000,"Value":2140000,"Internal":true,"Count Failed Values":true},{"ID":951,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":2140000,"Executor Run Time":118,"Executor CPU Time":106262000,"Result Size":1614,"JVM GC Time":7,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":848601,"Records Read":12560},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":31,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":145,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"314\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[144],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":143,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"310\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[142],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":141,"Name":"FileScanRDD","Scope":"{\"id\":\"311\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":142,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"311\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[141],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":144,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"313\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[143],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515455,"Completion Time":1629344515582,"Accumulables":[{"ID":950,"Name":"duration total (min, med, max)","Value":"114","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":953,"Name":"internal.metrics.executorRunTime","Value":118,"Internal":true,"Count Failed Values":true},{"ID":956,"Name":"internal.metrics.jvmGCTime","Value":7,"Internal":true,"Count Failed Values":true},{"ID":946,"Name":"number of output rows","Value":"12560","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":973,"Name":"internal.metrics.input.recordsRead","Value":12560,"Internal":true,"Count Failed Values":true},{"ID":955,"Name":"internal.metrics.resultSize","Value":1614,"Internal":true,"Count Failed Values":true},{"ID":952,"Name":"internal.metrics.executorDeserializeCpuTime","Value":2140000,"Internal":true,"Count Failed Values":true},{"ID":972,"Name":"internal.metrics.input.bytesRead","Value":848601,"Internal":true,"Count Failed Values":true},{"ID":954,"Name":"internal.metrics.executorCpuTime","Value":106262000,"Internal":true,"Count Failed Values":true},{"ID":957,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":951,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":31,"Completion Time":1629344515582,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":16,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#601, None)) > 0)\n      +- Project [value#601]\n         +- Relation[value#601] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#601, None)) > 0)\n      +- Project [value#601]\n         +- Relation[value#601] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#601, None)) > 0)\n      +- Relation[value#601] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#601, None)) > 0)\n   +- *(1) FileScan text [value#601] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/bd.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#601, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#601] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/bd.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/bd.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":978,"metricType":"sum"},{"name":"number of files","accumulatorId":979,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":980,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":981,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":977,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":976,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344515632}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":16,"accumUpdates":[[979,1],[980,0]]}
{"Event":"SparkListenerJobStart","Job ID":32,"Submission Time":1629344515662,"Stage Infos":[{"Stage ID":32,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":149,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"325\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[148],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":148,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"324\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[147],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":146,"Name":"FileScanRDD","Scope":"{\"id\":\"321\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":147,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"321\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[146],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[32],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"16","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":32,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":149,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"325\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[148],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":148,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"324\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[147],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":146,"Name":"FileScanRDD","Scope":"{\"id\":\"321\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":147,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"321\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[146],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515662,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"16","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":32,"Stage Attempt ID":0,"Task Info":{"Task ID":32,"Index":0,"Attempt":0,"Launch Time":1629344515667,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":32,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":32,"Index":0,"Attempt":0,"Launch Time":1629344515667,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344515673,"Failed":false,"Killed":false,"Accumulables":[{"ID":977,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":978,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1004,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1003,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":986,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":985,"Name":"internal.metrics.executorCpuTime","Update":1998000,"Value":1998000,"Internal":true,"Count Failed Values":true},{"ID":984,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":983,"Name":"internal.metrics.executorDeserializeCpuTime","Update":841000,"Value":841000,"Internal":true,"Count Failed Values":true},{"ID":982,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":841000,"Executor Run Time":4,"Executor CPU Time":1998000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":32,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":149,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"325\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[148],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":148,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"324\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[147],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":146,"Name":"FileScanRDD","Scope":"{\"id\":\"321\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":147,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"321\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[146],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515662,"Completion Time":1629344515674,"Accumulables":[{"ID":983,"Name":"internal.metrics.executorDeserializeCpuTime","Value":841000,"Internal":true,"Count Failed Values":true},{"ID":977,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1004,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":986,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":982,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1003,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":985,"Name":"internal.metrics.executorCpuTime","Value":1998000,"Internal":true,"Count Failed Values":true},{"ID":978,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":984,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":32,"Completion Time":1629344515674,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":16,"time":1629344515674}
{"Event":"SparkListenerJobStart","Job ID":33,"Submission Time":1629344515708,"Stage Infos":[{"Stage ID":33,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":154,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"334\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[153],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":153,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"333\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[152],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":150,"Name":"FileScanRDD","Scope":"{\"id\":\"331\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":152,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"330\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[151],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":151,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"331\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[150],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[33],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"335\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":33,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":154,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"334\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[153],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":153,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"333\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[152],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":150,"Name":"FileScanRDD","Scope":"{\"id\":\"331\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":152,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"330\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[151],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":151,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"331\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[150],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515708,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"335\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":33,"Stage Attempt ID":0,"Task Info":{"Task ID":33,"Index":0,"Attempt":0,"Launch Time":1629344515711,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":33,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":33,"Index":0,"Attempt":0,"Launch Time":1629344515711,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344515724,"Failed":false,"Killed":false,"Accumulables":[{"ID":1007,"Name":"number of output rows","Update":"1146","Value":"1146","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1011,"Name":"duration total (min, med, max)","Update":"8","Value":"7","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1034,"Name":"internal.metrics.input.recordsRead","Update":1146,"Value":1146,"Internal":true,"Count Failed Values":true},{"ID":1033,"Name":"internal.metrics.input.bytesRead","Update":86862,"Value":86862,"Internal":true,"Count Failed Values":true},{"ID":1016,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1015,"Name":"internal.metrics.executorCpuTime","Update":9633000,"Value":9633000,"Internal":true,"Count Failed Values":true},{"ID":1014,"Name":"internal.metrics.executorRunTime","Update":10,"Value":10,"Internal":true,"Count Failed Values":true},{"ID":1013,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1445000,"Value":1445000,"Internal":true,"Count Failed Values":true},{"ID":1012,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1445000,"Executor Run Time":10,"Executor CPU Time":9633000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":86862,"Records Read":1146},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":33,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":154,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"334\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[153],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":153,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"333\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[152],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":150,"Name":"FileScanRDD","Scope":"{\"id\":\"331\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":152,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"330\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[151],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":151,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"331\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[150],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515708,"Completion Time":1629344515725,"Accumulables":[{"ID":1013,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1445000,"Internal":true,"Count Failed Values":true},{"ID":1007,"Name":"number of output rows","Value":"1146","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1034,"Name":"internal.metrics.input.recordsRead","Value":1146,"Internal":true,"Count Failed Values":true},{"ID":1016,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1033,"Name":"internal.metrics.input.bytesRead","Value":86862,"Internal":true,"Count Failed Values":true},{"ID":1015,"Name":"internal.metrics.executorCpuTime","Value":9633000,"Internal":true,"Count Failed Values":true},{"ID":1012,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1014,"Name":"internal.metrics.executorRunTime","Value":10,"Internal":true,"Count Failed Values":true},{"ID":1011,"Name":"duration total (min, med, max)","Value":"7","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":33,"Completion Time":1629344515725,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":17,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#638, None)) > 0)\n      +- Project [value#638]\n         +- Relation[value#638] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#638, None)) > 0)\n      +- Project [value#638]\n         +- Relation[value#638] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#638, None)) > 0)\n      +- Relation[value#638] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#638, None)) > 0)\n   +- *(1) FileScan text [value#638] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/diet.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#638, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#638] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/diet.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/diet.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1039,"metricType":"sum"},{"name":"number of files","accumulatorId":1040,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1041,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1042,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1038,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1037,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344515770}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":17,"accumUpdates":[[1040,1],[1041,0]]}
{"Event":"SparkListenerJobStart","Job ID":34,"Submission Time":1629344515795,"Stage Infos":[{"Stage ID":34,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":158,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"345\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[157],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":155,"Name":"FileScanRDD","Scope":"{\"id\":\"341\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":156,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"341\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[155],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":157,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"344\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[156],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[34],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"17","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":34,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":158,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"345\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[157],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":155,"Name":"FileScanRDD","Scope":"{\"id\":\"341\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":156,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"341\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[155],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":157,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"344\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[156],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515796,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"17","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":34,"Stage Attempt ID":0,"Task Info":{"Task ID":34,"Index":0,"Attempt":0,"Launch Time":1629344515801,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":34,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":34,"Index":0,"Attempt":0,"Launch Time":1629344515801,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344515807,"Failed":false,"Killed":false,"Accumulables":[{"ID":1038,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1039,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1065,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1064,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1047,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1046,"Name":"internal.metrics.executorCpuTime","Update":2656000,"Value":2656000,"Internal":true,"Count Failed Values":true},{"ID":1045,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":1044,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1574000,"Value":1574000,"Internal":true,"Count Failed Values":true},{"ID":1043,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1574000,"Executor Run Time":4,"Executor CPU Time":2656000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":34,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":158,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"345\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[157],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":155,"Name":"FileScanRDD","Scope":"{\"id\":\"341\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":156,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"341\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[155],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":157,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"344\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[156],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515796,"Completion Time":1629344515808,"Accumulables":[{"ID":1043,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1064,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1046,"Name":"internal.metrics.executorCpuTime","Value":2656000,"Internal":true,"Count Failed Values":true},{"ID":1045,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":1039,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1038,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1065,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1047,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1044,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1574000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":34,"Completion Time":1629344515808,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":17,"time":1629344515808}
{"Event":"SparkListenerJobStart","Job ID":35,"Submission Time":1629344515843,"Stage Infos":[{"Stage ID":35,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":163,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"354\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[162],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":162,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"353\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[161],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":161,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"350\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[160],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":160,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"351\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[159],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":159,"Name":"FileScanRDD","Scope":"{\"id\":\"351\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[35],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"355\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":35,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":163,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"354\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[162],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":162,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"353\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[161],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":161,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"350\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[160],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":160,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"351\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[159],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":159,"Name":"FileScanRDD","Scope":"{\"id\":\"351\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515843,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"355\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":35,"Stage Attempt ID":0,"Task Info":{"Task ID":35,"Index":0,"Attempt":0,"Launch Time":1629344515847,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":35,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":35,"Index":0,"Attempt":0,"Launch Time":1629344515847,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344515878,"Failed":false,"Killed":false,"Accumulables":[{"ID":1068,"Name":"number of output rows","Update":"3942","Value":"3942","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1072,"Name":"duration total (min, med, max)","Update":"26","Value":"25","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1095,"Name":"internal.metrics.input.recordsRead","Update":3942,"Value":3942,"Internal":true,"Count Failed Values":true},{"ID":1094,"Name":"internal.metrics.input.bytesRead","Update":254205,"Value":254205,"Internal":true,"Count Failed Values":true},{"ID":1077,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1076,"Name":"internal.metrics.executorCpuTime","Update":25729000,"Value":25729000,"Internal":true,"Count Failed Values":true},{"ID":1075,"Name":"internal.metrics.executorRunTime","Update":28,"Value":28,"Internal":true,"Count Failed Values":true},{"ID":1074,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1151000,"Value":1151000,"Internal":true,"Count Failed Values":true},{"ID":1073,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1151000,"Executor Run Time":28,"Executor CPU Time":25729000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":254205,"Records Read":3942},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":35,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":163,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"354\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[162],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":162,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"353\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[161],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":161,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"350\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[160],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":160,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"351\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[159],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":159,"Name":"FileScanRDD","Scope":"{\"id\":\"351\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515843,"Completion Time":1629344515878,"Accumulables":[{"ID":1073,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1094,"Name":"internal.metrics.input.bytesRead","Value":254205,"Internal":true,"Count Failed Values":true},{"ID":1076,"Name":"internal.metrics.executorCpuTime","Value":25729000,"Internal":true,"Count Failed Values":true},{"ID":1075,"Name":"internal.metrics.executorRunTime","Value":28,"Internal":true,"Count Failed Values":true},{"ID":1072,"Name":"duration total (min, med, max)","Value":"25","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1074,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1151000,"Internal":true,"Count Failed Values":true},{"ID":1068,"Name":"number of output rows","Value":"3942","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1095,"Name":"internal.metrics.input.recordsRead","Value":3942,"Internal":true,"Count Failed Values":true},{"ID":1077,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":35,"Completion Time":1629344515878,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":18,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#675, None)) > 0)\n      +- Project [value#675]\n         +- Relation[value#675] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#675, None)) > 0)\n      +- Project [value#675]\n         +- Relation[value#675] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#675, None)) > 0)\n      +- Relation[value#675] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#675, None)) > 0)\n   +- *(1) FileScan text [value#675] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/japan_entert..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#675, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#675] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/japan_entert..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/japan_entertainment.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1100,"metricType":"sum"},{"name":"number of files","accumulatorId":1101,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1102,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1103,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1099,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1098,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344515938}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":18,"accumUpdates":[[1101,1],[1102,0]]}
{"Event":"SparkListenerJobStart","Job ID":36,"Submission Time":1629344515981,"Stage Infos":[{"Stage ID":36,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":167,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"365\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[166],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":166,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"364\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[165],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":164,"Name":"FileScanRDD","Scope":"{\"id\":\"361\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":165,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"361\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[164],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[36],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"18","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":36,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":167,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"365\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[166],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":166,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"364\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[165],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":164,"Name":"FileScanRDD","Scope":"{\"id\":\"361\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":165,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"361\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[164],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515982,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"18","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":36,"Stage Attempt ID":0,"Task Info":{"Task ID":36,"Index":0,"Attempt":0,"Launch Time":1629344515991,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":36,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":36,"Index":0,"Attempt":0,"Launch Time":1629344515991,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344516000,"Failed":false,"Killed":false,"Accumulables":[{"ID":1099,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1100,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1126,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1125,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1108,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1107,"Name":"internal.metrics.executorCpuTime","Update":2787000,"Value":2787000,"Internal":true,"Count Failed Values":true},{"ID":1106,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":1105,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1173000,"Value":1173000,"Internal":true,"Count Failed Values":true},{"ID":1104,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1173000,"Executor Run Time":4,"Executor CPU Time":2787000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":36,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":167,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"365\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[166],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":166,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"364\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[165],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":164,"Name":"FileScanRDD","Scope":"{\"id\":\"361\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":165,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"361\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[164],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344515982,"Completion Time":1629344516001,"Accumulables":[{"ID":1106,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":1100,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1126,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1105,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1173000,"Internal":true,"Count Failed Values":true},{"ID":1099,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1108,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1125,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1107,"Name":"internal.metrics.executorCpuTime","Value":2787000,"Internal":true,"Count Failed Values":true},{"ID":1104,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":36,"Completion Time":1629344516001,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":18,"time":1629344516002}
{"Event":"SparkListenerJobStart","Job ID":37,"Submission Time":1629344516047,"Stage Infos":[{"Stage ID":37,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":172,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"374\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[171],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":168,"Name":"FileScanRDD","Scope":"{\"id\":\"371\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":171,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"373\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[170],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":169,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"371\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[168],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":170,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"370\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[169],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[37],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"375\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":37,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":172,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"374\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[171],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":168,"Name":"FileScanRDD","Scope":"{\"id\":\"371\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":171,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"373\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[170],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":169,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"371\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[168],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":170,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"370\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[169],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344516048,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"375\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":37,"Stage Attempt ID":0,"Task Info":{"Task ID":37,"Index":0,"Attempt":0,"Launch Time":1629344516055,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":37,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":37,"Index":0,"Attempt":0,"Launch Time":1629344516055,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344516078,"Failed":false,"Killed":false,"Accumulables":[{"ID":1129,"Name":"number of output rows","Update":"2193","Value":"2193","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1133,"Name":"duration total (min, med, max)","Update":"18","Value":"17","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1156,"Name":"internal.metrics.input.recordsRead","Update":2193,"Value":2193,"Internal":true,"Count Failed Values":true},{"ID":1155,"Name":"internal.metrics.input.bytesRead","Update":143604,"Value":143604,"Internal":true,"Count Failed Values":true},{"ID":1138,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1137,"Name":"internal.metrics.executorCpuTime","Update":17944000,"Value":17944000,"Internal":true,"Count Failed Values":true},{"ID":1136,"Name":"internal.metrics.executorRunTime","Update":19,"Value":19,"Internal":true,"Count Failed Values":true},{"ID":1135,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1352000,"Value":1352000,"Internal":true,"Count Failed Values":true},{"ID":1134,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1352000,"Executor Run Time":19,"Executor CPU Time":17944000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":143604,"Records Read":2193},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":37,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":172,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"374\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[171],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":168,"Name":"FileScanRDD","Scope":"{\"id\":\"371\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":171,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"373\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[170],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":169,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"371\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[168],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":170,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"370\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[169],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344516048,"Completion Time":1629344516079,"Accumulables":[{"ID":1133,"Name":"duration total (min, med, max)","Value":"17","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1136,"Name":"internal.metrics.executorRunTime","Value":19,"Internal":true,"Count Failed Values":true},{"ID":1135,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1352000,"Internal":true,"Count Failed Values":true},{"ID":1129,"Name":"number of output rows","Value":"2193","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1156,"Name":"internal.metrics.input.recordsRead","Value":2193,"Internal":true,"Count Failed Values":true},{"ID":1138,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1134,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":1155,"Name":"internal.metrics.input.bytesRead","Value":143604,"Internal":true,"Count Failed Values":true},{"ID":1137,"Name":"internal.metrics.executorCpuTime","Value":17944000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":37,"Completion Time":1629344516079,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":19,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#712, None)) > 0)\n      +- Project [value#712]\n         +- Relation[value#712] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#712, None)) > 0)\n      +- Project [value#712]\n         +- Relation[value#712] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#712, None)) > 0)\n      +- Relation[value#712] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#712, None)) > 0)\n   +- *(1) FileScan text [value#712] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/football_new..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#712, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#712] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/football_new..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/football_new7.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1161,"metricType":"sum"},{"name":"number of files","accumulatorId":1162,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1163,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1164,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1160,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1159,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344516133}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":19,"accumUpdates":[[1162,1],[1163,0]]}
{"Event":"SparkListenerJobStart","Job ID":38,"Submission Time":1629344516166,"Stage Infos":[{"Stage ID":38,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":176,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"385\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[175],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":174,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"381\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[173],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":173,"Name":"FileScanRDD","Scope":"{\"id\":\"381\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":175,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"384\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[174],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[38],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"19","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":38,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":176,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"385\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[175],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":174,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"381\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[173],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":173,"Name":"FileScanRDD","Scope":"{\"id\":\"381\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":175,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"384\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[174],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344516166,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"19","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":38,"Stage Attempt ID":0,"Task Info":{"Task ID":38,"Index":0,"Attempt":0,"Launch Time":1629344516169,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":38,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":38,"Index":0,"Attempt":0,"Launch Time":1629344516169,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344516175,"Failed":false,"Killed":false,"Accumulables":[{"ID":1160,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1161,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1187,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1186,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1169,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1168,"Name":"internal.metrics.executorCpuTime","Update":1896000,"Value":1896000,"Internal":true,"Count Failed Values":true},{"ID":1167,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":1166,"Name":"internal.metrics.executorDeserializeCpuTime","Update":852000,"Value":852000,"Internal":true,"Count Failed Values":true},{"ID":1165,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":852000,"Executor Run Time":3,"Executor CPU Time":1896000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":38,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":176,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"385\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[175],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":174,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"381\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[173],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":173,"Name":"FileScanRDD","Scope":"{\"id\":\"381\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":175,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"384\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[174],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344516166,"Completion Time":1629344516176,"Accumulables":[{"ID":1160,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1187,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1169,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1186,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1165,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":1168,"Name":"internal.metrics.executorCpuTime","Value":1896000,"Internal":true,"Count Failed Values":true},{"ID":1167,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":1161,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1166,"Name":"internal.metrics.executorDeserializeCpuTime","Value":852000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":38,"Completion Time":1629344516176,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":19,"time":1629344516176}
{"Event":"SparkListenerJobStart","Job ID":39,"Submission Time":1629344516212,"Stage Infos":[{"Stage ID":39,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":181,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"394\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[180],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":177,"Name":"FileScanRDD","Scope":"{\"id\":\"391\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":179,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"390\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[178],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":178,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"391\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[177],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":180,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"393\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[179],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[39],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"395\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":39,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":181,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"394\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[180],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":177,"Name":"FileScanRDD","Scope":"{\"id\":\"391\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":179,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"390\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[178],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":178,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"391\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[177],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":180,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"393\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[179],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344516212,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"395\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":39,"Stage Attempt ID":0,"Task Info":{"Task ID":39,"Index":0,"Attempt":0,"Launch Time":1629344516221,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":39,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":39,"Index":0,"Attempt":0,"Launch Time":1629344516221,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344516479,"Failed":false,"Killed":false,"Accumulables":[{"ID":1190,"Name":"number of output rows","Update":"39950","Value":"39950","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1194,"Name":"duration total (min, med, max)","Update":"250","Value":"249","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1217,"Name":"internal.metrics.input.recordsRead","Update":39950,"Value":39950,"Internal":true,"Count Failed Values":true},{"ID":1216,"Name":"internal.metrics.input.bytesRead","Update":3007618,"Value":3007618,"Internal":true,"Count Failed Values":true},{"ID":1201,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1199,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":1198,"Name":"internal.metrics.executorCpuTime","Update":249010000,"Value":249010000,"Internal":true,"Count Failed Values":true},{"ID":1197,"Name":"internal.metrics.executorRunTime","Update":253,"Value":253,"Internal":true,"Count Failed Values":true},{"ID":1196,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1177000,"Value":1177000,"Internal":true,"Count Failed Values":true},{"ID":1195,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1177000,"Executor Run Time":253,"Executor CPU Time":249010000,"Result Size":1571,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":3007618,"Records Read":39950},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":39,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":181,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"394\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[180],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":177,"Name":"FileScanRDD","Scope":"{\"id\":\"391\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":179,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"390\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[178],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":178,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"391\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[177],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":180,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"393\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[179],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344516212,"Completion Time":1629344516480,"Accumulables":[{"ID":1196,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1177000,"Internal":true,"Count Failed Values":true},{"ID":1195,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1216,"Name":"internal.metrics.input.bytesRead","Value":3007618,"Internal":true,"Count Failed Values":true},{"ID":1198,"Name":"internal.metrics.executorCpuTime","Value":249010000,"Internal":true,"Count Failed Values":true},{"ID":1201,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1194,"Name":"duration total (min, med, max)","Value":"249","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1197,"Name":"internal.metrics.executorRunTime","Value":253,"Internal":true,"Count Failed Values":true},{"ID":1190,"Name":"number of output rows","Value":"39950","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1217,"Name":"internal.metrics.input.recordsRead","Value":39950,"Internal":true,"Count Failed Values":true},{"ID":1199,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":39,"Completion Time":1629344516480,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":20,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#749, None)) > 0)\n      +- Project [value#749]\n         +- Relation[value#749] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#749, None)) > 0)\n      +- Project [value#749]\n         +- Relation[value#749] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#749, None)) > 0)\n      +- Relation[value#749] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#749, None)) > 0)\n   +- *(1) FileScan text [value#749] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/penthouse.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#749, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#749] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/penthouse.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/penthouse.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1222,"metricType":"sum"},{"name":"number of files","accumulatorId":1223,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1224,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1225,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1221,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1220,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344516551}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":20,"accumUpdates":[[1223,1],[1224,0]]}
{"Event":"SparkListenerJobStart","Job ID":40,"Submission Time":1629344516590,"Stage Infos":[{"Stage ID":40,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":185,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"405\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[184],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":183,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"401\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[182],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":184,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"404\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[183],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":182,"Name":"FileScanRDD","Scope":"{\"id\":\"401\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[40],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"20","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":40,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":185,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"405\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[184],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":183,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"401\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[182],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":184,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"404\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[183],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":182,"Name":"FileScanRDD","Scope":"{\"id\":\"401\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344516590,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"20","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":40,"Stage Attempt ID":0,"Task Info":{"Task ID":40,"Index":0,"Attempt":0,"Launch Time":1629344516598,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":40,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":40,"Index":0,"Attempt":0,"Launch Time":1629344516598,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344516608,"Failed":false,"Killed":false,"Accumulables":[{"ID":1221,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1222,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1248,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1247,"Name":"internal.metrics.input.bytesRead","Update":43,"Value":43,"Internal":true,"Count Failed Values":true},{"ID":1230,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1229,"Name":"internal.metrics.executorCpuTime","Update":5120000,"Value":5120000,"Internal":true,"Count Failed Values":true},{"ID":1228,"Name":"internal.metrics.executorRunTime","Update":6,"Value":6,"Internal":true,"Count Failed Values":true},{"ID":1227,"Name":"internal.metrics.executorDeserializeCpuTime","Update":2116000,"Value":2116000,"Internal":true,"Count Failed Values":true},{"ID":1226,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":2116000,"Executor Run Time":6,"Executor CPU Time":5120000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":43,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":40,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":185,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"405\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[184],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":183,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"401\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[182],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":184,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"404\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[183],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":182,"Name":"FileScanRDD","Scope":"{\"id\":\"401\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344516590,"Completion Time":1629344516609,"Accumulables":[{"ID":1222,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1228,"Name":"internal.metrics.executorRunTime","Value":6,"Internal":true,"Count Failed Values":true},{"ID":1227,"Name":"internal.metrics.executorDeserializeCpuTime","Value":2116000,"Internal":true,"Count Failed Values":true},{"ID":1221,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1248,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1230,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1226,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":1247,"Name":"internal.metrics.input.bytesRead","Value":43,"Internal":true,"Count Failed Values":true},{"ID":1229,"Name":"internal.metrics.executorCpuTime","Value":5120000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":40,"Completion Time":1629344516609,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":20,"time":1629344516609}
{"Event":"SparkListenerJobStart","Job ID":41,"Submission Time":1629344516669,"Stage Infos":[{"Stage ID":41,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":190,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"414\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[189],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":189,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"413\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[188],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":187,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"411\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[186],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":188,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"410\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[187],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":186,"Name":"FileScanRDD","Scope":"{\"id\":\"411\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[41],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"415\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":41,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":190,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"414\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[189],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":189,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"413\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[188],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":187,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"411\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[186],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":188,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"410\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[187],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":186,"Name":"FileScanRDD","Scope":"{\"id\":\"411\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344516671,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"415\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":41,"Stage Attempt ID":0,"Task Info":{"Task ID":41,"Index":0,"Attempt":0,"Launch Time":1629344516678,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":41,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":41,"Index":0,"Attempt":0,"Launch Time":1629344516678,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344516689,"Failed":false,"Killed":false,"Accumulables":[{"ID":1251,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1255,"Name":"duration total (min, med, max)","Update":"4","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1278,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1277,"Name":"internal.metrics.input.bytesRead","Update":43,"Value":43,"Internal":true,"Count Failed Values":true},{"ID":1260,"Name":"internal.metrics.resultSize","Update":1446,"Value":1446,"Internal":true,"Count Failed Values":true},{"ID":1259,"Name":"internal.metrics.executorCpuTime","Update":5614000,"Value":5614000,"Internal":true,"Count Failed Values":true},{"ID":1258,"Name":"internal.metrics.executorRunTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true},{"ID":1257,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1824000,"Value":1824000,"Internal":true,"Count Failed Values":true},{"ID":1256,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1824000,"Executor Run Time":5,"Executor CPU Time":5614000,"Result Size":1446,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":43,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":41,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":190,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"414\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[189],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":189,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"413\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[188],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":187,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"411\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[186],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":188,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"410\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[187],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":186,"Name":"FileScanRDD","Scope":"{\"id\":\"411\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344516671,"Completion Time":1629344516690,"Accumulables":[{"ID":1255,"Name":"duration total (min, med, max)","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1258,"Name":"internal.metrics.executorRunTime","Value":5,"Internal":true,"Count Failed Values":true},{"ID":1278,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1260,"Name":"internal.metrics.resultSize","Value":1446,"Internal":true,"Count Failed Values":true},{"ID":1257,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1824000,"Internal":true,"Count Failed Values":true},{"ID":1251,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1277,"Name":"internal.metrics.input.bytesRead","Value":43,"Internal":true,"Count Failed Values":true},{"ID":1259,"Name":"internal.metrics.executorCpuTime","Value":5614000,"Internal":true,"Count Failed Values":true},{"ID":1256,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":41,"Completion Time":1629344516690,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":21,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#785, None)) > 0)\n      +- Project [value#785]\n         +- Relation[value#785] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#785, None)) > 0)\n      +- Project [value#785]\n         +- Relation[value#785] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#785, None)) > 0)\n      +- Relation[value#785] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#785, None)) > 0)\n   +- *(1) FileScan text [value#785] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/kancolle.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#785, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#785] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/kancolle.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/kancolle.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1283,"metricType":"sum"},{"name":"number of files","accumulatorId":1284,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1285,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1286,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1282,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1281,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344516763}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":21,"accumUpdates":[[1284,1],[1285,0]]}
{"Event":"SparkListenerJobStart","Job ID":42,"Submission Time":1629344516822,"Stage Infos":[{"Stage ID":42,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":194,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"425\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[193],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":193,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"424\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[192],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":192,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"421\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[191],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":191,"Name":"FileScanRDD","Scope":"{\"id\":\"421\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[42],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"21","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":42,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":194,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"425\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[193],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":193,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"424\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[192],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":192,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"421\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[191],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":191,"Name":"FileScanRDD","Scope":"{\"id\":\"421\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344516824,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"21","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":42,"Stage Attempt ID":0,"Task Info":{"Task ID":42,"Index":0,"Attempt":0,"Launch Time":1629344516831,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":42,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":42,"Index":0,"Attempt":0,"Launch Time":1629344516831,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344516843,"Failed":false,"Killed":false,"Accumulables":[{"ID":1282,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1283,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1309,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1308,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1291,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1290,"Name":"internal.metrics.executorCpuTime","Update":5452000,"Value":5452000,"Internal":true,"Count Failed Values":true},{"ID":1289,"Name":"internal.metrics.executorRunTime","Update":8,"Value":8,"Internal":true,"Count Failed Values":true},{"ID":1288,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1786000,"Value":1786000,"Internal":true,"Count Failed Values":true},{"ID":1287,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1786000,"Executor Run Time":8,"Executor CPU Time":5452000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":42,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":194,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"425\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[193],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":193,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"424\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[192],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":192,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"421\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[191],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":191,"Name":"FileScanRDD","Scope":"{\"id\":\"421\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344516824,"Completion Time":1629344516843,"Accumulables":[{"ID":1282,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1309,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1291,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1288,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1786000,"Internal":true,"Count Failed Values":true},{"ID":1287,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1308,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1290,"Name":"internal.metrics.executorCpuTime","Value":5452000,"Internal":true,"Count Failed Values":true},{"ID":1283,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1289,"Name":"internal.metrics.executorRunTime","Value":8,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":42,"Completion Time":1629344516843,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":21,"time":1629344516844}
{"Event":"SparkListenerJobStart","Job ID":43,"Submission Time":1629344516883,"Stage Infos":[{"Stage ID":43,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":199,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"434\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[198],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":198,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"433\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[197],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":196,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"431\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[195],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":197,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"430\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[196],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":195,"Name":"FileScanRDD","Scope":"{\"id\":\"431\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[43],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"435\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":43,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":199,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"434\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[198],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":198,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"433\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[197],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":196,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"431\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[195],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":197,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"430\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[196],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":195,"Name":"FileScanRDD","Scope":"{\"id\":\"431\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344516884,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"435\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":43,"Stage Attempt ID":0,"Task Info":{"Task ID":43,"Index":0,"Attempt":0,"Launch Time":1629344516891,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":43,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":43,"Index":0,"Attempt":0,"Launch Time":1629344516891,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344516923,"Failed":false,"Killed":false,"Accumulables":[{"ID":1312,"Name":"number of output rows","Update":"3045","Value":"3045","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1316,"Name":"duration total (min, med, max)","Update":"24","Value":"23","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1339,"Name":"internal.metrics.input.recordsRead","Update":3045,"Value":3045,"Internal":true,"Count Failed Values":true},{"ID":1338,"Name":"internal.metrics.input.bytesRead","Update":201093,"Value":201093,"Internal":true,"Count Failed Values":true},{"ID":1321,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1320,"Name":"internal.metrics.executorCpuTime","Update":24485000,"Value":24485000,"Internal":true,"Count Failed Values":true},{"ID":1319,"Name":"internal.metrics.executorRunTime","Update":26,"Value":26,"Internal":true,"Count Failed Values":true},{"ID":1318,"Name":"internal.metrics.executorDeserializeCpuTime","Update":2034000,"Value":2034000,"Internal":true,"Count Failed Values":true},{"ID":1317,"Name":"internal.metrics.executorDeserializeTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":3,"Executor Deserialize CPU Time":2034000,"Executor Run Time":26,"Executor CPU Time":24485000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":201093,"Records Read":3045},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":43,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":199,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"434\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[198],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":198,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"433\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[197],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":196,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"431\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[195],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":197,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"430\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[196],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":195,"Name":"FileScanRDD","Scope":"{\"id\":\"431\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344516884,"Completion Time":1629344516923,"Accumulables":[{"ID":1318,"Name":"internal.metrics.executorDeserializeCpuTime","Value":2034000,"Internal":true,"Count Failed Values":true},{"ID":1312,"Name":"number of output rows","Value":"3045","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1339,"Name":"internal.metrics.input.recordsRead","Value":3045,"Internal":true,"Count Failed Values":true},{"ID":1321,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1338,"Name":"internal.metrics.input.bytesRead","Value":201093,"Internal":true,"Count Failed Values":true},{"ID":1320,"Name":"internal.metrics.executorCpuTime","Value":24485000,"Internal":true,"Count Failed Values":true},{"ID":1317,"Name":"internal.metrics.executorDeserializeTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":1319,"Name":"internal.metrics.executorRunTime","Value":26,"Internal":true,"Count Failed Values":true},{"ID":1316,"Name":"duration total (min, med, max)","Value":"23","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":43,"Completion Time":1629344516924,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":22,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#822, None)) > 0)\n      +- Project [value#822]\n         +- Relation[value#822] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#822, None)) > 0)\n      +- Project [value#822]\n         +- Relation[value#822] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#822, None)) > 0)\n      +- Relation[value#822] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#822, None)) > 0)\n   +- *(1) FileScan text [value#822] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lostark.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#822, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#822] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lostark.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lostark.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1344,"metricType":"sum"},{"name":"number of files","accumulatorId":1345,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1346,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1347,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1343,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1342,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344516977}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":22,"accumUpdates":[[1345,1],[1346,0]]}
{"Event":"SparkListenerJobStart","Job ID":44,"Submission Time":1629344517010,"Stage Infos":[{"Stage ID":44,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":203,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"445\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[202],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":202,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"444\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[201],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":200,"Name":"FileScanRDD","Scope":"{\"id\":\"441\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":201,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"441\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[200],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[44],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"22","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":44,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":203,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"445\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[202],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":202,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"444\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[201],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":200,"Name":"FileScanRDD","Scope":"{\"id\":\"441\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":201,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"441\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[200],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517010,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"22","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":44,"Stage Attempt ID":0,"Task Info":{"Task ID":44,"Index":0,"Attempt":0,"Launch Time":1629344517014,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":44,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":44,"Index":0,"Attempt":0,"Launch Time":1629344517014,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344517024,"Failed":false,"Killed":false,"Accumulables":[{"ID":1343,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1344,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1370,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1369,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1352,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1351,"Name":"internal.metrics.executorCpuTime","Update":3968000,"Value":3968000,"Internal":true,"Count Failed Values":true},{"ID":1350,"Name":"internal.metrics.executorRunTime","Update":6,"Value":6,"Internal":true,"Count Failed Values":true},{"ID":1349,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1549000,"Value":1549000,"Internal":true,"Count Failed Values":true},{"ID":1348,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1549000,"Executor Run Time":6,"Executor CPU Time":3968000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":44,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":203,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"445\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[202],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":202,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"444\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[201],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":200,"Name":"FileScanRDD","Scope":"{\"id\":\"441\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":201,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"441\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[200],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517010,"Completion Time":1629344517024,"Accumulables":[{"ID":1369,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1351,"Name":"internal.metrics.executorCpuTime","Value":3968000,"Internal":true,"Count Failed Values":true},{"ID":1348,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":1350,"Name":"internal.metrics.executorRunTime","Value":6,"Internal":true,"Count Failed Values":true},{"ID":1344,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1343,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1370,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1352,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1349,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1549000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":44,"Completion Time":1629344517025,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":22,"time":1629344517025}
{"Event":"SparkListenerJobStart","Job ID":45,"Submission Time":1629344517061,"Stage Infos":[{"Stage ID":45,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":208,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"454\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[207],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":205,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"451\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[204],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":204,"Name":"FileScanRDD","Scope":"{\"id\":\"451\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":206,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"450\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[205],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":207,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"453\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[206],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[45],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"455\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":45,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":208,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"454\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[207],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":205,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"451\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[204],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":204,"Name":"FileScanRDD","Scope":"{\"id\":\"451\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":206,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"450\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[205],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":207,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"453\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[206],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517062,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"455\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":45,"Stage Attempt ID":0,"Task Info":{"Task ID":45,"Index":0,"Attempt":0,"Launch Time":1629344517065,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":45,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":45,"Index":0,"Attempt":0,"Launch Time":1629344517065,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344517484,"Failed":false,"Killed":false,"Accumulables":[{"ID":1373,"Name":"number of output rows","Update":"66150","Value":"66150","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1377,"Name":"duration total (min, med, max)","Update":"412","Value":"411","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1400,"Name":"internal.metrics.input.recordsRead","Update":66150,"Value":66150,"Internal":true,"Count Failed Values":true},{"ID":1399,"Name":"internal.metrics.input.bytesRead","Update":4897673,"Value":4897673,"Internal":true,"Count Failed Values":true},{"ID":1383,"Name":"internal.metrics.jvmGCTime","Update":8,"Value":8,"Internal":true,"Count Failed Values":true},{"ID":1382,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":1381,"Name":"internal.metrics.executorCpuTime","Update":400792000,"Value":400792000,"Internal":true,"Count Failed Values":true},{"ID":1380,"Name":"internal.metrics.executorRunTime","Update":414,"Value":414,"Internal":true,"Count Failed Values":true},{"ID":1379,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1264000,"Value":1264000,"Internal":true,"Count Failed Values":true},{"ID":1378,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1264000,"Executor Run Time":414,"Executor CPU Time":400792000,"Result Size":1571,"JVM GC Time":8,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":4897673,"Records Read":66150},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":45,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":208,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"454\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[207],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":205,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"451\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[204],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":204,"Name":"FileScanRDD","Scope":"{\"id\":\"451\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":206,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"450\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[205],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":207,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"453\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[206],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517062,"Completion Time":1629344517484,"Accumulables":[{"ID":1378,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1399,"Name":"internal.metrics.input.bytesRead","Value":4897673,"Internal":true,"Count Failed Values":true},{"ID":1381,"Name":"internal.metrics.executorCpuTime","Value":400792000,"Internal":true,"Count Failed Values":true},{"ID":1380,"Name":"internal.metrics.executorRunTime","Value":414,"Internal":true,"Count Failed Values":true},{"ID":1383,"Name":"internal.metrics.jvmGCTime","Value":8,"Internal":true,"Count Failed Values":true},{"ID":1377,"Name":"duration total (min, med, max)","Value":"411","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1379,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1264000,"Internal":true,"Count Failed Values":true},{"ID":1373,"Name":"number of output rows","Value":"66150","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1400,"Name":"internal.metrics.input.recordsRead","Value":66150,"Internal":true,"Count Failed Values":true},{"ID":1382,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":45,"Completion Time":1629344517484,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":23,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#859, None)) > 0)\n      +- Project [value#859]\n         +- Relation[value#859] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#859, None)) > 0)\n      +- Project [value#859]\n         +- Relation[value#859] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#859, None)) > 0)\n      +- Relation[value#859] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#859, None)) > 0)\n   +- *(1) FileScan text [value#859] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/pumpitup.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#859, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#859] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/pumpitup.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/pumpitup.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1405,"metricType":"sum"},{"name":"number of files","accumulatorId":1406,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1407,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1408,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1404,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1403,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344517523}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":23,"accumUpdates":[[1406,1],[1407,0]]}
{"Event":"SparkListenerJobStart","Job ID":46,"Submission Time":1629344517547,"Stage Infos":[{"Stage ID":46,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":212,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"465\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[211],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":210,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"461\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[209],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":209,"Name":"FileScanRDD","Scope":"{\"id\":\"461\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":211,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"464\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[210],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[46],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"23","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":46,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":212,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"465\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[211],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":210,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"461\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[209],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":209,"Name":"FileScanRDD","Scope":"{\"id\":\"461\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":211,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"464\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[210],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517547,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"23","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":46,"Stage Attempt ID":0,"Task Info":{"Task ID":46,"Index":0,"Attempt":0,"Launch Time":1629344517551,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":46,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":46,"Index":0,"Attempt":0,"Launch Time":1629344517551,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344517557,"Failed":false,"Killed":false,"Accumulables":[{"ID":1404,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1405,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1431,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1430,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1413,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":1412,"Name":"internal.metrics.executorCpuTime","Update":1873000,"Value":1873000,"Internal":true,"Count Failed Values":true},{"ID":1411,"Name":"internal.metrics.executorRunTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true},{"ID":1410,"Name":"internal.metrics.executorDeserializeCpuTime","Update":791000,"Value":791000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":791000,"Executor Run Time":5,"Executor CPU Time":1873000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":46,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":212,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"465\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[211],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":210,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"461\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[209],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":209,"Name":"FileScanRDD","Scope":"{\"id\":\"461\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":211,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"464\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[210],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517547,"Completion Time":1629344517557,"Accumulables":[{"ID":1411,"Name":"internal.metrics.executorRunTime","Value":5,"Internal":true,"Count Failed Values":true},{"ID":1405,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1410,"Name":"internal.metrics.executorDeserializeCpuTime","Value":791000,"Internal":true,"Count Failed Values":true},{"ID":1404,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1431,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1413,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":1430,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1412,"Name":"internal.metrics.executorCpuTime","Value":1873000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":46,"Completion Time":1629344517557,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":23,"time":1629344517558}
{"Event":"SparkListenerJobStart","Job ID":47,"Submission Time":1629344517589,"Stage Infos":[{"Stage ID":47,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":217,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"474\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[216],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":215,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"470\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[214],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":216,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"473\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[215],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":214,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"471\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[213],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":213,"Name":"FileScanRDD","Scope":"{\"id\":\"471\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[47],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"475\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":47,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":217,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"474\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[216],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":215,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"470\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[214],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":216,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"473\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[215],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":214,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"471\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[213],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":213,"Name":"FileScanRDD","Scope":"{\"id\":\"471\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517589,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"475\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":47,"Stage Attempt ID":0,"Task Info":{"Task ID":47,"Index":0,"Attempt":0,"Launch Time":1629344517592,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":47,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":47,"Index":0,"Attempt":0,"Launch Time":1629344517592,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344517627,"Failed":false,"Killed":false,"Accumulables":[{"ID":1434,"Name":"number of output rows","Update":"4425","Value":"4425","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1438,"Name":"duration total (min, med, max)","Update":"29","Value":"28","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1461,"Name":"internal.metrics.input.recordsRead","Update":4425,"Value":4425,"Internal":true,"Count Failed Values":true},{"ID":1460,"Name":"internal.metrics.input.bytesRead","Update":300373,"Value":300373,"Internal":true,"Count Failed Values":true},{"ID":1443,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1442,"Name":"internal.metrics.executorCpuTime","Update":29244000,"Value":29244000,"Internal":true,"Count Failed Values":true},{"ID":1441,"Name":"internal.metrics.executorRunTime","Update":31,"Value":31,"Internal":true,"Count Failed Values":true},{"ID":1440,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1172000,"Value":1172000,"Internal":true,"Count Failed Values":true},{"ID":1439,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1172000,"Executor Run Time":31,"Executor CPU Time":29244000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":300373,"Records Read":4425},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":47,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":217,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"474\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[216],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":215,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"470\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[214],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":216,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"473\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[215],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":214,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"471\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[213],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":213,"Name":"FileScanRDD","Scope":"{\"id\":\"471\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517589,"Completion Time":1629344517627,"Accumulables":[{"ID":1438,"Name":"duration total (min, med, max)","Value":"28","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1441,"Name":"internal.metrics.executorRunTime","Value":31,"Internal":true,"Count Failed Values":true},{"ID":1440,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1172000,"Internal":true,"Count Failed Values":true},{"ID":1434,"Name":"number of output rows","Value":"4425","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1461,"Name":"internal.metrics.input.recordsRead","Value":4425,"Internal":true,"Count Failed Values":true},{"ID":1443,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1439,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":1460,"Name":"internal.metrics.input.bytesRead","Value":300373,"Internal":true,"Count Failed Values":true},{"ID":1442,"Name":"internal.metrics.executorCpuTime","Value":29244000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":47,"Completion Time":1629344517628,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":24,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#896, None)) > 0)\n      +- Project [value#896]\n         +- Relation[value#896] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#896, None)) > 0)\n      +- Project [value#896]\n         +- Relation[value#896] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#896, None)) > 0)\n      +- Relation[value#896] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#896, None)) > 0)\n   +- *(1) FileScan text [value#896] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/skwyverns.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#896, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#896] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/skwyverns.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/skwyverns.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1466,"metricType":"sum"},{"name":"number of files","accumulatorId":1467,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1468,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1469,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1465,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1464,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344517667}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":24,"accumUpdates":[[1467,1],[1468,0]]}
{"Event":"SparkListenerJobStart","Job ID":48,"Submission Time":1629344517690,"Stage Infos":[{"Stage ID":48,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":221,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"485\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[220],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":218,"Name":"FileScanRDD","Scope":"{\"id\":\"481\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":219,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"481\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[218],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":220,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"484\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[219],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[48],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"24","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":48,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":221,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"485\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[220],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":218,"Name":"FileScanRDD","Scope":"{\"id\":\"481\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":219,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"481\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[218],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":220,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"484\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[219],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517690,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"24","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":48,"Stage Attempt ID":0,"Task Info":{"Task ID":48,"Index":0,"Attempt":0,"Launch Time":1629344517694,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":48,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":48,"Index":0,"Attempt":0,"Launch Time":1629344517694,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344517699,"Failed":false,"Killed":false,"Accumulables":[{"ID":1465,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1466,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1492,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1491,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1474,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1473,"Name":"internal.metrics.executorCpuTime","Update":1888000,"Value":1888000,"Internal":true,"Count Failed Values":true},{"ID":1472,"Name":"internal.metrics.executorRunTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true},{"ID":1471,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1042000,"Value":1042000,"Internal":true,"Count Failed Values":true},{"ID":1470,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1042000,"Executor Run Time":2,"Executor CPU Time":1888000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":48,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":221,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"485\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[220],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":218,"Name":"FileScanRDD","Scope":"{\"id\":\"481\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":219,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"481\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[218],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":220,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"484\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[219],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517690,"Completion Time":1629344517700,"Accumulables":[{"ID":1465,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1492,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1474,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1470,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1491,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1473,"Name":"internal.metrics.executorCpuTime","Value":1888000,"Internal":true,"Count Failed Values":true},{"ID":1472,"Name":"internal.metrics.executorRunTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":1466,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1471,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1042000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":48,"Completion Time":1629344517700,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":24,"time":1629344517701}
{"Event":"SparkListenerJobStart","Job ID":49,"Submission Time":1629344517732,"Stage Infos":[{"Stage ID":49,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":226,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"494\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[225],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":225,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"493\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[224],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":224,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"490\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[223],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":223,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"491\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[222],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":222,"Name":"FileScanRDD","Scope":"{\"id\":\"491\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[49],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"495\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":49,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":226,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"494\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[225],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":225,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"493\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[224],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":224,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"490\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[223],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":223,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"491\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[222],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":222,"Name":"FileScanRDD","Scope":"{\"id\":\"491\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517733,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"495\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":49,"Stage Attempt ID":0,"Task Info":{"Task ID":49,"Index":0,"Attempt":0,"Launch Time":1629344517737,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":49,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":49,"Index":0,"Attempt":0,"Launch Time":1629344517737,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344517777,"Failed":false,"Killed":false,"Accumulables":[{"ID":1495,"Name":"number of output rows","Update":"4805","Value":"4805","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1499,"Name":"duration total (min, med, max)","Update":"35","Value":"34","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1522,"Name":"internal.metrics.input.recordsRead","Update":4805,"Value":4805,"Internal":true,"Count Failed Values":true},{"ID":1521,"Name":"internal.metrics.input.bytesRead","Update":337400,"Value":337400,"Internal":true,"Count Failed Values":true},{"ID":1504,"Name":"internal.metrics.resultSize","Update":1485,"Value":1485,"Internal":true,"Count Failed Values":true},{"ID":1503,"Name":"internal.metrics.executorCpuTime","Update":34753000,"Value":34753000,"Internal":true,"Count Failed Values":true},{"ID":1502,"Name":"internal.metrics.executorRunTime","Update":38,"Value":38,"Internal":true,"Count Failed Values":true},{"ID":1501,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1178000,"Value":1178000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":1178000,"Executor Run Time":38,"Executor CPU Time":34753000,"Result Size":1485,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":337400,"Records Read":4805},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":49,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":226,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"494\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[225],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":225,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"493\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[224],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":224,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"490\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[223],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":223,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"491\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[222],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":222,"Name":"FileScanRDD","Scope":"{\"id\":\"491\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517733,"Completion Time":1629344517777,"Accumulables":[{"ID":1501,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1178000,"Internal":true,"Count Failed Values":true},{"ID":1521,"Name":"internal.metrics.input.bytesRead","Value":337400,"Internal":true,"Count Failed Values":true},{"ID":1503,"Name":"internal.metrics.executorCpuTime","Value":34753000,"Internal":true,"Count Failed Values":true},{"ID":1499,"Name":"duration total (min, med, max)","Value":"34","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1502,"Name":"internal.metrics.executorRunTime","Value":38,"Internal":true,"Count Failed Values":true},{"ID":1495,"Name":"number of output rows","Value":"4805","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1522,"Name":"internal.metrics.input.recordsRead","Value":4805,"Internal":true,"Count Failed Values":true},{"ID":1504,"Name":"internal.metrics.resultSize","Value":1485,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":49,"Completion Time":1629344517777,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":25,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#933, None)) > 0)\n      +- Project [value#933]\n         +- Relation[value#933] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#933, None)) > 0)\n      +- Project [value#933]\n         +- Relation[value#933] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#933, None)) > 0)\n      +- Relation[value#933] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#933, None)) > 0)\n   +- *(1) FileScan text [value#933] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/arbeit.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#933, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#933] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/arbeit.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/arbeit.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1527,"metricType":"sum"},{"name":"number of files","accumulatorId":1528,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1529,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1530,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1526,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1525,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344517828}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":25,"accumUpdates":[[1528,1],[1529,0]]}
{"Event":"SparkListenerJobStart","Job ID":50,"Submission Time":1629344517854,"Stage Infos":[{"Stage ID":50,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":230,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"505\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[229],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":227,"Name":"FileScanRDD","Scope":"{\"id\":\"501\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":228,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"501\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[227],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":229,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"504\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[228],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[50],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"25","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":50,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":230,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"505\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[229],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":227,"Name":"FileScanRDD","Scope":"{\"id\":\"501\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":228,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"501\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[227],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":229,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"504\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[228],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517854,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"25","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":50,"Stage Attempt ID":0,"Task Info":{"Task ID":50,"Index":0,"Attempt":0,"Launch Time":1629344517858,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":50,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":50,"Index":0,"Attempt":0,"Launch Time":1629344517858,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344517864,"Failed":false,"Killed":false,"Accumulables":[{"ID":1526,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1527,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1553,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1552,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1535,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1534,"Name":"internal.metrics.executorCpuTime","Update":1941000,"Value":1941000,"Internal":true,"Count Failed Values":true},{"ID":1533,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":1532,"Name":"internal.metrics.executorDeserializeCpuTime","Update":787000,"Value":787000,"Internal":true,"Count Failed Values":true},{"ID":1531,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":787000,"Executor Run Time":3,"Executor CPU Time":1941000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":50,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":230,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"505\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[229],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":227,"Name":"FileScanRDD","Scope":"{\"id\":\"501\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":228,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"501\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[227],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":229,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"504\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[228],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517854,"Completion Time":1629344517864,"Accumulables":[{"ID":1527,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1533,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":1532,"Name":"internal.metrics.executorDeserializeCpuTime","Value":787000,"Internal":true,"Count Failed Values":true},{"ID":1526,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1553,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1535,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1531,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1552,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1534,"Name":"internal.metrics.executorCpuTime","Value":1941000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":50,"Completion Time":1629344517864,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":25,"time":1629344517865}
{"Event":"SparkListenerJobStart","Job ID":51,"Submission Time":1629344517900,"Stage Infos":[{"Stage ID":51,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":235,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"514\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[234],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":233,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"510\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[232],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":231,"Name":"FileScanRDD","Scope":"{\"id\":\"511\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":232,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"511\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[231],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":234,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"513\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[233],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[51],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"515\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":51,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":235,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"514\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[234],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":233,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"510\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[232],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":231,"Name":"FileScanRDD","Scope":"{\"id\":\"511\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":232,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"511\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[231],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":234,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"513\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[233],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517902,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"515\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":51,"Stage Attempt ID":0,"Task Info":{"Task ID":51,"Index":0,"Attempt":0,"Launch Time":1629344517908,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":51,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":51,"Index":0,"Attempt":0,"Launch Time":1629344517908,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344517949,"Failed":false,"Killed":false,"Accumulables":[{"ID":1556,"Name":"number of output rows","Update":"5053","Value":"5053","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1560,"Name":"duration total (min, med, max)","Update":"36","Value":"35","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1583,"Name":"internal.metrics.input.recordsRead","Update":5053,"Value":5053,"Internal":true,"Count Failed Values":true},{"ID":1582,"Name":"internal.metrics.input.bytesRead","Update":370251,"Value":370251,"Internal":true,"Count Failed Values":true},{"ID":1565,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1564,"Name":"internal.metrics.executorCpuTime","Update":35329000,"Value":35329000,"Internal":true,"Count Failed Values":true},{"ID":1563,"Name":"internal.metrics.executorRunTime","Update":38,"Value":38,"Internal":true,"Count Failed Values":true},{"ID":1562,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1141000,"Value":1141000,"Internal":true,"Count Failed Values":true},{"ID":1561,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1141000,"Executor Run Time":38,"Executor CPU Time":35329000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":370251,"Records Read":5053},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":51,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":235,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"514\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[234],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":233,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"510\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[232],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":231,"Name":"FileScanRDD","Scope":"{\"id\":\"511\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":232,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"511\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[231],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":234,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"513\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[233],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344517902,"Completion Time":1629344517949,"Accumulables":[{"ID":1560,"Name":"duration total (min, med, max)","Value":"35","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1563,"Name":"internal.metrics.executorRunTime","Value":38,"Internal":true,"Count Failed Values":true},{"ID":1583,"Name":"internal.metrics.input.recordsRead","Value":5053,"Internal":true,"Count Failed Values":true},{"ID":1562,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1141000,"Internal":true,"Count Failed Values":true},{"ID":1556,"Name":"number of output rows","Value":"5053","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1565,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1582,"Name":"internal.metrics.input.bytesRead","Value":370251,"Internal":true,"Count Failed Values":true},{"ID":1564,"Name":"internal.metrics.executorCpuTime","Value":35329000,"Internal":true,"Count Failed Values":true},{"ID":1561,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":51,"Completion Time":1629344517949,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":26,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#970, None)) > 0)\n      +- Project [value#970]\n         +- Relation[value#970] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#970, None)) > 0)\n      +- Project [value#970]\n         +- Relation[value#970] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#970, None)) > 0)\n      +- Relation[value#970] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#970, None)) > 0)\n   +- *(1) FileScan text [value#970] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/akb48.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#970, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#970] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/akb48.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/akb48.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1588,"metricType":"sum"},{"name":"number of files","accumulatorId":1589,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1590,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1591,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1587,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1586,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344517989}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":26,"accumUpdates":[[1589,1],[1590,0]]}
{"Event":"SparkListenerJobStart","Job ID":52,"Submission Time":1629344518020,"Stage Infos":[{"Stage ID":52,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":239,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"525\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[238],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":238,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"524\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[237],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":236,"Name":"FileScanRDD","Scope":"{\"id\":\"521\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":237,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"521\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[236],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[52],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"26","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":52,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":239,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"525\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[238],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":238,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"524\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[237],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":236,"Name":"FileScanRDD","Scope":"{\"id\":\"521\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":237,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"521\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[236],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518020,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"26","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":52,"Stage Attempt ID":0,"Task Info":{"Task ID":52,"Index":0,"Attempt":0,"Launch Time":1629344518023,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":52,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":52,"Index":0,"Attempt":0,"Launch Time":1629344518023,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344518027,"Failed":false,"Killed":false,"Accumulables":[{"ID":1587,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1588,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1614,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1613,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1596,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1595,"Name":"internal.metrics.executorCpuTime","Update":1512000,"Value":1512000,"Internal":true,"Count Failed Values":true},{"ID":1594,"Name":"internal.metrics.executorRunTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1593,"Name":"internal.metrics.executorDeserializeCpuTime","Update":804000,"Value":804000,"Internal":true,"Count Failed Values":true},{"ID":1592,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":804000,"Executor Run Time":1,"Executor CPU Time":1512000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":52,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":239,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"525\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[238],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":238,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"524\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[237],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":236,"Name":"FileScanRDD","Scope":"{\"id\":\"521\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":237,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"521\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[236],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518020,"Completion Time":1629344518027,"Accumulables":[{"ID":1587,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1614,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1596,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1593,"Name":"internal.metrics.executorDeserializeCpuTime","Value":804000,"Internal":true,"Count Failed Values":true},{"ID":1592,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1613,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1595,"Name":"internal.metrics.executorCpuTime","Value":1512000,"Internal":true,"Count Failed Values":true},{"ID":1594,"Name":"internal.metrics.executorRunTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1588,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":52,"Completion Time":1629344518028,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":26,"time":1629344518028}
{"Event":"SparkListenerJobStart","Job ID":53,"Submission Time":1629344518058,"Stage Infos":[{"Stage ID":53,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":244,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"534\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[243],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":241,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"531\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[240],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":240,"Name":"FileScanRDD","Scope":"{\"id\":\"531\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":243,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"533\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[242],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":242,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"530\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[241],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[53],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"535\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":53,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":244,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"534\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[243],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":241,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"531\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[240],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":240,"Name":"FileScanRDD","Scope":"{\"id\":\"531\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":243,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"533\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[242],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":242,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"530\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[241],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518058,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"535\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":53,"Stage Attempt ID":0,"Task Info":{"Task ID":53,"Index":0,"Attempt":0,"Launch Time":1629344518061,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":53,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":53,"Index":0,"Attempt":0,"Launch Time":1629344518061,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344518099,"Failed":false,"Killed":false,"Accumulables":[{"ID":1617,"Name":"number of output rows","Update":"4965","Value":"4965","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1621,"Name":"duration total (min, med, max)","Update":"31","Value":"30","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1644,"Name":"internal.metrics.input.recordsRead","Update":4965,"Value":4965,"Internal":true,"Count Failed Values":true},{"ID":1643,"Name":"internal.metrics.input.bytesRead","Update":348514,"Value":348514,"Internal":true,"Count Failed Values":true},{"ID":1628,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1626,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":1625,"Name":"internal.metrics.executorCpuTime","Update":32883000,"Value":32883000,"Internal":true,"Count Failed Values":true},{"ID":1624,"Name":"internal.metrics.executorRunTime","Update":33,"Value":33,"Internal":true,"Count Failed Values":true},{"ID":1623,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1351000,"Value":1351000,"Internal":true,"Count Failed Values":true},{"ID":1622,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1351000,"Executor Run Time":33,"Executor CPU Time":32883000,"Result Size":1571,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":348514,"Records Read":4965},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":53,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":244,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"534\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[243],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":241,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"531\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[240],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":240,"Name":"FileScanRDD","Scope":"{\"id\":\"531\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":243,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"533\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[242],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":242,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"530\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[241],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518058,"Completion Time":1629344518100,"Accumulables":[{"ID":1623,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1351000,"Internal":true,"Count Failed Values":true},{"ID":1617,"Name":"number of output rows","Value":"4965","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1644,"Name":"internal.metrics.input.recordsRead","Value":4965,"Internal":true,"Count Failed Values":true},{"ID":1626,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true},{"ID":1643,"Name":"internal.metrics.input.bytesRead","Value":348514,"Internal":true,"Count Failed Values":true},{"ID":1628,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1622,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1625,"Name":"internal.metrics.executorCpuTime","Value":32883000,"Internal":true,"Count Failed Values":true},{"ID":1624,"Name":"internal.metrics.executorRunTime","Value":33,"Internal":true,"Count Failed Values":true},{"ID":1621,"Name":"duration total (min, med, max)","Value":"30","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":53,"Completion Time":1629344518100,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":27,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1007, None)) > 0)\n      +- Project [value#1007]\n         +- Relation[value#1007] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1007, None)) > 0)\n      +- Project [value#1007]\n         +- Relation[value#1007] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1007, None)) > 0)\n      +- Relation[value#1007] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1007, None)) > 0)\n   +- *(1) FileScan text [value#1007] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/typemoon.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1007, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1007] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/typemoon.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/typemoon.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1649,"metricType":"sum"},{"name":"number of files","accumulatorId":1650,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1651,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1652,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1648,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1647,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344518148}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":27,"accumUpdates":[[1650,1],[1651,0]]}
{"Event":"SparkListenerJobStart","Job ID":54,"Submission Time":1629344518178,"Stage Infos":[{"Stage ID":54,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":248,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"545\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[247],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":247,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"544\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[246],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":246,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"541\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[245],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":245,"Name":"FileScanRDD","Scope":"{\"id\":\"541\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[54],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"27","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":54,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":248,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"545\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[247],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":247,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"544\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[246],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":246,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"541\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[245],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":245,"Name":"FileScanRDD","Scope":"{\"id\":\"541\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518179,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"27","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":54,"Stage Attempt ID":0,"Task Info":{"Task ID":54,"Index":0,"Attempt":0,"Launch Time":1629344518185,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":54,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":54,"Index":0,"Attempt":0,"Launch Time":1629344518185,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344518191,"Failed":false,"Killed":false,"Accumulables":[{"ID":1648,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1649,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1675,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1674,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1657,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1656,"Name":"internal.metrics.executorCpuTime","Update":1780000,"Value":1780000,"Internal":true,"Count Failed Values":true},{"ID":1655,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":1654,"Name":"internal.metrics.executorDeserializeCpuTime","Update":892000,"Value":892000,"Internal":true,"Count Failed Values":true},{"ID":1653,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":892000,"Executor Run Time":3,"Executor CPU Time":1780000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":54,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":248,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"545\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[247],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":247,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"544\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[246],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":246,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"541\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[245],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":245,"Name":"FileScanRDD","Scope":"{\"id\":\"541\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518179,"Completion Time":1629344518191,"Accumulables":[{"ID":1674,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1656,"Name":"internal.metrics.executorCpuTime","Value":1780000,"Internal":true,"Count Failed Values":true},{"ID":1653,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1655,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":1649,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1675,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1657,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1654,"Name":"internal.metrics.executorDeserializeCpuTime","Value":892000,"Internal":true,"Count Failed Values":true},{"ID":1648,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":54,"Completion Time":1629344518192,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":27,"time":1629344518192}
{"Event":"SparkListenerJobStart","Job ID":55,"Submission Time":1629344518235,"Stage Infos":[{"Stage ID":55,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":253,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"554\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[252],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":249,"Name":"FileScanRDD","Scope":"{\"id\":\"551\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":250,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"551\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[249],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":251,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"550\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[250],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":252,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"553\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[251],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[55],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"555\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":55,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":253,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"554\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[252],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":249,"Name":"FileScanRDD","Scope":"{\"id\":\"551\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":250,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"551\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[249],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":251,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"550\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[250],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":252,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"553\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[251],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518236,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"555\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":55,"Stage Attempt ID":0,"Task Info":{"Task ID":55,"Index":0,"Attempt":0,"Launch Time":1629344518241,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":55,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":55,"Index":0,"Attempt":0,"Launch Time":1629344518241,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344518359,"Failed":false,"Killed":false,"Accumulables":[{"ID":1678,"Name":"number of output rows","Update":"12569","Value":"12569","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1682,"Name":"duration total (min, med, max)","Update":"113","Value":"112","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1705,"Name":"internal.metrics.input.recordsRead","Update":12569,"Value":12569,"Internal":true,"Count Failed Values":true},{"ID":1704,"Name":"internal.metrics.input.bytesRead","Update":905859,"Value":905859,"Internal":true,"Count Failed Values":true},{"ID":1689,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1687,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":1686,"Name":"internal.metrics.executorCpuTime","Update":111846000,"Value":111846000,"Internal":true,"Count Failed Values":true},{"ID":1685,"Name":"internal.metrics.executorRunTime","Update":114,"Value":114,"Internal":true,"Count Failed Values":true},{"ID":1684,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1333000,"Value":1333000,"Internal":true,"Count Failed Values":true},{"ID":1683,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1333000,"Executor Run Time":114,"Executor CPU Time":111846000,"Result Size":1571,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":905859,"Records Read":12569},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":55,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":253,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"554\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[252],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":249,"Name":"FileScanRDD","Scope":"{\"id\":\"551\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":250,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"551\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[249],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":251,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"550\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[250],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":252,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"553\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[251],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518236,"Completion Time":1629344518360,"Accumulables":[{"ID":1689,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1683,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":1704,"Name":"internal.metrics.input.bytesRead","Value":905859,"Internal":true,"Count Failed Values":true},{"ID":1686,"Name":"internal.metrics.executorCpuTime","Value":111846000,"Internal":true,"Count Failed Values":true},{"ID":1682,"Name":"duration total (min, med, max)","Value":"112","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1685,"Name":"internal.metrics.executorRunTime","Value":114,"Internal":true,"Count Failed Values":true},{"ID":1684,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1333000,"Internal":true,"Count Failed Values":true},{"ID":1678,"Name":"number of output rows","Value":"12569","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1705,"Name":"internal.metrics.input.recordsRead","Value":12569,"Internal":true,"Count Failed Values":true},{"ID":1687,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":55,"Completion Time":1629344518360,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":28,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1044, None)) > 0)\n      +- Project [value#1044]\n         +- Relation[value#1044] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1044, None)) > 0)\n      +- Project [value#1044]\n         +- Relation[value#1044] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1044, None)) > 0)\n      +- Relation[value#1044] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1044, None)) > 0)\n   +- *(1) FileScan text [value#1044] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/game_mabinog..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1044, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1044] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/game_mabinog..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/game_mabinogi1.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1710,"metricType":"sum"},{"name":"number of files","accumulatorId":1711,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1712,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1713,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1709,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1708,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344518416}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":28,"accumUpdates":[[1711,1],[1712,0]]}
{"Event":"SparkListenerJobStart","Job ID":56,"Submission Time":1629344518446,"Stage Infos":[{"Stage ID":56,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":257,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"565\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[256],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":255,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"561\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[254],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":256,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"564\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[255],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":254,"Name":"FileScanRDD","Scope":"{\"id\":\"561\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[56],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"28","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":56,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":257,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"565\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[256],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":255,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"561\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[254],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":256,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"564\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[255],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":254,"Name":"FileScanRDD","Scope":"{\"id\":\"561\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518447,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"28","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":56,"Stage Attempt ID":0,"Task Info":{"Task ID":56,"Index":0,"Attempt":0,"Launch Time":1629344518452,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":56,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":56,"Index":0,"Attempt":0,"Launch Time":1629344518452,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344518459,"Failed":false,"Killed":false,"Accumulables":[{"ID":1709,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1710,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1736,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1735,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1718,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1717,"Name":"internal.metrics.executorCpuTime","Update":2014000,"Value":2014000,"Internal":true,"Count Failed Values":true},{"ID":1716,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":1715,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1027000,"Value":1027000,"Internal":true,"Count Failed Values":true},{"ID":1714,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1027000,"Executor Run Time":3,"Executor CPU Time":2014000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":56,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":257,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"565\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[256],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":255,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"561\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[254],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":256,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"564\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[255],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":254,"Name":"FileScanRDD","Scope":"{\"id\":\"561\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518447,"Completion Time":1629344518459,"Accumulables":[{"ID":1716,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":1710,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1715,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1027000,"Internal":true,"Count Failed Values":true},{"ID":1709,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1736,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1718,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1735,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1717,"Name":"internal.metrics.executorCpuTime","Value":2014000,"Internal":true,"Count Failed Values":true},{"ID":1714,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":56,"Completion Time":1629344518459,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":28,"time":1629344518460}
{"Event":"SparkListenerJobStart","Job ID":57,"Submission Time":1629344518496,"Stage Infos":[{"Stage ID":57,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":262,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"574\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[261],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":261,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"573\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[260],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":259,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"571\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[258],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":260,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"570\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[259],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":258,"Name":"FileScanRDD","Scope":"{\"id\":\"571\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[57],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"575\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":57,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":262,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"574\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[261],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":261,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"573\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[260],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":259,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"571\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[258],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":260,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"570\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[259],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":258,"Name":"FileScanRDD","Scope":"{\"id\":\"571\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518496,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"575\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":57,"Stage Attempt ID":0,"Task Info":{"Task ID":57,"Index":0,"Attempt":0,"Launch Time":1629344518502,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":57,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":57,"Index":0,"Attempt":0,"Launch Time":1629344518502,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344518560,"Failed":false,"Killed":false,"Accumulables":[{"ID":1739,"Name":"number of output rows","Update":"5788","Value":"5788","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1743,"Name":"duration total (min, med, max)","Update":"53","Value":"52","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1766,"Name":"internal.metrics.input.recordsRead","Update":5788,"Value":5788,"Internal":true,"Count Failed Values":true},{"ID":1765,"Name":"internal.metrics.input.bytesRead","Update":412615,"Value":412615,"Internal":true,"Count Failed Values":true},{"ID":1749,"Name":"internal.metrics.jvmGCTime","Update":8,"Value":8,"Internal":true,"Count Failed Values":true},{"ID":1748,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":1747,"Name":"internal.metrics.executorCpuTime","Update":44761000,"Value":44761000,"Internal":true,"Count Failed Values":true},{"ID":1746,"Name":"internal.metrics.executorRunTime","Update":55,"Value":55,"Internal":true,"Count Failed Values":true},{"ID":1745,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1337000,"Value":1337000,"Internal":true,"Count Failed Values":true},{"ID":1744,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1337000,"Executor Run Time":55,"Executor CPU Time":44761000,"Result Size":1571,"JVM GC Time":8,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":412615,"Records Read":5788},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":57,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":262,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"574\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[261],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":261,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"573\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[260],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":259,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"571\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[258],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":260,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"570\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[259],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":258,"Name":"FileScanRDD","Scope":"{\"id\":\"571\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518496,"Completion Time":1629344518560,"Accumulables":[{"ID":1743,"Name":"duration total (min, med, max)","Value":"52","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1746,"Name":"internal.metrics.executorRunTime","Value":55,"Internal":true,"Count Failed Values":true},{"ID":1739,"Name":"number of output rows","Value":"5788","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1766,"Name":"internal.metrics.input.recordsRead","Value":5788,"Internal":true,"Count Failed Values":true},{"ID":1748,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true},{"ID":1745,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1337000,"Internal":true,"Count Failed Values":true},{"ID":1744,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1765,"Name":"internal.metrics.input.bytesRead","Value":412615,"Internal":true,"Count Failed Values":true},{"ID":1747,"Name":"internal.metrics.executorCpuTime","Value":44761000,"Internal":true,"Count Failed Values":true},{"ID":1749,"Name":"internal.metrics.jvmGCTime","Value":8,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":57,"Completion Time":1629344518560,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":29,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1081, None)) > 0)\n      +- Project [value#1081]\n         +- Relation[value#1081] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1081, None)) > 0)\n      +- Project [value#1081]\n         +- Relation[value#1081] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1081, None)) > 0)\n      +- Relation[value#1081] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1081, None)) > 0)\n   +- *(1) FileScan text [value#1081] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/pridepc_new4..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1081, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1081] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/pridepc_new4..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/pridepc_new4.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1771,"metricType":"sum"},{"name":"number of files","accumulatorId":1772,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1773,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1774,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1770,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1769,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344518603}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":29,"accumUpdates":[[1772,1],[1773,0]]}
{"Event":"SparkListenerJobStart","Job ID":58,"Submission Time":1629344518627,"Stage Infos":[{"Stage ID":58,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":266,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"585\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[265],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":265,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"584\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[264],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":263,"Name":"FileScanRDD","Scope":"{\"id\":\"581\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":264,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"581\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[263],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[58],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"29","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":58,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":266,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"585\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[265],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":265,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"584\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[264],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":263,"Name":"FileScanRDD","Scope":"{\"id\":\"581\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":264,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"581\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[263],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518627,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"29","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":58,"Stage Attempt ID":0,"Task Info":{"Task ID":58,"Index":0,"Attempt":0,"Launch Time":1629344518630,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":58,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":58,"Index":0,"Attempt":0,"Launch Time":1629344518630,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344518636,"Failed":false,"Killed":false,"Accumulables":[{"ID":1770,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1771,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1797,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1796,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1779,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":1778,"Name":"internal.metrics.executorCpuTime","Update":1663000,"Value":1663000,"Internal":true,"Count Failed Values":true},{"ID":1777,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":1776,"Name":"internal.metrics.executorDeserializeCpuTime","Update":754000,"Value":754000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":754000,"Executor Run Time":4,"Executor CPU Time":1663000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":58,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":266,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"585\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[265],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":265,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"584\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[264],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":263,"Name":"FileScanRDD","Scope":"{\"id\":\"581\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":264,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"581\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[263],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518627,"Completion Time":1629344518636,"Accumulables":[{"ID":1770,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1797,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1779,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":1796,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1778,"Name":"internal.metrics.executorCpuTime","Value":1663000,"Internal":true,"Count Failed Values":true},{"ID":1777,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":1771,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1776,"Name":"internal.metrics.executorDeserializeCpuTime","Value":754000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":58,"Completion Time":1629344518636,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":29,"time":1629344518636}
{"Event":"SparkListenerJobStart","Job ID":59,"Submission Time":1629344518667,"Stage Infos":[{"Stage ID":59,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":271,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"594\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[270],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":268,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"591\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[267],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":270,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"593\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[269],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":269,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"590\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[268],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":267,"Name":"FileScanRDD","Scope":"{\"id\":\"591\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[59],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"595\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":59,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":271,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"594\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[270],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":268,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"591\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[267],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":270,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"593\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[269],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":269,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"590\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[268],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":267,"Name":"FileScanRDD","Scope":"{\"id\":\"591\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518667,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"595\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":59,"Stage Attempt ID":0,"Task Info":{"Task ID":59,"Index":0,"Attempt":0,"Launch Time":1629344518670,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":59,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":59,"Index":0,"Attempt":0,"Launch Time":1629344518670,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344518739,"Failed":false,"Killed":false,"Accumulables":[{"ID":1800,"Name":"number of output rows","Update":"10327","Value":"10327","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1804,"Name":"duration total (min, med, max)","Update":"64","Value":"63","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1827,"Name":"internal.metrics.input.recordsRead","Update":10327,"Value":10327,"Internal":true,"Count Failed Values":true},{"ID":1826,"Name":"internal.metrics.input.bytesRead","Update":751242,"Value":751242,"Internal":true,"Count Failed Values":true},{"ID":1809,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1808,"Name":"internal.metrics.executorCpuTime","Update":63393000,"Value":63393000,"Internal":true,"Count Failed Values":true},{"ID":1807,"Name":"internal.metrics.executorRunTime","Update":65,"Value":65,"Internal":true,"Count Failed Values":true},{"ID":1806,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1162000,"Value":1162000,"Internal":true,"Count Failed Values":true},{"ID":1805,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1162000,"Executor Run Time":65,"Executor CPU Time":63393000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":751242,"Records Read":10327},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":59,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":271,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"594\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[270],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":268,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"591\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[267],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":270,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"593\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[269],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":269,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"590\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[268],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":267,"Name":"FileScanRDD","Scope":"{\"id\":\"591\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518667,"Completion Time":1629344518739,"Accumulables":[{"ID":1806,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1162000,"Internal":true,"Count Failed Values":true},{"ID":1826,"Name":"internal.metrics.input.bytesRead","Value":751242,"Internal":true,"Count Failed Values":true},{"ID":1808,"Name":"internal.metrics.executorCpuTime","Value":63393000,"Internal":true,"Count Failed Values":true},{"ID":1805,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1804,"Name":"duration total (min, med, max)","Value":"63","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1807,"Name":"internal.metrics.executorRunTime","Value":65,"Internal":true,"Count Failed Values":true},{"ID":1800,"Name":"number of output rows","Value":"10327","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1827,"Name":"internal.metrics.input.recordsRead","Value":10327,"Internal":true,"Count Failed Values":true},{"ID":1809,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":59,"Completion Time":1629344518739,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":30,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1118, None)) > 0)\n      +- Project [value#1118]\n         +- Relation[value#1118] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1118, None)) > 0)\n      +- Project [value#1118]\n         +- Relation[value#1118] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1118, None)) > 0)\n      +- Relation[value#1118] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1118, None)) > 0)\n   +- *(1) FileScan text [value#1118] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/fashion_new1..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1118, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1118] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/fashion_new1..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/fashion_new1.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1832,"metricType":"sum"},{"name":"number of files","accumulatorId":1833,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1834,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1835,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1831,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1830,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344518777}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":30,"accumUpdates":[[1833,1],[1834,0]]}
{"Event":"SparkListenerJobStart","Job ID":60,"Submission Time":1629344518803,"Stage Infos":[{"Stage ID":60,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":275,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"605\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[274],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":272,"Name":"FileScanRDD","Scope":"{\"id\":\"601\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":274,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"604\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[273],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":273,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"601\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[272],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[60],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"30","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":60,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":275,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"605\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[274],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":272,"Name":"FileScanRDD","Scope":"{\"id\":\"601\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":274,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"604\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[273],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":273,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"601\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[272],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518804,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"30","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":60,"Stage Attempt ID":0,"Task Info":{"Task ID":60,"Index":0,"Attempt":0,"Launch Time":1629344518812,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":60,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":60,"Index":0,"Attempt":0,"Launch Time":1629344518812,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344518817,"Failed":false,"Killed":false,"Accumulables":[{"ID":1831,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1832,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1858,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1857,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1840,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":1839,"Name":"internal.metrics.executorCpuTime","Update":1696000,"Value":1696000,"Internal":true,"Count Failed Values":true},{"ID":1838,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":1837,"Name":"internal.metrics.executorDeserializeCpuTime","Update":760000,"Value":760000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":760000,"Executor Run Time":3,"Executor CPU Time":1696000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":60,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":275,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"605\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[274],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":272,"Name":"FileScanRDD","Scope":"{\"id\":\"601\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":274,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"604\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[273],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":273,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"601\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[272],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518804,"Completion Time":1629344518818,"Accumulables":[{"ID":1832,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1838,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":1837,"Name":"internal.metrics.executorDeserializeCpuTime","Value":760000,"Internal":true,"Count Failed Values":true},{"ID":1831,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1858,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1840,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":1857,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1839,"Name":"internal.metrics.executorCpuTime","Value":1696000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":60,"Completion Time":1629344518818,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":30,"time":1629344518819}
{"Event":"SparkListenerJobStart","Job ID":61,"Submission Time":1629344518850,"Stage Infos":[{"Stage ID":61,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":280,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"614\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[279],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":279,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"613\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[278],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":278,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"610\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[277],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":276,"Name":"FileScanRDD","Scope":"{\"id\":\"611\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":277,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"611\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[276],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[61],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"615\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":61,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":280,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"614\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[279],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":279,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"613\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[278],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":278,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"610\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[277],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":276,"Name":"FileScanRDD","Scope":"{\"id\":\"611\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":277,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"611\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[276],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518850,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"615\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":61,"Stage Attempt ID":0,"Task Info":{"Task ID":61,"Index":0,"Attempt":0,"Launch Time":1629344518853,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":61,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":61,"Index":0,"Attempt":0,"Launch Time":1629344518853,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344518896,"Failed":false,"Killed":false,"Accumulables":[{"ID":1861,"Name":"number of output rows","Update":"5693","Value":"5693","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1865,"Name":"duration total (min, med, max)","Update":"38","Value":"37","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1888,"Name":"internal.metrics.input.recordsRead","Update":5693,"Value":5693,"Internal":true,"Count Failed Values":true},{"ID":1887,"Name":"internal.metrics.input.bytesRead","Update":370457,"Value":370457,"Internal":true,"Count Failed Values":true},{"ID":1870,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1869,"Name":"internal.metrics.executorCpuTime","Update":37938000,"Value":37938000,"Internal":true,"Count Failed Values":true},{"ID":1868,"Name":"internal.metrics.executorRunTime","Update":40,"Value":40,"Internal":true,"Count Failed Values":true},{"ID":1867,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1099000,"Value":1099000,"Internal":true,"Count Failed Values":true},{"ID":1866,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1099000,"Executor Run Time":40,"Executor CPU Time":37938000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":370457,"Records Read":5693},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":61,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":280,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"614\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[279],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":279,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"613\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[278],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":278,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"610\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[277],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":276,"Name":"FileScanRDD","Scope":"{\"id\":\"611\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":277,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"611\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[276],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518850,"Completion Time":1629344518897,"Accumulables":[{"ID":1868,"Name":"internal.metrics.executorRunTime","Value":40,"Internal":true,"Count Failed Values":true},{"ID":1865,"Name":"duration total (min, med, max)","Value":"37","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1867,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1099000,"Internal":true,"Count Failed Values":true},{"ID":1861,"Name":"number of output rows","Value":"5693","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1888,"Name":"internal.metrics.input.recordsRead","Value":5693,"Internal":true,"Count Failed Values":true},{"ID":1870,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1887,"Name":"internal.metrics.input.bytesRead","Value":370457,"Internal":true,"Count Failed Values":true},{"ID":1869,"Name":"internal.metrics.executorCpuTime","Value":37938000,"Internal":true,"Count Failed Values":true},{"ID":1866,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":61,"Completion Time":1629344518897,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":31,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1155, None)) > 0)\n      +- Project [value#1155]\n         +- Relation[value#1155] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1155, None)) > 0)\n      +- Project [value#1155]\n         +- Relation[value#1155] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1155, None)) > 0)\n      +- Relation[value#1155] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1155, None)) > 0)\n   +- *(1) FileScan text [value#1155] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/plastic_s.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1155, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1155] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/plastic_s.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/plastic_s.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1893,"metricType":"sum"},{"name":"number of files","accumulatorId":1894,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1895,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1896,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1892,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1891,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344518934}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":31,"accumUpdates":[[1894,1],[1895,0]]}
{"Event":"SparkListenerJobStart","Job ID":62,"Submission Time":1629344518958,"Stage Infos":[{"Stage ID":62,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":284,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"625\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[283],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":281,"Name":"FileScanRDD","Scope":"{\"id\":\"621\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":283,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"624\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[282],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":282,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"621\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[281],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[62],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"31","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":62,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":284,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"625\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[283],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":281,"Name":"FileScanRDD","Scope":"{\"id\":\"621\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":283,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"624\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[282],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":282,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"621\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[281],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518958,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"31","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":62,"Stage Attempt ID":0,"Task Info":{"Task ID":62,"Index":0,"Attempt":0,"Launch Time":1629344518961,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":62,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":62,"Index":0,"Attempt":0,"Launch Time":1629344518961,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344518967,"Failed":false,"Killed":false,"Accumulables":[{"ID":1892,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1893,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1919,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1918,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1901,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1900,"Name":"internal.metrics.executorCpuTime","Update":1699000,"Value":1699000,"Internal":true,"Count Failed Values":true},{"ID":1899,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":1898,"Name":"internal.metrics.executorDeserializeCpuTime","Update":683000,"Value":683000,"Internal":true,"Count Failed Values":true},{"ID":1897,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":683000,"Executor Run Time":4,"Executor CPU Time":1699000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":62,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":284,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"625\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[283],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":281,"Name":"FileScanRDD","Scope":"{\"id\":\"621\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":283,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"624\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[282],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":282,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"621\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[281],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344518958,"Completion Time":1629344518967,"Accumulables":[{"ID":1892,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1919,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1901,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1898,"Name":"internal.metrics.executorDeserializeCpuTime","Value":683000,"Internal":true,"Count Failed Values":true},{"ID":1897,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1918,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1900,"Name":"internal.metrics.executorCpuTime","Value":1699000,"Internal":true,"Count Failed Values":true},{"ID":1899,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":1893,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":62,"Completion Time":1629344518967,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":31,"time":1629344518968}
{"Event":"SparkListenerJobStart","Job ID":63,"Submission Time":1629344519001,"Stage Infos":[{"Stage ID":63,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":289,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"634\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[288],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":285,"Name":"FileScanRDD","Scope":"{\"id\":\"631\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":287,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"630\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[286],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":286,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"631\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[285],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":288,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"633\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[287],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[63],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"635\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":63,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":289,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"634\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[288],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":285,"Name":"FileScanRDD","Scope":"{\"id\":\"631\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":287,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"630\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[286],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":286,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"631\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[285],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":288,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"633\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[287],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519002,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"635\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":63,"Stage Attempt ID":0,"Task Info":{"Task ID":63,"Index":0,"Attempt":0,"Launch Time":1629344519005,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":63,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":63,"Index":0,"Attempt":0,"Launch Time":1629344519005,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344519036,"Failed":false,"Killed":false,"Accumulables":[{"ID":1922,"Name":"number of output rows","Update":"3678","Value":"3678","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1926,"Name":"duration total (min, med, max)","Update":"25","Value":"24","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1949,"Name":"internal.metrics.input.recordsRead","Update":3678,"Value":3678,"Internal":true,"Count Failed Values":true},{"ID":1948,"Name":"internal.metrics.input.bytesRead","Update":255021,"Value":255021,"Internal":true,"Count Failed Values":true},{"ID":1931,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1930,"Name":"internal.metrics.executorCpuTime","Update":25251000,"Value":25251000,"Internal":true,"Count Failed Values":true},{"ID":1929,"Name":"internal.metrics.executorRunTime","Update":27,"Value":27,"Internal":true,"Count Failed Values":true},{"ID":1928,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1089000,"Value":1089000,"Internal":true,"Count Failed Values":true},{"ID":1927,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1089000,"Executor Run Time":27,"Executor CPU Time":25251000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":255021,"Records Read":3678},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":63,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":289,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"634\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[288],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":285,"Name":"FileScanRDD","Scope":"{\"id\":\"631\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":287,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"630\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[286],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":286,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"631\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[285],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":288,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"633\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[287],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519002,"Completion Time":1629344519037,"Accumulables":[{"ID":1928,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1089000,"Internal":true,"Count Failed Values":true},{"ID":1922,"Name":"number of output rows","Value":"3678","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1949,"Name":"internal.metrics.input.recordsRead","Value":3678,"Internal":true,"Count Failed Values":true},{"ID":1931,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1927,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1948,"Name":"internal.metrics.input.bytesRead","Value":255021,"Internal":true,"Count Failed Values":true},{"ID":1930,"Name":"internal.metrics.executorCpuTime","Value":25251000,"Internal":true,"Count Failed Values":true},{"ID":1929,"Name":"internal.metrics.executorRunTime","Value":27,"Internal":true,"Count Failed Values":true},{"ID":1926,"Name":"duration total (min, med, max)","Value":"24","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":63,"Completion Time":1629344519037,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":32,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1192, None)) > 0)\n      +- Project [value#1192]\n         +- Relation[value#1192] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1192, None)) > 0)\n      +- Project [value#1192]\n         +- Relation[value#1192] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1192, None)) > 0)\n      +- Relation[value#1192] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1192, None)) > 0)\n   +- *(1) FileScan text [value#1192] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/producex.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1192, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1192] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/producex.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/producex.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":1954,"metricType":"sum"},{"name":"number of files","accumulatorId":1955,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":1956,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":1957,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1953,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":1952,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344519072}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":32,"accumUpdates":[[1955,1],[1956,0]]}
{"Event":"SparkListenerJobStart","Job ID":64,"Submission Time":1629344519098,"Stage Infos":[{"Stage ID":64,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":293,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"645\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[292],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":290,"Name":"FileScanRDD","Scope":"{\"id\":\"641\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":292,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"644\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[291],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":291,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"641\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[290],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[64],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"32","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":64,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":293,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"645\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[292],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":290,"Name":"FileScanRDD","Scope":"{\"id\":\"641\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":292,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"644\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[291],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":291,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"641\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[290],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519099,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"32","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":64,"Stage Attempt ID":0,"Task Info":{"Task ID":64,"Index":0,"Attempt":0,"Launch Time":1629344519106,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":64,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":64,"Index":0,"Attempt":0,"Launch Time":1629344519106,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344519115,"Failed":false,"Killed":false,"Accumulables":[{"ID":1953,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1954,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1980,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":1979,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1962,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":1961,"Name":"internal.metrics.executorCpuTime","Update":3614000,"Value":3614000,"Internal":true,"Count Failed Values":true},{"ID":1960,"Name":"internal.metrics.executorRunTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true},{"ID":1959,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1298000,"Value":1298000,"Internal":true,"Count Failed Values":true},{"ID":1958,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1298000,"Executor Run Time":5,"Executor CPU Time":3614000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":64,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":293,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"645\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[292],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":290,"Name":"FileScanRDD","Scope":"{\"id\":\"641\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":292,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"644\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[291],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":291,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"641\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[290],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519099,"Completion Time":1629344519115,"Accumulables":[{"ID":1979,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":1961,"Name":"internal.metrics.executorCpuTime","Value":3614000,"Internal":true,"Count Failed Values":true},{"ID":1958,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":1960,"Name":"internal.metrics.executorRunTime","Value":5,"Internal":true,"Count Failed Values":true},{"ID":1954,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1980,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":1959,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1298000,"Internal":true,"Count Failed Values":true},{"ID":1953,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1962,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":64,"Completion Time":1629344519115,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":32,"time":1629344519116}
{"Event":"SparkListenerJobStart","Job ID":65,"Submission Time":1629344519169,"Stage Infos":[{"Stage ID":65,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":298,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"654\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[297],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":295,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"651\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[294],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":294,"Name":"FileScanRDD","Scope":"{\"id\":\"651\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":297,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"653\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[296],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":296,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"650\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[295],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[65],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"655\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":65,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":298,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"654\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[297],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":295,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"651\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[294],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":294,"Name":"FileScanRDD","Scope":"{\"id\":\"651\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":297,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"653\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[296],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":296,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"650\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[295],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519170,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"655\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":65,"Stage Attempt ID":0,"Task Info":{"Task ID":65,"Index":0,"Attempt":0,"Launch Time":1629344519180,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":65,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":65,"Index":0,"Attempt":0,"Launch Time":1629344519180,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344519214,"Failed":false,"Killed":false,"Accumulables":[{"ID":1983,"Name":"number of output rows","Update":"3433","Value":"3433","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1987,"Name":"duration total (min, med, max)","Update":"28","Value":"27","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2010,"Name":"internal.metrics.input.recordsRead","Update":3433,"Value":3433,"Internal":true,"Count Failed Values":true},{"ID":2009,"Name":"internal.metrics.input.bytesRead","Update":232457,"Value":232457,"Internal":true,"Count Failed Values":true},{"ID":1992,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":1991,"Name":"internal.metrics.executorCpuTime","Update":29242000,"Value":29242000,"Internal":true,"Count Failed Values":true},{"ID":1990,"Name":"internal.metrics.executorRunTime","Update":30,"Value":30,"Internal":true,"Count Failed Values":true},{"ID":1989,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1752000,"Value":1752000,"Internal":true,"Count Failed Values":true},{"ID":1988,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1752000,"Executor Run Time":30,"Executor CPU Time":29242000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":232457,"Records Read":3433},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":65,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":298,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"654\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[297],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":295,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"651\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[294],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":294,"Name":"FileScanRDD","Scope":"{\"id\":\"651\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":297,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"653\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[296],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":296,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"650\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[295],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519170,"Completion Time":1629344519214,"Accumulables":[{"ID":1988,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":2009,"Name":"internal.metrics.input.bytesRead","Value":232457,"Internal":true,"Count Failed Values":true},{"ID":1991,"Name":"internal.metrics.executorCpuTime","Value":29242000,"Internal":true,"Count Failed Values":true},{"ID":1987,"Name":"duration total (min, med, max)","Value":"27","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1990,"Name":"internal.metrics.executorRunTime","Value":30,"Internal":true,"Count Failed Values":true},{"ID":1989,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1752000,"Internal":true,"Count Failed Values":true},{"ID":1983,"Name":"number of output rows","Value":"3433","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2010,"Name":"internal.metrics.input.recordsRead","Value":3433,"Internal":true,"Count Failed Values":true},{"ID":1992,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":65,"Completion Time":1629344519214,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":33,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1229, None)) > 0)\n      +- Project [value#1229]\n         +- Relation[value#1229] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1229, None)) > 0)\n      +- Project [value#1229]\n         +- Relation[value#1229] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1229, None)) > 0)\n      +- Relation[value#1229] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1229, None)) > 0)\n   +- *(1) FileScan text [value#1229] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/maplestory.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1229, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1229] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/maplestory.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/maplestory.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2015,"metricType":"sum"},{"name":"number of files","accumulatorId":2016,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2017,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2018,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2014,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2013,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344519259}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":33,"accumUpdates":[[2016,1],[2017,0]]}
{"Event":"SparkListenerJobStart","Job ID":66,"Submission Time":1629344519282,"Stage Infos":[{"Stage ID":66,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":302,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"665\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[301],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":300,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"661\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[299],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":301,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"664\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[300],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":299,"Name":"FileScanRDD","Scope":"{\"id\":\"661\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[66],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"33","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":66,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":302,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"665\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[301],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":300,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"661\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[299],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":301,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"664\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[300],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":299,"Name":"FileScanRDD","Scope":"{\"id\":\"661\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519282,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"33","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":66,"Stage Attempt ID":0,"Task Info":{"Task ID":66,"Index":0,"Attempt":0,"Launch Time":1629344519285,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":66,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":66,"Index":0,"Attempt":0,"Launch Time":1629344519285,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344519291,"Failed":false,"Killed":false,"Accumulables":[{"ID":2014,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2015,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2041,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2040,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2023,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":2022,"Name":"internal.metrics.executorCpuTime","Update":1443000,"Value":1443000,"Internal":true,"Count Failed Values":true},{"ID":2021,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":2020,"Name":"internal.metrics.executorDeserializeCpuTime","Update":695000,"Value":695000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":695000,"Executor Run Time":4,"Executor CPU Time":1443000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":66,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":302,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"665\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[301],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":300,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"661\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[299],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":301,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"664\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[300],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":299,"Name":"FileScanRDD","Scope":"{\"id\":\"661\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519282,"Completion Time":1629344519291,"Accumulables":[{"ID":2021,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":2015,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2020,"Name":"internal.metrics.executorDeserializeCpuTime","Value":695000,"Internal":true,"Count Failed Values":true},{"ID":2014,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2041,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2023,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":2040,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2022,"Name":"internal.metrics.executorCpuTime","Value":1443000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":66,"Completion Time":1629344519291,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":33,"time":1629344519292}
{"Event":"SparkListenerJobStart","Job ID":67,"Submission Time":1629344519326,"Stage Infos":[{"Stage ID":67,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":307,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"674\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[306],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":304,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"671\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[303],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":305,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"670\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[304],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":306,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"673\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[305],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":303,"Name":"FileScanRDD","Scope":"{\"id\":\"671\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[67],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"675\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":67,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":307,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"674\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[306],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":304,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"671\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[303],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":305,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"670\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[304],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":306,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"673\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[305],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":303,"Name":"FileScanRDD","Scope":"{\"id\":\"671\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519326,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"675\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":67,"Stage Attempt ID":0,"Task Info":{"Task ID":67,"Index":0,"Attempt":0,"Launch Time":1629344519329,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":67,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":67,"Index":0,"Attempt":0,"Launch Time":1629344519329,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344519487,"Failed":false,"Killed":false,"Accumulables":[{"ID":2044,"Name":"number of output rows","Update":"24519","Value":"24519","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2048,"Name":"duration total (min, med, max)","Update":"153","Value":"152","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2071,"Name":"internal.metrics.input.recordsRead","Update":24519,"Value":24519,"Internal":true,"Count Failed Values":true},{"ID":2070,"Name":"internal.metrics.input.bytesRead","Update":1695109,"Value":1695109,"Internal":true,"Count Failed Values":true},{"ID":2053,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2052,"Name":"internal.metrics.executorCpuTime","Update":152158000,"Value":152158000,"Internal":true,"Count Failed Values":true},{"ID":2051,"Name":"internal.metrics.executorRunTime","Update":156,"Value":156,"Internal":true,"Count Failed Values":true},{"ID":2050,"Name":"internal.metrics.executorDeserializeCpuTime","Update":983000,"Value":983000,"Internal":true,"Count Failed Values":true},{"ID":2049,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":983000,"Executor Run Time":156,"Executor CPU Time":152158000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1695109,"Records Read":24519},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":67,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":307,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"674\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[306],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":304,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"671\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[303],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":305,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"670\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[304],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":306,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"673\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[305],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":303,"Name":"FileScanRDD","Scope":"{\"id\":\"671\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519326,"Completion Time":1629344519488,"Accumulables":[{"ID":2048,"Name":"duration total (min, med, max)","Value":"152","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2051,"Name":"internal.metrics.executorRunTime","Value":156,"Internal":true,"Count Failed Values":true},{"ID":2044,"Name":"number of output rows","Value":"24519","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2071,"Name":"internal.metrics.input.recordsRead","Value":24519,"Internal":true,"Count Failed Values":true},{"ID":2053,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2050,"Name":"internal.metrics.executorDeserializeCpuTime","Value":983000,"Internal":true,"Count Failed Values":true},{"ID":2049,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2070,"Name":"internal.metrics.input.bytesRead","Value":1695109,"Internal":true,"Count Failed Values":true},{"ID":2052,"Name":"internal.metrics.executorCpuTime","Value":152158000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":67,"Completion Time":1629344519488,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":34,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1266, None)) > 0)\n      +- Project [value#1266]\n         +- Relation[value#1266] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1266, None)) > 0)\n      +- Project [value#1266]\n         +- Relation[value#1266] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1266, None)) > 0)\n      +- Relation[value#1266] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1266, None)) > 0)\n   +- *(1) FileScan text [value#1266] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ff14.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1266, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1266] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ff14.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ff14.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2076,"metricType":"sum"},{"name":"number of files","accumulatorId":2077,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2078,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2079,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2075,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2074,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344519528}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":34,"accumUpdates":[[2077,1],[2078,0]]}
{"Event":"SparkListenerJobStart","Job ID":68,"Submission Time":1629344519556,"Stage Infos":[{"Stage ID":68,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":311,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"685\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[310],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":310,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"684\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[309],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":308,"Name":"FileScanRDD","Scope":"{\"id\":\"681\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":309,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"681\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[308],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[68],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"34","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":68,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":311,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"685\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[310],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":310,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"684\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[309],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":308,"Name":"FileScanRDD","Scope":"{\"id\":\"681\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":309,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"681\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[308],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519557,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"34","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":68,"Stage Attempt ID":0,"Task Info":{"Task ID":68,"Index":0,"Attempt":0,"Launch Time":1629344519560,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":68,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":68,"Index":0,"Attempt":0,"Launch Time":1629344519560,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344519565,"Failed":false,"Killed":false,"Accumulables":[{"ID":2075,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2076,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2102,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2101,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2084,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2083,"Name":"internal.metrics.executorCpuTime","Update":1866000,"Value":1866000,"Internal":true,"Count Failed Values":true},{"ID":2082,"Name":"internal.metrics.executorRunTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true},{"ID":2081,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1083000,"Value":1083000,"Internal":true,"Count Failed Values":true},{"ID":2080,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1083000,"Executor Run Time":2,"Executor CPU Time":1866000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":68,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":311,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"685\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[310],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":310,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"684\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[309],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":308,"Name":"FileScanRDD","Scope":"{\"id\":\"681\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":309,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"681\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[308],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519557,"Completion Time":1629344519565,"Accumulables":[{"ID":2075,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2102,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2084,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2080,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2101,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2083,"Name":"internal.metrics.executorCpuTime","Value":1866000,"Internal":true,"Count Failed Values":true},{"ID":2076,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2082,"Name":"internal.metrics.executorRunTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":2081,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1083000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":68,"Completion Time":1629344519565,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":34,"time":1629344519566}
{"Event":"SparkListenerJobStart","Job ID":69,"Submission Time":1629344519597,"Stage Infos":[{"Stage ID":69,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":316,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"694\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[315],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":314,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"690\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[313],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":313,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"691\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[312],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":312,"Name":"FileScanRDD","Scope":"{\"id\":\"691\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":315,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"693\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[314],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[69],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"695\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":69,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":316,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"694\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[315],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":314,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"690\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[313],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":313,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"691\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[312],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":312,"Name":"FileScanRDD","Scope":"{\"id\":\"691\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":315,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"693\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[314],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519598,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"695\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":69,"Stage Attempt ID":0,"Task Info":{"Task ID":69,"Index":0,"Attempt":0,"Launch Time":1629344519601,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":69,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":69,"Index":0,"Attempt":0,"Launch Time":1629344519601,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344519636,"Failed":false,"Killed":false,"Accumulables":[{"ID":2105,"Name":"number of output rows","Update":"3802","Value":"3802","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2109,"Name":"duration total (min, med, max)","Update":"30","Value":"29","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2132,"Name":"internal.metrics.input.recordsRead","Update":3802,"Value":3802,"Internal":true,"Count Failed Values":true},{"ID":2131,"Name":"internal.metrics.input.bytesRead","Update":268026,"Value":268026,"Internal":true,"Count Failed Values":true},{"ID":2114,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2113,"Name":"internal.metrics.executorCpuTime","Update":29468000,"Value":29468000,"Internal":true,"Count Failed Values":true},{"ID":2112,"Name":"internal.metrics.executorRunTime","Update":32,"Value":32,"Internal":true,"Count Failed Values":true},{"ID":2111,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1175000,"Value":1175000,"Internal":true,"Count Failed Values":true},{"ID":2110,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1175000,"Executor Run Time":32,"Executor CPU Time":29468000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":268026,"Records Read":3802},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":69,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":316,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"694\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[315],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":314,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"690\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[313],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":313,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"691\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[312],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":312,"Name":"FileScanRDD","Scope":"{\"id\":\"691\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":315,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"693\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[314],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519598,"Completion Time":1629344519636,"Accumulables":[{"ID":2111,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1175000,"Internal":true,"Count Failed Values":true},{"ID":2105,"Name":"number of output rows","Value":"3802","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2131,"Name":"internal.metrics.input.bytesRead","Value":268026,"Internal":true,"Count Failed Values":true},{"ID":2113,"Name":"internal.metrics.executorCpuTime","Value":29468000,"Internal":true,"Count Failed Values":true},{"ID":2110,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2109,"Name":"duration total (min, med, max)","Value":"29","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2112,"Name":"internal.metrics.executorRunTime","Value":32,"Internal":true,"Count Failed Values":true},{"ID":2132,"Name":"internal.metrics.input.recordsRead","Value":3802,"Internal":true,"Count Failed Values":true},{"ID":2114,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":69,"Completion Time":1629344519636,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":35,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1303, None)) > 0)\n      +- Project [value#1303]\n         +- Relation[value#1303] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1303, None)) > 0)\n      +- Project [value#1303]\n         +- Relation[value#1303] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1303, None)) > 0)\n      +- Relation[value#1303] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1303, None)) > 0)\n   +- *(1) FileScan text [value#1303] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/divination.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1303, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1303] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/divination.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/divination.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2137,"metricType":"sum"},{"name":"number of files","accumulatorId":2138,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2139,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2140,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2136,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2135,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344519677}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":35,"accumUpdates":[[2138,1],[2139,0]]}
{"Event":"SparkListenerJobStart","Job ID":70,"Submission Time":1629344519705,"Stage Infos":[{"Stage ID":70,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":320,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"705\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[319],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":319,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"704\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[318],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":317,"Name":"FileScanRDD","Scope":"{\"id\":\"701\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":318,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"701\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[317],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[70],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"35","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":70,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":320,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"705\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[319],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":319,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"704\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[318],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":317,"Name":"FileScanRDD","Scope":"{\"id\":\"701\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":318,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"701\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[317],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519705,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"35","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":70,"Stage Attempt ID":0,"Task Info":{"Task ID":70,"Index":0,"Attempt":0,"Launch Time":1629344519709,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":70,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":70,"Index":0,"Attempt":0,"Launch Time":1629344519709,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344519714,"Failed":false,"Killed":false,"Accumulables":[{"ID":2136,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2137,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2163,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2162,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2145,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2144,"Name":"internal.metrics.executorCpuTime","Update":1583000,"Value":1583000,"Internal":true,"Count Failed Values":true},{"ID":2143,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":2142,"Name":"internal.metrics.executorDeserializeCpuTime","Update":692000,"Value":692000,"Internal":true,"Count Failed Values":true},{"ID":2141,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":692000,"Executor Run Time":3,"Executor CPU Time":1583000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":70,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":320,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"705\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[319],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":319,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"704\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[318],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":317,"Name":"FileScanRDD","Scope":"{\"id\":\"701\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":318,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"701\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[317],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519705,"Completion Time":1629344519714,"Accumulables":[{"ID":2137,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2143,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":2136,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2163,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2145,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2142,"Name":"internal.metrics.executorDeserializeCpuTime","Value":692000,"Internal":true,"Count Failed Values":true},{"ID":2141,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2162,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2144,"Name":"internal.metrics.executorCpuTime","Value":1583000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":70,"Completion Time":1629344519715,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":35,"time":1629344519715}
{"Event":"SparkListenerJobStart","Job ID":71,"Submission Time":1629344519745,"Stage Infos":[{"Stage ID":71,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":325,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"714\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[324],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":324,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"713\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[323],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":321,"Name":"FileScanRDD","Scope":"{\"id\":\"711\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":322,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"711\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[321],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":323,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"710\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[322],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[71],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"715\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":71,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":325,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"714\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[324],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":324,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"713\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[323],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":321,"Name":"FileScanRDD","Scope":"{\"id\":\"711\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":322,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"711\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[321],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":323,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"710\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[322],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519745,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"715\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":71,"Stage Attempt ID":0,"Task Info":{"Task ID":71,"Index":0,"Attempt":0,"Launch Time":1629344519748,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":71,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":71,"Index":0,"Attempt":0,"Launch Time":1629344519748,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344519855,"Failed":false,"Killed":false,"Accumulables":[{"ID":2166,"Name":"number of output rows","Update":"15383","Value":"15383","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2170,"Name":"duration total (min, med, max)","Update":"101","Value":"100","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2193,"Name":"internal.metrics.input.recordsRead","Update":15383,"Value":15383,"Internal":true,"Count Failed Values":true},{"ID":2192,"Name":"internal.metrics.input.bytesRead","Update":1146032,"Value":1146032,"Internal":true,"Count Failed Values":true},{"ID":2175,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2174,"Name":"internal.metrics.executorCpuTime","Update":100387000,"Value":100387000,"Internal":true,"Count Failed Values":true},{"ID":2173,"Name":"internal.metrics.executorRunTime","Update":103,"Value":103,"Internal":true,"Count Failed Values":true},{"ID":2172,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1370000,"Value":1370000,"Internal":true,"Count Failed Values":true},{"ID":2171,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1370000,"Executor Run Time":103,"Executor CPU Time":100387000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1146032,"Records Read":15383},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":71,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":325,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"714\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[324],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":324,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"713\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[323],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":321,"Name":"FileScanRDD","Scope":"{\"id\":\"711\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":322,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"711\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[321],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":323,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"710\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[322],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519745,"Completion Time":1629344519855,"Accumulables":[{"ID":2173,"Name":"internal.metrics.executorRunTime","Value":103,"Internal":true,"Count Failed Values":true},{"ID":2170,"Name":"duration total (min, med, max)","Value":"100","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2172,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1370000,"Internal":true,"Count Failed Values":true},{"ID":2166,"Name":"number of output rows","Value":"15383","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2193,"Name":"internal.metrics.input.recordsRead","Value":15383,"Internal":true,"Count Failed Values":true},{"ID":2175,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2192,"Name":"internal.metrics.input.bytesRead","Value":1146032,"Internal":true,"Count Failed Values":true},{"ID":2174,"Name":"internal.metrics.executorCpuTime","Value":100387000,"Internal":true,"Count Failed Values":true},{"ID":2171,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":71,"Completion Time":1629344519855,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":36,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1340, None)) > 0)\n      +- Project [value#1340]\n         +- Relation[value#1340] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1340, None)) > 0)\n      +- Project [value#1340]\n         +- Relation[value#1340] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1340, None)) > 0)\n      +- Relation[value#1340] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1340, None)) > 0)\n   +- *(1) FileScan text [value#1340] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/loan_new1.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1340, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1340] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/loan_new1.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/loan_new1.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2198,"metricType":"sum"},{"name":"number of files","accumulatorId":2199,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2200,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2201,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2197,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2196,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344519898}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":36,"accumUpdates":[[2199,1],[2200,0]]}
{"Event":"SparkListenerJobStart","Job ID":72,"Submission Time":1629344519924,"Stage Infos":[{"Stage ID":72,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":329,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"725\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[328],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":328,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"724\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[327],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":327,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"721\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[326],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":326,"Name":"FileScanRDD","Scope":"{\"id\":\"721\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[72],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"36","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":72,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":329,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"725\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[328],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":328,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"724\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[327],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":327,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"721\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[326],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":326,"Name":"FileScanRDD","Scope":"{\"id\":\"721\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519924,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"36","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":72,"Stage Attempt ID":0,"Task Info":{"Task ID":72,"Index":0,"Attempt":0,"Launch Time":1629344519928,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":72,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":72,"Index":0,"Attempt":0,"Launch Time":1629344519928,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344519934,"Failed":false,"Killed":false,"Accumulables":[{"ID":2197,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2198,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2224,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2223,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2206,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2205,"Name":"internal.metrics.executorCpuTime","Update":1997000,"Value":1997000,"Internal":true,"Count Failed Values":true},{"ID":2204,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":2203,"Name":"internal.metrics.executorDeserializeCpuTime","Update":686000,"Value":686000,"Internal":true,"Count Failed Values":true},{"ID":2202,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":686000,"Executor Run Time":4,"Executor CPU Time":1997000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":72,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":329,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"725\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[328],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":328,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"724\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[327],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":327,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"721\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[326],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":326,"Name":"FileScanRDD","Scope":"{\"id\":\"721\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519924,"Completion Time":1629344519934,"Accumulables":[{"ID":2197,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2224,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2206,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2203,"Name":"internal.metrics.executorDeserializeCpuTime","Value":686000,"Internal":true,"Count Failed Values":true},{"ID":2223,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2205,"Name":"internal.metrics.executorCpuTime","Value":1997000,"Internal":true,"Count Failed Values":true},{"ID":2202,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2204,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":2198,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":72,"Completion Time":1629344519934,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":36,"time":1629344519935}
{"Event":"SparkListenerJobStart","Job ID":73,"Submission Time":1629344519967,"Stage Infos":[{"Stage ID":73,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":334,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"734\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[333],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":332,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"730\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[331],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":331,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"731\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[330],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":333,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"733\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[332],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":330,"Name":"FileScanRDD","Scope":"{\"id\":\"731\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[73],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"735\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":73,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":334,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"734\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[333],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":332,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"730\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[331],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":331,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"731\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[330],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":333,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"733\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[332],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":330,"Name":"FileScanRDD","Scope":"{\"id\":\"731\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519967,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"735\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":73,"Stage Attempt ID":0,"Task Info":{"Task ID":73,"Index":0,"Attempt":0,"Launch Time":1629344519972,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":73,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":73,"Index":0,"Attempt":0,"Launch Time":1629344519972,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344520064,"Failed":false,"Killed":false,"Accumulables":[{"ID":2227,"Name":"number of output rows","Update":"10142","Value":"10142","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2231,"Name":"duration total (min, med, max)","Update":"87","Value":"86","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2254,"Name":"internal.metrics.input.recordsRead","Update":10142,"Value":10142,"Internal":true,"Count Failed Values":true},{"ID":2253,"Name":"internal.metrics.input.bytesRead","Update":700491,"Value":700491,"Internal":true,"Count Failed Values":true},{"ID":2238,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2237,"Name":"internal.metrics.jvmGCTime","Update":9,"Value":9,"Internal":true,"Count Failed Values":true},{"ID":2236,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":2235,"Name":"internal.metrics.executorCpuTime","Update":76668000,"Value":76668000,"Internal":true,"Count Failed Values":true},{"ID":2234,"Name":"internal.metrics.executorRunTime","Update":91,"Value":91,"Internal":true,"Count Failed Values":true},{"ID":2233,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1079000,"Value":1079000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":1079000,"Executor Run Time":91,"Executor CPU Time":76668000,"Result Size":1571,"JVM GC Time":9,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":700491,"Records Read":10142},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":73,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":334,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"734\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[333],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":332,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"730\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[331],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":331,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"731\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[330],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":333,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"733\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[332],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":330,"Name":"FileScanRDD","Scope":"{\"id\":\"731\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344519967,"Completion Time":1629344520064,"Accumulables":[{"ID":2233,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1079000,"Internal":true,"Count Failed Values":true},{"ID":2227,"Name":"number of output rows","Value":"10142","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2254,"Name":"internal.metrics.input.recordsRead","Value":10142,"Internal":true,"Count Failed Values":true},{"ID":2236,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true},{"ID":2238,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2253,"Name":"internal.metrics.input.bytesRead","Value":700491,"Internal":true,"Count Failed Values":true},{"ID":2235,"Name":"internal.metrics.executorCpuTime","Value":76668000,"Internal":true,"Count Failed Values":true},{"ID":2234,"Name":"internal.metrics.executorRunTime","Value":91,"Internal":true,"Count Failed Values":true},{"ID":2237,"Name":"internal.metrics.jvmGCTime","Value":9,"Internal":true,"Count Failed Values":true},{"ID":2231,"Name":"duration total (min, med, max)","Value":"86","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":73,"Completion Time":1629344520065,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":37,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1377, None)) > 0)\n      +- Project [value#1377]\n         +- Relation[value#1377] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1377, None)) > 0)\n      +- Project [value#1377]\n         +- Relation[value#1377] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1377, None)) > 0)\n      +- Relation[value#1377] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1377, None)) > 0)\n   +- *(1) FileScan text [value#1377] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/mistertrot.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1377, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1377] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/mistertrot.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/mistertrot.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2259,"metricType":"sum"},{"name":"number of files","accumulatorId":2260,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2261,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2262,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2258,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2257,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344520110}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":37,"accumUpdates":[[2260,1],[2261,0]]}
{"Event":"SparkListenerJobStart","Job ID":74,"Submission Time":1629344520139,"Stage Infos":[{"Stage ID":74,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":338,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"745\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[337],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":335,"Name":"FileScanRDD","Scope":"{\"id\":\"741\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":337,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"744\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[336],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":336,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"741\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[335],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[74],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"37","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":74,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":338,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"745\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[337],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":335,"Name":"FileScanRDD","Scope":"{\"id\":\"741\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":337,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"744\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[336],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":336,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"741\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[335],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520139,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"37","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":74,"Stage Attempt ID":0,"Task Info":{"Task ID":74,"Index":0,"Attempt":0,"Launch Time":1629344520142,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":74,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":74,"Index":0,"Attempt":0,"Launch Time":1629344520142,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344520148,"Failed":false,"Killed":false,"Accumulables":[{"ID":2258,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2259,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2285,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2284,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2267,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2266,"Name":"internal.metrics.executorCpuTime","Update":1562000,"Value":1562000,"Internal":true,"Count Failed Values":true},{"ID":2265,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":2264,"Name":"internal.metrics.executorDeserializeCpuTime","Update":694000,"Value":694000,"Internal":true,"Count Failed Values":true},{"ID":2263,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":694000,"Executor Run Time":4,"Executor CPU Time":1562000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":74,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":338,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"745\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[337],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":335,"Name":"FileScanRDD","Scope":"{\"id\":\"741\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":337,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"744\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[336],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":336,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"741\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[335],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520139,"Completion Time":1629344520148,"Accumulables":[{"ID":2284,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2266,"Name":"internal.metrics.executorCpuTime","Value":1562000,"Internal":true,"Count Failed Values":true},{"ID":2263,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2265,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":2259,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2264,"Name":"internal.metrics.executorDeserializeCpuTime","Value":694000,"Internal":true,"Count Failed Values":true},{"ID":2258,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2285,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2267,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":74,"Completion Time":1629344520148,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":37,"time":1629344520148}
{"Event":"SparkListenerJobStart","Job ID":75,"Submission Time":1629344520178,"Stage Infos":[{"Stage ID":75,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":343,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"754\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[342],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":342,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"753\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[341],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":339,"Name":"FileScanRDD","Scope":"{\"id\":\"751\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":340,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"751\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[339],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":341,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"750\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[340],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[75],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"755\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":75,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":343,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"754\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[342],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":342,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"753\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[341],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":339,"Name":"FileScanRDD","Scope":"{\"id\":\"751\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":340,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"751\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[339],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":341,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"750\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[340],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520178,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"755\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":75,"Stage Attempt ID":0,"Task Info":{"Task ID":75,"Index":0,"Attempt":0,"Launch Time":1629344520181,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":75,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":75,"Index":0,"Attempt":0,"Launch Time":1629344520181,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344520299,"Failed":false,"Killed":false,"Accumulables":[{"ID":2288,"Name":"number of output rows","Update":"18714","Value":"18714","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2292,"Name":"duration total (min, med, max)","Update":"113","Value":"112","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2315,"Name":"internal.metrics.input.recordsRead","Update":18714,"Value":18714,"Internal":true,"Count Failed Values":true},{"ID":2314,"Name":"internal.metrics.input.bytesRead","Update":1392919,"Value":1392919,"Internal":true,"Count Failed Values":true},{"ID":2297,"Name":"internal.metrics.resultSize","Update":1485,"Value":1485,"Internal":true,"Count Failed Values":true},{"ID":2296,"Name":"internal.metrics.executorCpuTime","Update":112656000,"Value":112656000,"Internal":true,"Count Failed Values":true},{"ID":2295,"Name":"internal.metrics.executorRunTime","Update":116,"Value":116,"Internal":true,"Count Failed Values":true},{"ID":2294,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1005000,"Value":1005000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":1005000,"Executor Run Time":116,"Executor CPU Time":112656000,"Result Size":1485,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1392919,"Records Read":18714},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":75,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":343,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"754\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[342],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":342,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"753\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[341],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":339,"Name":"FileScanRDD","Scope":"{\"id\":\"751\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":340,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"751\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[339],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":341,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"750\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[340],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520178,"Completion Time":1629344520300,"Accumulables":[{"ID":2314,"Name":"internal.metrics.input.bytesRead","Value":1392919,"Internal":true,"Count Failed Values":true},{"ID":2296,"Name":"internal.metrics.executorCpuTime","Value":112656000,"Internal":true,"Count Failed Values":true},{"ID":2292,"Name":"duration total (min, med, max)","Value":"112","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2295,"Name":"internal.metrics.executorRunTime","Value":116,"Internal":true,"Count Failed Values":true},{"ID":2294,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1005000,"Internal":true,"Count Failed Values":true},{"ID":2288,"Name":"number of output rows","Value":"18714","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2315,"Name":"internal.metrics.input.recordsRead","Value":18714,"Internal":true,"Count Failed Values":true},{"ID":2297,"Name":"internal.metrics.resultSize","Value":1485,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":75,"Completion Time":1629344520300,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":38,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1414, None)) > 0)\n      +- Project [value#1414]\n         +- Relation[value#1414] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1414, None)) > 0)\n      +- Project [value#1414]\n         +- Relation[value#1414] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1414, None)) > 0)\n      +- Relation[value#1414] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1414, None)) > 0)\n   +- *(1) FileScan text [value#1414] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/closers.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1414, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1414] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/closers.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/closers.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2320,"metricType":"sum"},{"name":"number of files","accumulatorId":2321,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2322,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2323,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2319,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2318,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344520346}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":38,"accumUpdates":[[2321,1],[2322,0]]}
{"Event":"SparkListenerJobStart","Job ID":76,"Submission Time":1629344520370,"Stage Infos":[{"Stage ID":76,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":347,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"765\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[346],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":344,"Name":"FileScanRDD","Scope":"{\"id\":\"761\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":345,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"761\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[344],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":346,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"764\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[345],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[76],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"38","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":76,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":347,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"765\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[346],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":344,"Name":"FileScanRDD","Scope":"{\"id\":\"761\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":345,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"761\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[344],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":346,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"764\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[345],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520371,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"38","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":76,"Stage Attempt ID":0,"Task Info":{"Task ID":76,"Index":0,"Attempt":0,"Launch Time":1629344520374,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":76,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":76,"Index":0,"Attempt":0,"Launch Time":1629344520374,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344520379,"Failed":false,"Killed":false,"Accumulables":[{"ID":2319,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2320,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2346,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2345,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2328,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2327,"Name":"internal.metrics.executorCpuTime","Update":1556000,"Value":1556000,"Internal":true,"Count Failed Values":true},{"ID":2326,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":2325,"Name":"internal.metrics.executorDeserializeCpuTime","Update":696000,"Value":696000,"Internal":true,"Count Failed Values":true},{"ID":2324,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":696000,"Executor Run Time":3,"Executor CPU Time":1556000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":76,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":347,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"765\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[346],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":344,"Name":"FileScanRDD","Scope":"{\"id\":\"761\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":345,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"761\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[344],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":346,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"764\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[345],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520371,"Completion Time":1629344520380,"Accumulables":[{"ID":2326,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":2320,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2325,"Name":"internal.metrics.executorDeserializeCpuTime","Value":696000,"Internal":true,"Count Failed Values":true},{"ID":2319,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2346,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2328,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2324,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2345,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2327,"Name":"internal.metrics.executorCpuTime","Value":1556000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":76,"Completion Time":1629344520380,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":38,"time":1629344520380}
{"Event":"SparkListenerJobStart","Job ID":77,"Submission Time":1629344520409,"Stage Infos":[{"Stage ID":77,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":352,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"774\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[351],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":349,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"771\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[348],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":351,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"773\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[350],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":350,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"770\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[349],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":348,"Name":"FileScanRDD","Scope":"{\"id\":\"771\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[77],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"775\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":77,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":352,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"774\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[351],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":349,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"771\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[348],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":351,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"773\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[350],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":350,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"770\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[349],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":348,"Name":"FileScanRDD","Scope":"{\"id\":\"771\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520409,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"775\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":77,"Stage Attempt ID":0,"Task Info":{"Task ID":77,"Index":0,"Attempt":0,"Launch Time":1629344520412,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":77,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":77,"Index":0,"Attempt":0,"Launch Time":1629344520412,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344520492,"Failed":false,"Killed":false,"Accumulables":[{"ID":2349,"Name":"number of output rows","Update":"12021","Value":"12021","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2353,"Name":"duration total (min, med, max)","Update":"75","Value":"74","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2376,"Name":"internal.metrics.input.recordsRead","Update":12021,"Value":12021,"Internal":true,"Count Failed Values":true},{"ID":2375,"Name":"internal.metrics.input.bytesRead","Update":801521,"Value":801521,"Internal":true,"Count Failed Values":true},{"ID":2358,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2357,"Name":"internal.metrics.executorCpuTime","Update":74258000,"Value":74258000,"Internal":true,"Count Failed Values":true},{"ID":2356,"Name":"internal.metrics.executorRunTime","Update":76,"Value":76,"Internal":true,"Count Failed Values":true},{"ID":2355,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1132000,"Value":1132000,"Internal":true,"Count Failed Values":true},{"ID":2354,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1132000,"Executor Run Time":76,"Executor CPU Time":74258000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":801521,"Records Read":12021},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":77,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":352,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"774\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[351],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":349,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"771\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[348],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":351,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"773\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[350],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":350,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"770\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[349],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":348,"Name":"FileScanRDD","Scope":"{\"id\":\"771\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520409,"Completion Time":1629344520493,"Accumulables":[{"ID":2353,"Name":"duration total (min, med, max)","Value":"74","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2356,"Name":"internal.metrics.executorRunTime","Value":76,"Internal":true,"Count Failed Values":true},{"ID":2349,"Name":"number of output rows","Value":"12021","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2376,"Name":"internal.metrics.input.recordsRead","Value":12021,"Internal":true,"Count Failed Values":true},{"ID":2358,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2355,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1132000,"Internal":true,"Count Failed Values":true},{"ID":2354,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2375,"Name":"internal.metrics.input.bytesRead","Value":801521,"Internal":true,"Count Failed Values":true},{"ID":2357,"Name":"internal.metrics.executorCpuTime","Value":74258000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":77,"Completion Time":1629344520493,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":39,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1451, None)) > 0)\n      +- Project [value#1451]\n         +- Relation[value#1451] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1451, None)) > 0)\n      +- Project [value#1451]\n         +- Relation[value#1451] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1451, None)) > 0)\n      +- Relation[value#1451] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1451, None)) > 0)\n   +- *(1) FileScan text [value#1451] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/exam_new2.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1451, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1451] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/exam_new2.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/exam_new2.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2381,"metricType":"sum"},{"name":"number of files","accumulatorId":2382,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2383,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2384,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2380,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2379,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344520530}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":39,"accumUpdates":[[2382,1],[2383,0]]}
{"Event":"SparkListenerJobStart","Job ID":78,"Submission Time":1629344520559,"Stage Infos":[{"Stage ID":78,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":356,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"785\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[355],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":354,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"781\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[353],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":355,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"784\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[354],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":353,"Name":"FileScanRDD","Scope":"{\"id\":\"781\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[78],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"39","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":78,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":356,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"785\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[355],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":354,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"781\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[353],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":355,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"784\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[354],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":353,"Name":"FileScanRDD","Scope":"{\"id\":\"781\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520559,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"39","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":78,"Stage Attempt ID":0,"Task Info":{"Task ID":78,"Index":0,"Attempt":0,"Launch Time":1629344520562,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":78,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":78,"Index":0,"Attempt":0,"Launch Time":1629344520562,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344520567,"Failed":false,"Killed":false,"Accumulables":[{"ID":2380,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2381,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2407,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2406,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2389,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":2388,"Name":"internal.metrics.executorCpuTime","Update":1597000,"Value":1597000,"Internal":true,"Count Failed Values":true},{"ID":2387,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":2386,"Name":"internal.metrics.executorDeserializeCpuTime","Update":759000,"Value":759000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":759000,"Executor Run Time":4,"Executor CPU Time":1597000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":78,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":356,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"785\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[355],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":354,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"781\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[353],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":355,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"784\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[354],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":353,"Name":"FileScanRDD","Scope":"{\"id\":\"781\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520559,"Completion Time":1629344520568,"Accumulables":[{"ID":2380,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2407,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2389,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":2406,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2388,"Name":"internal.metrics.executorCpuTime","Value":1597000,"Internal":true,"Count Failed Values":true},{"ID":2381,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2387,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":2386,"Name":"internal.metrics.executorDeserializeCpuTime","Value":759000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":78,"Completion Time":1629344520568,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":39,"time":1629344520568}
{"Event":"SparkListenerJobStart","Job ID":79,"Submission Time":1629344520601,"Stage Infos":[{"Stage ID":79,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":361,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"794\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[360],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":360,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"793\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[359],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":359,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"790\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[358],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":358,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"791\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[357],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":357,"Name":"FileScanRDD","Scope":"{\"id\":\"791\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[79],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"795\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":79,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":361,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"794\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[360],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":360,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"793\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[359],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":359,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"790\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[358],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":358,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"791\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[357],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":357,"Name":"FileScanRDD","Scope":"{\"id\":\"791\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520601,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"795\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":79,"Stage Attempt ID":0,"Task Info":{"Task ID":79,"Index":0,"Attempt":0,"Launch Time":1629344520604,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":79,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":79,"Index":0,"Attempt":0,"Launch Time":1629344520604,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344520633,"Failed":false,"Killed":false,"Accumulables":[{"ID":2410,"Name":"number of output rows","Update":"3762","Value":"3762","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2414,"Name":"duration total (min, med, max)","Update":"23","Value":"22","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2437,"Name":"internal.metrics.input.recordsRead","Update":3762,"Value":3762,"Internal":true,"Count Failed Values":true},{"ID":2436,"Name":"internal.metrics.input.bytesRead","Update":257372,"Value":257372,"Internal":true,"Count Failed Values":true},{"ID":2419,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2418,"Name":"internal.metrics.executorCpuTime","Update":22828000,"Value":22828000,"Internal":true,"Count Failed Values":true},{"ID":2417,"Name":"internal.metrics.executorRunTime","Update":24,"Value":24,"Internal":true,"Count Failed Values":true},{"ID":2416,"Name":"internal.metrics.executorDeserializeCpuTime","Update":951000,"Value":951000,"Internal":true,"Count Failed Values":true},{"ID":2415,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":951000,"Executor Run Time":24,"Executor CPU Time":22828000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":257372,"Records Read":3762},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":79,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":361,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"794\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[360],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":360,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"793\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[359],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":359,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"790\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[358],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":358,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"791\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[357],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":357,"Name":"FileScanRDD","Scope":"{\"id\":\"791\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520601,"Completion Time":1629344520633,"Accumulables":[{"ID":2416,"Name":"internal.metrics.executorDeserializeCpuTime","Value":951000,"Internal":true,"Count Failed Values":true},{"ID":2410,"Name":"number of output rows","Value":"3762","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2419,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2436,"Name":"internal.metrics.input.bytesRead","Value":257372,"Internal":true,"Count Failed Values":true},{"ID":2418,"Name":"internal.metrics.executorCpuTime","Value":22828000,"Internal":true,"Count Failed Values":true},{"ID":2415,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2414,"Name":"duration total (min, med, max)","Value":"22","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2417,"Name":"internal.metrics.executorRunTime","Value":24,"Internal":true,"Count Failed Values":true},{"ID":2437,"Name":"internal.metrics.input.recordsRead","Value":3762,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":79,"Completion Time":1629344520633,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":40,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1488, None)) > 0)\n      +- Project [value#1488]\n         +- Relation[value#1488] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1488, None)) > 0)\n      +- Project [value#1488]\n         +- Relation[value#1488] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1488, None)) > 0)\n      +- Relation[value#1488] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1488, None)) > 0)\n   +- *(1) FileScan text [value#1488] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ktwiz.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1488, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1488] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ktwiz.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ktwiz.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2442,"metricType":"sum"},{"name":"number of files","accumulatorId":2443,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2444,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2445,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2441,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2440,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344520671}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":40,"accumUpdates":[[2443,1],[2444,0]]}
{"Event":"SparkListenerJobStart","Job ID":80,"Submission Time":1629344520695,"Stage Infos":[{"Stage ID":80,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":365,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"805\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[364],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":364,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"804\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[363],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":362,"Name":"FileScanRDD","Scope":"{\"id\":\"801\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":363,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"801\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[362],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[80],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"40","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":80,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":365,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"805\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[364],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":364,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"804\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[363],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":362,"Name":"FileScanRDD","Scope":"{\"id\":\"801\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":363,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"801\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[362],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520696,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"40","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":80,"Stage Attempt ID":0,"Task Info":{"Task ID":80,"Index":0,"Attempt":0,"Launch Time":1629344520698,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":80,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":80,"Index":0,"Attempt":0,"Launch Time":1629344520698,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344520703,"Failed":false,"Killed":false,"Accumulables":[{"ID":2441,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2442,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2468,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2467,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2450,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":2449,"Name":"internal.metrics.executorCpuTime","Update":1407000,"Value":1407000,"Internal":true,"Count Failed Values":true},{"ID":2448,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":2447,"Name":"internal.metrics.executorDeserializeCpuTime","Update":649000,"Value":649000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":649000,"Executor Run Time":3,"Executor CPU Time":1407000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":80,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":365,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"805\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[364],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":364,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"804\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[363],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":362,"Name":"FileScanRDD","Scope":"{\"id\":\"801\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":363,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"801\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[362],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520696,"Completion Time":1629344520704,"Accumulables":[{"ID":2448,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":2442,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2441,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2468,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2450,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":2447,"Name":"internal.metrics.executorDeserializeCpuTime","Value":649000,"Internal":true,"Count Failed Values":true},{"ID":2467,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2449,"Name":"internal.metrics.executorCpuTime","Value":1407000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":80,"Completion Time":1629344520704,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":40,"time":1629344520704}
{"Event":"SparkListenerJobStart","Job ID":81,"Submission Time":1629344520733,"Stage Infos":[{"Stage ID":81,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":370,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"814\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[369],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":366,"Name":"FileScanRDD","Scope":"{\"id\":\"811\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":369,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"813\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[368],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":367,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"811\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[366],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":368,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"810\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[367],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[81],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"815\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":81,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":370,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"814\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[369],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":366,"Name":"FileScanRDD","Scope":"{\"id\":\"811\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":369,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"813\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[368],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":367,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"811\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[366],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":368,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"810\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[367],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520733,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"815\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":81,"Stage Attempt ID":0,"Task Info":{"Task ID":81,"Index":0,"Attempt":0,"Launch Time":1629344520736,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":81,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":81,"Index":0,"Attempt":0,"Launch Time":1629344520736,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344520774,"Failed":false,"Killed":false,"Accumulables":[{"ID":2471,"Name":"number of output rows","Update":"4633","Value":"4633","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2475,"Name":"duration total (min, med, max)","Update":"32","Value":"31","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2498,"Name":"internal.metrics.input.recordsRead","Update":4633,"Value":4633,"Internal":true,"Count Failed Values":true},{"ID":2497,"Name":"internal.metrics.input.bytesRead","Update":306917,"Value":306917,"Internal":true,"Count Failed Values":true},{"ID":2480,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2479,"Name":"internal.metrics.executorCpuTime","Update":32247000,"Value":32247000,"Internal":true,"Count Failed Values":true},{"ID":2478,"Name":"internal.metrics.executorRunTime","Update":34,"Value":34,"Internal":true,"Count Failed Values":true},{"ID":2477,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1159000,"Value":1159000,"Internal":true,"Count Failed Values":true},{"ID":2476,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1159000,"Executor Run Time":34,"Executor CPU Time":32247000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":306917,"Records Read":4633},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":81,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":370,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"814\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[369],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":366,"Name":"FileScanRDD","Scope":"{\"id\":\"811\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":369,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"813\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[368],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":367,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"811\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[366],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":368,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"810\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[367],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520733,"Completion Time":1629344520774,"Accumulables":[{"ID":2479,"Name":"internal.metrics.executorCpuTime","Value":32247000,"Internal":true,"Count Failed Values":true},{"ID":2478,"Name":"internal.metrics.executorRunTime","Value":34,"Internal":true,"Count Failed Values":true},{"ID":2475,"Name":"duration total (min, med, max)","Value":"31","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2477,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1159000,"Internal":true,"Count Failed Values":true},{"ID":2471,"Name":"number of output rows","Value":"4633","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2498,"Name":"internal.metrics.input.recordsRead","Value":4633,"Internal":true,"Count Failed Values":true},{"ID":2480,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2497,"Name":"internal.metrics.input.bytesRead","Value":306917,"Internal":true,"Count Failed Values":true},{"ID":2476,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":81,"Completion Time":1629344520774,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":41,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1525, None)) > 0)\n      +- Project [value#1525]\n         +- Relation[value#1525] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1525, None)) > 0)\n      +- Project [value#1525]\n         +- Relation[value#1525] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1525, None)) > 0)\n      +- Relation[value#1525] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1525, None)) > 0)\n   +- *(1) FileScan text [value#1525] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/basketball.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1525, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1525] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/basketball.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/basketball.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2503,"metricType":"sum"},{"name":"number of files","accumulatorId":2504,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2505,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2506,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2502,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2501,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344520813}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":41,"accumUpdates":[[2504,1],[2505,0]]}
{"Event":"SparkListenerJobStart","Job ID":82,"Submission Time":1629344520842,"Stage Infos":[{"Stage ID":82,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":374,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"825\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[373],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":371,"Name":"FileScanRDD","Scope":"{\"id\":\"821\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":372,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"821\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[371],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":373,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"824\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[372],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[82],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"41","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":82,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":374,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"825\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[373],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":371,"Name":"FileScanRDD","Scope":"{\"id\":\"821\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":372,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"821\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[371],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":373,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"824\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[372],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520842,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"41","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":82,"Stage Attempt ID":0,"Task Info":{"Task ID":82,"Index":0,"Attempt":0,"Launch Time":1629344520845,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":82,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":82,"Index":0,"Attempt":0,"Launch Time":1629344520845,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344520853,"Failed":false,"Killed":false,"Accumulables":[{"ID":2502,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2503,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2529,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2528,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2511,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2510,"Name":"internal.metrics.executorCpuTime","Update":2154000,"Value":2154000,"Internal":true,"Count Failed Values":true},{"ID":2509,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":2508,"Name":"internal.metrics.executorDeserializeCpuTime","Update":767000,"Value":767000,"Internal":true,"Count Failed Values":true},{"ID":2507,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":767000,"Executor Run Time":4,"Executor CPU Time":2154000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":82,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":374,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"825\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[373],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":371,"Name":"FileScanRDD","Scope":"{\"id\":\"821\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":372,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"821\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[371],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":373,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"824\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[372],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520842,"Completion Time":1629344520853,"Accumulables":[{"ID":2529,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2511,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2508,"Name":"internal.metrics.executorDeserializeCpuTime","Value":767000,"Internal":true,"Count Failed Values":true},{"ID":2502,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2528,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2510,"Name":"internal.metrics.executorCpuTime","Value":2154000,"Internal":true,"Count Failed Values":true},{"ID":2507,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2509,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":2503,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":82,"Completion Time":1629344520853,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":41,"time":1629344520854}
{"Event":"SparkListenerJobStart","Job ID":83,"Submission Time":1629344520882,"Stage Infos":[{"Stage ID":83,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":379,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"834\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[378],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":377,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"830\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[376],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":375,"Name":"FileScanRDD","Scope":"{\"id\":\"831\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":378,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"833\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[377],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":376,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"831\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[375],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[83],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"835\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":83,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":379,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"834\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[378],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":377,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"830\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[376],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":375,"Name":"FileScanRDD","Scope":"{\"id\":\"831\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":378,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"833\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[377],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":376,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"831\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[375],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520882,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"835\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":83,"Stage Attempt ID":0,"Task Info":{"Task ID":83,"Index":0,"Attempt":0,"Launch Time":1629344520886,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":83,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":83,"Index":0,"Attempt":0,"Launch Time":1629344520886,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344520900,"Failed":false,"Killed":false,"Accumulables":[{"ID":2532,"Name":"number of output rows","Update":"1298","Value":"1298","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2536,"Name":"duration total (min, med, max)","Update":"10","Value":"9","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2559,"Name":"internal.metrics.input.recordsRead","Update":1298,"Value":1298,"Internal":true,"Count Failed Values":true},{"ID":2558,"Name":"internal.metrics.input.bytesRead","Update":96003,"Value":96003,"Internal":true,"Count Failed Values":true},{"ID":2541,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2540,"Name":"internal.metrics.executorCpuTime","Update":10057000,"Value":10057000,"Internal":true,"Count Failed Values":true},{"ID":2539,"Name":"internal.metrics.executorRunTime","Update":12,"Value":12,"Internal":true,"Count Failed Values":true},{"ID":2538,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1079000,"Value":1079000,"Internal":true,"Count Failed Values":true},{"ID":2537,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1079000,"Executor Run Time":12,"Executor CPU Time":10057000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":96003,"Records Read":1298},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":83,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":379,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"834\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[378],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":377,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"830\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[376],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":375,"Name":"FileScanRDD","Scope":"{\"id\":\"831\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":378,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"833\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[377],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":376,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"831\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[375],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520882,"Completion Time":1629344520901,"Accumulables":[{"ID":2538,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1079000,"Internal":true,"Count Failed Values":true},{"ID":2532,"Name":"number of output rows","Value":"1298","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2559,"Name":"internal.metrics.input.recordsRead","Value":1298,"Internal":true,"Count Failed Values":true},{"ID":2541,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2537,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2558,"Name":"internal.metrics.input.bytesRead","Value":96003,"Internal":true,"Count Failed Values":true},{"ID":2540,"Name":"internal.metrics.executorCpuTime","Value":10057000,"Internal":true,"Count Failed Values":true},{"ID":2536,"Name":"duration total (min, med, max)","Value":"9","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2539,"Name":"internal.metrics.executorRunTime","Value":12,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":83,"Completion Time":1629344520901,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":42,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1562, None)) > 0)\n      +- Project [value#1562]\n         +- Relation[value#1562] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1562, None)) > 0)\n      +- Project [value#1562]\n         +- Relation[value#1562] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1562, None)) > 0)\n      +- Relation[value#1562] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1562, None)) > 0)\n   +- *(1) FileScan text [value#1562] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/pripara.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1562, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1562] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/pripara.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/pripara.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2564,"metricType":"sum"},{"name":"number of files","accumulatorId":2565,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2566,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2567,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2563,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2562,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344520940}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":42,"accumUpdates":[[2565,1],[2566,0]]}
{"Event":"SparkListenerJobStart","Job ID":84,"Submission Time":1629344520965,"Stage Infos":[{"Stage ID":84,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":383,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"845\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[382],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":380,"Name":"FileScanRDD","Scope":"{\"id\":\"841\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":381,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"841\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[380],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":382,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"844\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[381],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[84],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"42","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":84,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":383,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"845\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[382],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":380,"Name":"FileScanRDD","Scope":"{\"id\":\"841\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":381,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"841\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[380],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":382,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"844\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[381],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520965,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"42","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":84,"Stage Attempt ID":0,"Task Info":{"Task ID":84,"Index":0,"Attempt":0,"Launch Time":1629344520969,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":84,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":84,"Index":0,"Attempt":0,"Launch Time":1629344520969,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344520974,"Failed":false,"Killed":false,"Accumulables":[{"ID":2563,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2564,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2590,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2589,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2572,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2571,"Name":"internal.metrics.executorCpuTime","Update":1638000,"Value":1638000,"Internal":true,"Count Failed Values":true},{"ID":2570,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":2569,"Name":"internal.metrics.executorDeserializeCpuTime","Update":682000,"Value":682000,"Internal":true,"Count Failed Values":true},{"ID":2568,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":682000,"Executor Run Time":3,"Executor CPU Time":1638000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":84,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":383,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"845\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[382],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":380,"Name":"FileScanRDD","Scope":"{\"id\":\"841\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":381,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"841\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[380],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":382,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"844\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[381],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344520965,"Completion Time":1629344520975,"Accumulables":[{"ID":2589,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2571,"Name":"internal.metrics.executorCpuTime","Value":1638000,"Internal":true,"Count Failed Values":true},{"ID":2568,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2570,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":2564,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2569,"Name":"internal.metrics.executorDeserializeCpuTime","Value":682000,"Internal":true,"Count Failed Values":true},{"ID":2563,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2590,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2572,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":84,"Completion Time":1629344520975,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":42,"time":1629344520975}
{"Event":"SparkListenerJobStart","Job ID":85,"Submission Time":1629344521005,"Stage Infos":[{"Stage ID":85,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":388,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"854\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[387],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":384,"Name":"FileScanRDD","Scope":"{\"id\":\"851\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":385,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"851\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[384],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":387,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"853\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[386],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":386,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"850\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[385],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[85],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"855\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":85,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":388,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"854\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[387],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":384,"Name":"FileScanRDD","Scope":"{\"id\":\"851\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":385,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"851\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[384],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":387,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"853\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[386],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":386,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"850\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[385],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521005,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"855\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":85,"Stage Attempt ID":0,"Task Info":{"Task ID":85,"Index":0,"Attempt":0,"Launch Time":1629344521008,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":85,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":85,"Index":0,"Attempt":0,"Launch Time":1629344521008,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344521043,"Failed":false,"Killed":false,"Accumulables":[{"ID":2593,"Name":"number of output rows","Update":"4709","Value":"4709","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2597,"Name":"duration total (min, med, max)","Update":"30","Value":"29","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2620,"Name":"internal.metrics.input.recordsRead","Update":4709,"Value":4709,"Internal":true,"Count Failed Values":true},{"ID":2619,"Name":"internal.metrics.input.bytesRead","Update":335651,"Value":335651,"Internal":true,"Count Failed Values":true},{"ID":2602,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2601,"Name":"internal.metrics.executorCpuTime","Update":30157000,"Value":30157000,"Internal":true,"Count Failed Values":true},{"ID":2600,"Name":"internal.metrics.executorRunTime","Update":32,"Value":32,"Internal":true,"Count Failed Values":true},{"ID":2599,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1037000,"Value":1037000,"Internal":true,"Count Failed Values":true},{"ID":2598,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1037000,"Executor Run Time":32,"Executor CPU Time":30157000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":335651,"Records Read":4709},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":85,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":388,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"854\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[387],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":384,"Name":"FileScanRDD","Scope":"{\"id\":\"851\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":385,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"851\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[384],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":387,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"853\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[386],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":386,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"850\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[385],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521005,"Completion Time":1629344521044,"Accumulables":[{"ID":2598,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2619,"Name":"internal.metrics.input.bytesRead","Value":335651,"Internal":true,"Count Failed Values":true},{"ID":2601,"Name":"internal.metrics.executorCpuTime","Value":30157000,"Internal":true,"Count Failed Values":true},{"ID":2597,"Name":"duration total (min, med, max)","Value":"29","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2600,"Name":"internal.metrics.executorRunTime","Value":32,"Internal":true,"Count Failed Values":true},{"ID":2593,"Name":"number of output rows","Value":"4709","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2620,"Name":"internal.metrics.input.recordsRead","Value":4709,"Internal":true,"Count Failed Values":true},{"ID":2602,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2599,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1037000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":85,"Completion Time":1629344521044,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":43,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1599, None)) > 0)\n      +- Project [value#1599]\n         +- Relation[value#1599] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1599, None)) > 0)\n      +- Project [value#1599]\n         +- Relation[value#1599] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1599, None)) > 0)\n      +- Relation[value#1599] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1599, None)) > 0)\n   +- *(1) FileScan text [value#1599] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/taeyeon_new1..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1599, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1599] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/taeyeon_new1..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/taeyeon_new1.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2625,"metricType":"sum"},{"name":"number of files","accumulatorId":2626,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2627,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2628,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2624,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2623,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344521121}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":43,"accumUpdates":[[2626,1],[2627,0]]}
{"Event":"SparkListenerJobStart","Job ID":86,"Submission Time":1629344521163,"Stage Infos":[{"Stage ID":86,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":392,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"865\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[391],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":389,"Name":"FileScanRDD","Scope":"{\"id\":\"861\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":390,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"861\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[389],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":391,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"864\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[390],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[86],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"43","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":86,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":392,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"865\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[391],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":389,"Name":"FileScanRDD","Scope":"{\"id\":\"861\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":390,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"861\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[389],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":391,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"864\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[390],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521165,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"43","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":86,"Stage Attempt ID":0,"Task Info":{"Task ID":86,"Index":0,"Attempt":0,"Launch Time":1629344521171,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":86,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":86,"Index":0,"Attempt":0,"Launch Time":1629344521171,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344521182,"Failed":false,"Killed":false,"Accumulables":[{"ID":2624,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2625,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2651,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2650,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2633,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2632,"Name":"internal.metrics.executorCpuTime","Update":4486000,"Value":4486000,"Internal":true,"Count Failed Values":true},{"ID":2631,"Name":"internal.metrics.executorRunTime","Update":7,"Value":7,"Internal":true,"Count Failed Values":true},{"ID":2630,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1311000,"Value":1311000,"Internal":true,"Count Failed Values":true},{"ID":2629,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1311000,"Executor Run Time":7,"Executor CPU Time":4486000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":86,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":392,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"865\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[391],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":389,"Name":"FileScanRDD","Scope":"{\"id\":\"861\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":390,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"861\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[389],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":391,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"864\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[390],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521165,"Completion Time":1629344521182,"Accumulables":[{"ID":2631,"Name":"internal.metrics.executorRunTime","Value":7,"Internal":true,"Count Failed Values":true},{"ID":2625,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2630,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1311000,"Internal":true,"Count Failed Values":true},{"ID":2624,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2651,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2633,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2629,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2650,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2632,"Name":"internal.metrics.executorCpuTime","Value":4486000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":86,"Completion Time":1629344521182,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":43,"time":1629344521183}
{"Event":"SparkListenerJobStart","Job ID":87,"Submission Time":1629344521236,"Stage Infos":[{"Stage ID":87,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":397,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"874\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[396],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":394,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"871\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[393],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":393,"Name":"FileScanRDD","Scope":"{\"id\":\"871\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":396,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"873\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[395],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":395,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"870\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[394],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[87],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"875\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":87,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":397,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"874\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[396],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":394,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"871\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[393],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":393,"Name":"FileScanRDD","Scope":"{\"id\":\"871\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":396,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"873\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[395],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":395,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"870\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[394],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521237,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"875\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":87,"Stage Attempt ID":0,"Task Info":{"Task ID":87,"Index":0,"Attempt":0,"Launch Time":1629344521245,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":87,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":87,"Index":0,"Attempt":0,"Launch Time":1629344521245,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344521264,"Failed":false,"Killed":false,"Accumulables":[{"ID":2654,"Name":"number of output rows","Update":"1167","Value":"1167","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2658,"Name":"duration total (min, med, max)","Update":"13","Value":"12","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2681,"Name":"internal.metrics.input.recordsRead","Update":1167,"Value":1167,"Internal":true,"Count Failed Values":true},{"ID":2680,"Name":"internal.metrics.input.bytesRead","Update":66853,"Value":66853,"Internal":true,"Count Failed Values":true},{"ID":2665,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2663,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":2662,"Name":"internal.metrics.executorCpuTime","Update":13102000,"Value":13102000,"Internal":true,"Count Failed Values":true},{"ID":2661,"Name":"internal.metrics.executorRunTime","Update":15,"Value":15,"Internal":true,"Count Failed Values":true},{"ID":2660,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1581000,"Value":1581000,"Internal":true,"Count Failed Values":true},{"ID":2659,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1581000,"Executor Run Time":15,"Executor CPU Time":13102000,"Result Size":1571,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":66853,"Records Read":1167},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":87,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":397,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"874\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[396],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":394,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"871\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[393],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":393,"Name":"FileScanRDD","Scope":"{\"id\":\"871\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":396,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"873\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[395],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":395,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"870\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[394],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521237,"Completion Time":1629344521265,"Accumulables":[{"ID":2658,"Name":"duration total (min, med, max)","Value":"12","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2661,"Name":"internal.metrics.executorRunTime","Value":15,"Internal":true,"Count Failed Values":true},{"ID":2654,"Name":"number of output rows","Value":"1167","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2681,"Name":"internal.metrics.input.recordsRead","Value":1167,"Internal":true,"Count Failed Values":true},{"ID":2663,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true},{"ID":2660,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1581000,"Internal":true,"Count Failed Values":true},{"ID":2680,"Name":"internal.metrics.input.bytesRead","Value":66853,"Internal":true,"Count Failed Values":true},{"ID":2662,"Name":"internal.metrics.executorCpuTime","Value":13102000,"Internal":true,"Count Failed Values":true},{"ID":2665,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2659,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":87,"Completion Time":1629344521265,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":44,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1636, None)) > 0)\n      +- Project [value#1636]\n         +- Relation[value#1636] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1636, None)) > 0)\n      +- Project [value#1636]\n         +- Relation[value#1636] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1636, None)) > 0)\n      +- Relation[value#1636] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1636, None)) > 0)\n   +- *(1) FileScan text [value#1636] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/iu_new.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1636, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1636] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/iu_new.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/iu_new.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2686,"metricType":"sum"},{"name":"number of files","accumulatorId":2687,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2688,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2689,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2685,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2684,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344521334}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":44,"accumUpdates":[[2687,1],[2688,0]]}
{"Event":"SparkListenerJobStart","Job ID":88,"Submission Time":1629344521371,"Stage Infos":[{"Stage ID":88,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":401,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"885\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[400],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":399,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"881\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[398],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":400,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"884\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[399],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":398,"Name":"FileScanRDD","Scope":"{\"id\":\"881\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[88],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"44","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":88,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":401,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"885\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[400],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":399,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"881\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[398],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":400,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"884\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[399],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":398,"Name":"FileScanRDD","Scope":"{\"id\":\"881\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521371,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"44","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":88,"Stage Attempt ID":0,"Task Info":{"Task ID":88,"Index":0,"Attempt":0,"Launch Time":1629344521374,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":88,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":88,"Index":0,"Attempt":0,"Launch Time":1629344521374,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344521380,"Failed":false,"Killed":false,"Accumulables":[{"ID":2685,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2686,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2712,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2711,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2694,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2693,"Name":"internal.metrics.executorCpuTime","Update":1655000,"Value":1655000,"Internal":true,"Count Failed Values":true},{"ID":2692,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":2691,"Name":"internal.metrics.executorDeserializeCpuTime","Update":730000,"Value":730000,"Internal":true,"Count Failed Values":true},{"ID":2690,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":730000,"Executor Run Time":4,"Executor CPU Time":1655000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":88,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":401,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"885\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[400],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":399,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"881\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[398],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":400,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"884\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[399],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":398,"Name":"FileScanRDD","Scope":"{\"id\":\"881\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521371,"Completion Time":1629344521380,"Accumulables":[{"ID":2685,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2712,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2694,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2690,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2711,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2693,"Name":"internal.metrics.executorCpuTime","Value":1655000,"Internal":true,"Count Failed Values":true},{"ID":2686,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2692,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":2691,"Name":"internal.metrics.executorDeserializeCpuTime","Value":730000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":88,"Completion Time":1629344521380,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":44,"time":1629344521381}
{"Event":"SparkListenerJobStart","Job ID":89,"Submission Time":1629344521411,"Stage Infos":[{"Stage ID":89,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":406,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"894\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[405],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":405,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"893\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[404],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":403,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"891\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[402],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":404,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"890\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[403],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":402,"Name":"FileScanRDD","Scope":"{\"id\":\"891\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[89],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"895\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":89,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":406,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"894\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[405],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":405,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"893\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[404],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":403,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"891\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[402],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":404,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"890\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[403],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":402,"Name":"FileScanRDD","Scope":"{\"id\":\"891\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521411,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"895\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":89,"Stage Attempt ID":0,"Task Info":{"Task ID":89,"Index":0,"Attempt":0,"Launch Time":1629344521414,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":89,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":89,"Index":0,"Attempt":0,"Launch Time":1629344521414,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344521440,"Failed":false,"Killed":false,"Accumulables":[{"ID":2715,"Name":"number of output rows","Update":"3483","Value":"3483","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2719,"Name":"duration total (min, med, max)","Update":"22","Value":"21","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2742,"Name":"internal.metrics.input.recordsRead","Update":3483,"Value":3483,"Internal":true,"Count Failed Values":true},{"ID":2741,"Name":"internal.metrics.input.bytesRead","Update":220629,"Value":220629,"Internal":true,"Count Failed Values":true},{"ID":2724,"Name":"internal.metrics.resultSize","Update":1485,"Value":1485,"Internal":true,"Count Failed Values":true},{"ID":2723,"Name":"internal.metrics.executorCpuTime","Update":21887000,"Value":21887000,"Internal":true,"Count Failed Values":true},{"ID":2722,"Name":"internal.metrics.executorRunTime","Update":25,"Value":25,"Internal":true,"Count Failed Values":true},{"ID":2721,"Name":"internal.metrics.executorDeserializeCpuTime","Update":992000,"Value":992000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":992000,"Executor Run Time":25,"Executor CPU Time":21887000,"Result Size":1485,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":220629,"Records Read":3483},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":89,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":406,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"894\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[405],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":405,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"893\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[404],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":403,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"891\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[402],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":404,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"890\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[403],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":402,"Name":"FileScanRDD","Scope":"{\"id\":\"891\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521411,"Completion Time":1629344521441,"Accumulables":[{"ID":2721,"Name":"internal.metrics.executorDeserializeCpuTime","Value":992000,"Internal":true,"Count Failed Values":true},{"ID":2715,"Name":"number of output rows","Value":"3483","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2742,"Name":"internal.metrics.input.recordsRead","Value":3483,"Internal":true,"Count Failed Values":true},{"ID":2724,"Name":"internal.metrics.resultSize","Value":1485,"Internal":true,"Count Failed Values":true},{"ID":2741,"Name":"internal.metrics.input.bytesRead","Value":220629,"Internal":true,"Count Failed Values":true},{"ID":2723,"Name":"internal.metrics.executorCpuTime","Value":21887000,"Internal":true,"Count Failed Values":true},{"ID":2722,"Name":"internal.metrics.executorRunTime","Value":25,"Internal":true,"Count Failed Values":true},{"ID":2719,"Name":"duration total (min, med, max)","Value":"21","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":89,"Completion Time":1629344521441,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":45,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1673, None)) > 0)\n      +- Project [value#1673]\n         +- Relation[value#1673] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1673, None)) > 0)\n      +- Project [value#1673]\n         +- Relation[value#1673] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1673, None)) > 0)\n      +- Relation[value#1673] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1673, None)) > 0)\n   +- *(1) FileScan text [value#1673] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/boardgame.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1673, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1673] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/boardgame.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/boardgame.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2747,"metricType":"sum"},{"name":"number of files","accumulatorId":2748,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2749,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2750,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2746,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2745,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344521484}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":45,"accumUpdates":[[2748,1],[2749,0]]}
{"Event":"SparkListenerJobStart","Job ID":90,"Submission Time":1629344521525,"Stage Infos":[{"Stage ID":90,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":410,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"905\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[409],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":409,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"904\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[408],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":408,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"901\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[407],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":407,"Name":"FileScanRDD","Scope":"{\"id\":\"901\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[90],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"45","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":90,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":410,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"905\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[409],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":409,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"904\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[408],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":408,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"901\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[407],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":407,"Name":"FileScanRDD","Scope":"{\"id\":\"901\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521525,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"45","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":90,"Stage Attempt ID":0,"Task Info":{"Task ID":90,"Index":0,"Attempt":0,"Launch Time":1629344521530,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":90,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":90,"Index":0,"Attempt":0,"Launch Time":1629344521530,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344521539,"Failed":false,"Killed":false,"Accumulables":[{"ID":2746,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2747,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2773,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2772,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2755,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2754,"Name":"internal.metrics.executorCpuTime","Update":4259000,"Value":4259000,"Internal":true,"Count Failed Values":true},{"ID":2753,"Name":"internal.metrics.executorRunTime","Update":6,"Value":6,"Internal":true,"Count Failed Values":true},{"ID":2752,"Name":"internal.metrics.executorDeserializeCpuTime","Update":858000,"Value":858000,"Internal":true,"Count Failed Values":true},{"ID":2751,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":858000,"Executor Run Time":6,"Executor CPU Time":4259000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":90,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":410,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"905\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[409],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":409,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"904\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[408],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":408,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"901\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[407],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":407,"Name":"FileScanRDD","Scope":"{\"id\":\"901\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521525,"Completion Time":1629344521540,"Accumulables":[{"ID":2753,"Name":"internal.metrics.executorRunTime","Value":6,"Internal":true,"Count Failed Values":true},{"ID":2747,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2746,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2773,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2755,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2752,"Name":"internal.metrics.executorDeserializeCpuTime","Value":858000,"Internal":true,"Count Failed Values":true},{"ID":2751,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2772,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2754,"Name":"internal.metrics.executorCpuTime","Value":4259000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":90,"Completion Time":1629344521540,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":45,"time":1629344521540}
{"Event":"SparkListenerJobStart","Job ID":91,"Submission Time":1629344521585,"Stage Infos":[{"Stage ID":91,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":415,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"914\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[414],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":414,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"913\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[413],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":412,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"911\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[411],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":411,"Name":"FileScanRDD","Scope":"{\"id\":\"911\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":413,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"910\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[412],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[91],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"915\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":91,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":415,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"914\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[414],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":414,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"913\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[413],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":412,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"911\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[411],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":411,"Name":"FileScanRDD","Scope":"{\"id\":\"911\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":413,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"910\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[412],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521586,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"915\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":91,"Stage Attempt ID":0,"Task Info":{"Task ID":91,"Index":0,"Attempt":0,"Launch Time":1629344521591,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":91,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":91,"Index":0,"Attempt":0,"Launch Time":1629344521591,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344521633,"Failed":false,"Killed":false,"Accumulables":[{"ID":2776,"Name":"number of output rows","Update":"4763","Value":"4763","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2780,"Name":"duration total (min, med, max)","Update":"37","Value":"36","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2803,"Name":"internal.metrics.input.recordsRead","Update":4763,"Value":4763,"Internal":true,"Count Failed Values":true},{"ID":2802,"Name":"internal.metrics.input.bytesRead","Update":323041,"Value":323041,"Internal":true,"Count Failed Values":true},{"ID":2785,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2784,"Name":"internal.metrics.executorCpuTime","Update":36639000,"Value":36639000,"Internal":true,"Count Failed Values":true},{"ID":2783,"Name":"internal.metrics.executorRunTime","Update":39,"Value":39,"Internal":true,"Count Failed Values":true},{"ID":2782,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1059000,"Value":1059000,"Internal":true,"Count Failed Values":true},{"ID":2781,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1059000,"Executor Run Time":39,"Executor CPU Time":36639000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":323041,"Records Read":4763},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":91,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":415,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"914\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[414],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":414,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"913\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[413],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":412,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"911\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[411],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":411,"Name":"FileScanRDD","Scope":"{\"id\":\"911\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":413,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"910\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[412],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521586,"Completion Time":1629344521633,"Accumulables":[{"ID":2802,"Name":"internal.metrics.input.bytesRead","Value":323041,"Internal":true,"Count Failed Values":true},{"ID":2784,"Name":"internal.metrics.executorCpuTime","Value":36639000,"Internal":true,"Count Failed Values":true},{"ID":2783,"Name":"internal.metrics.executorRunTime","Value":39,"Internal":true,"Count Failed Values":true},{"ID":2780,"Name":"duration total (min, med, max)","Value":"36","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2782,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1059000,"Internal":true,"Count Failed Values":true},{"ID":2776,"Name":"number of output rows","Value":"4763","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2803,"Name":"internal.metrics.input.recordsRead","Value":4763,"Internal":true,"Count Failed Values":true},{"ID":2785,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2781,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":91,"Completion Time":1629344521634,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":46,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1710, None)) > 0)\n      +- Project [value#1710]\n         +- Relation[value#1710] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1710, None)) > 0)\n      +- Project [value#1710]\n         +- Relation[value#1710] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1710, None)) > 0)\n      +- Relation[value#1710] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1710, None)) > 0)\n   +- *(1) FileScan text [value#1710] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/stock_new2.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1710, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1710] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/stock_new2.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/stock_new2.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2808,"metricType":"sum"},{"name":"number of files","accumulatorId":2809,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2810,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2811,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2807,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2806,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344521692}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":46,"accumUpdates":[[2809,1],[2810,0]]}
{"Event":"SparkListenerJobStart","Job ID":92,"Submission Time":1629344521719,"Stage Infos":[{"Stage ID":92,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":419,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"925\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[418],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":418,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"924\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[417],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":416,"Name":"FileScanRDD","Scope":"{\"id\":\"921\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":417,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"921\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[416],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[92],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"46","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":92,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":419,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"925\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[418],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":418,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"924\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[417],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":416,"Name":"FileScanRDD","Scope":"{\"id\":\"921\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":417,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"921\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[416],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521720,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"46","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":92,"Stage Attempt ID":0,"Task Info":{"Task ID":92,"Index":0,"Attempt":0,"Launch Time":1629344521725,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":92,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":92,"Index":0,"Attempt":0,"Launch Time":1629344521725,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344521731,"Failed":false,"Killed":false,"Accumulables":[{"ID":2807,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2808,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2834,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2833,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2816,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2815,"Name":"internal.metrics.executorCpuTime","Update":1757000,"Value":1757000,"Internal":true,"Count Failed Values":true},{"ID":2814,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":2813,"Name":"internal.metrics.executorDeserializeCpuTime","Update":813000,"Value":813000,"Internal":true,"Count Failed Values":true},{"ID":2812,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":813000,"Executor Run Time":3,"Executor CPU Time":1757000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":92,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":419,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"925\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[418],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":418,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"924\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[417],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":416,"Name":"FileScanRDD","Scope":"{\"id\":\"921\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":417,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"921\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[416],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521720,"Completion Time":1629344521731,"Accumulables":[{"ID":2834,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2813,"Name":"internal.metrics.executorDeserializeCpuTime","Value":813000,"Internal":true,"Count Failed Values":true},{"ID":2807,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2816,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2833,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2815,"Name":"internal.metrics.executorCpuTime","Value":1757000,"Internal":true,"Count Failed Values":true},{"ID":2812,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2814,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":2808,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":92,"Completion Time":1629344521731,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":46,"time":1629344521731}
{"Event":"SparkListenerJobStart","Job ID":93,"Submission Time":1629344521777,"Stage Infos":[{"Stage ID":93,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":424,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"934\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[423],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":423,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"933\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[422],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":420,"Name":"FileScanRDD","Scope":"{\"id\":\"931\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":422,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"930\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[421],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":421,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"931\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[420],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[93],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"935\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":93,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":424,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"934\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[423],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":423,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"933\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[422],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":420,"Name":"FileScanRDD","Scope":"{\"id\":\"931\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":422,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"930\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[421],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":421,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"931\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[420],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521777,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"935\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":93,"Stage Attempt ID":0,"Task Info":{"Task ID":93,"Index":0,"Attempt":0,"Launch Time":1629344521783,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":93,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":93,"Index":0,"Attempt":0,"Launch Time":1629344521783,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344521830,"Failed":false,"Killed":false,"Accumulables":[{"ID":2837,"Name":"number of output rows","Update":"3831","Value":"3831","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2841,"Name":"duration total (min, med, max)","Update":"41","Value":"40","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2864,"Name":"internal.metrics.input.recordsRead","Update":3831,"Value":3831,"Internal":true,"Count Failed Values":true},{"ID":2863,"Name":"internal.metrics.input.bytesRead","Update":328147,"Value":328147,"Internal":true,"Count Failed Values":true},{"ID":2846,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2845,"Name":"internal.metrics.executorCpuTime","Update":41597000,"Value":41597000,"Internal":true,"Count Failed Values":true},{"ID":2844,"Name":"internal.metrics.executorRunTime","Update":45,"Value":45,"Internal":true,"Count Failed Values":true},{"ID":2843,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1811000,"Value":1811000,"Internal":true,"Count Failed Values":true},{"ID":2842,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1811000,"Executor Run Time":45,"Executor CPU Time":41597000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":328147,"Records Read":3831},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":93,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":424,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"934\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[423],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":423,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"933\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[422],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":420,"Name":"FileScanRDD","Scope":"{\"id\":\"931\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":422,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"930\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[421],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":421,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"931\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[420],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521777,"Completion Time":1629344521831,"Accumulables":[{"ID":2843,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1811000,"Internal":true,"Count Failed Values":true},{"ID":2837,"Name":"number of output rows","Value":"3831","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2864,"Name":"internal.metrics.input.recordsRead","Value":3831,"Internal":true,"Count Failed Values":true},{"ID":2846,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2842,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2863,"Name":"internal.metrics.input.bytesRead","Value":328147,"Internal":true,"Count Failed Values":true},{"ID":2845,"Name":"internal.metrics.executorCpuTime","Value":41597000,"Internal":true,"Count Failed Values":true},{"ID":2841,"Name":"duration total (min, med, max)","Value":"40","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2844,"Name":"internal.metrics.executorRunTime","Value":45,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":93,"Completion Time":1629344521831,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":47,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1747, None)) > 0)\n      +- Project [value#1747]\n         +- Relation[value#1747] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1747, None)) > 0)\n      +- Project [value#1747]\n         +- Relation[value#1747] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1747, None)) > 0)\n      +- Relation[value#1747] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1747, None)) > 0)\n   +- *(1) FileScan text [value#1747] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/extra.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1747, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1747] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/extra.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/extra.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2869,"metricType":"sum"},{"name":"number of files","accumulatorId":2870,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2871,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2872,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2868,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2867,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344521890}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":47,"accumUpdates":[[2870,1],[2871,0]]}
{"Event":"SparkListenerJobStart","Job ID":94,"Submission Time":1629344521918,"Stage Infos":[{"Stage ID":94,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":428,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"945\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[427],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":427,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"944\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[426],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":425,"Name":"FileScanRDD","Scope":"{\"id\":\"941\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":426,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"941\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[425],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[94],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"47","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":94,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":428,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"945\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[427],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":427,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"944\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[426],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":425,"Name":"FileScanRDD","Scope":"{\"id\":\"941\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":426,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"941\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[425],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521919,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"47","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":94,"Stage Attempt ID":0,"Task Info":{"Task ID":94,"Index":0,"Attempt":0,"Launch Time":1629344521924,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":94,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":94,"Index":0,"Attempt":0,"Launch Time":1629344521924,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344521930,"Failed":false,"Killed":false,"Accumulables":[{"ID":2868,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2869,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2895,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2894,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2877,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2876,"Name":"internal.metrics.executorCpuTime","Update":1989000,"Value":1989000,"Internal":true,"Count Failed Values":true},{"ID":2875,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":2874,"Name":"internal.metrics.executorDeserializeCpuTime","Update":843000,"Value":843000,"Internal":true,"Count Failed Values":true},{"ID":2873,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":843000,"Executor Run Time":4,"Executor CPU Time":1989000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":94,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":428,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"945\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[427],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":427,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"944\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[426],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":425,"Name":"FileScanRDD","Scope":"{\"id\":\"941\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":426,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"941\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[425],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344521919,"Completion Time":1629344521931,"Accumulables":[{"ID":2894,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2873,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2876,"Name":"internal.metrics.executorCpuTime","Value":1989000,"Internal":true,"Count Failed Values":true},{"ID":2875,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":2869,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2874,"Name":"internal.metrics.executorDeserializeCpuTime","Value":843000,"Internal":true,"Count Failed Values":true},{"ID":2868,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2895,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2877,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":94,"Completion Time":1629344521931,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":47,"time":1629344521932}
{"Event":"SparkListenerJobStart","Job ID":95,"Submission Time":1629344522019,"Stage Infos":[{"Stage ID":95,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":433,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"954\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[432],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":429,"Name":"FileScanRDD","Scope":"{\"id\":\"951\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":430,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"951\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[429],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":432,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"953\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[431],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":431,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"950\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[430],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[95],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"955\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":95,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":433,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"954\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[432],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":429,"Name":"FileScanRDD","Scope":"{\"id\":\"951\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":430,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"951\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[429],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":432,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"953\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[431],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":431,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"950\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[430],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522020,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"955\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":95,"Stage Attempt ID":0,"Task Info":{"Task ID":95,"Index":0,"Attempt":0,"Launch Time":1629344522027,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":95,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":95,"Index":0,"Attempt":0,"Launch Time":1629344522027,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344522111,"Failed":false,"Killed":false,"Accumulables":[{"ID":2898,"Name":"number of output rows","Update":"8194","Value":"8194","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2902,"Name":"duration total (min, med, max)","Update":"76","Value":"75","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2925,"Name":"internal.metrics.input.recordsRead","Update":8194,"Value":8194,"Internal":true,"Count Failed Values":true},{"ID":2924,"Name":"internal.metrics.input.bytesRead","Update":575792,"Value":575792,"Internal":true,"Count Failed Values":true},{"ID":2907,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2906,"Name":"internal.metrics.executorCpuTime","Update":75000000,"Value":75000000,"Internal":true,"Count Failed Values":true},{"ID":2905,"Name":"internal.metrics.executorRunTime","Update":77,"Value":77,"Internal":true,"Count Failed Values":true},{"ID":2904,"Name":"internal.metrics.executorDeserializeCpuTime","Update":2576000,"Value":2576000,"Internal":true,"Count Failed Values":true},{"ID":2903,"Name":"internal.metrics.executorDeserializeTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":3,"Executor Deserialize CPU Time":2576000,"Executor Run Time":77,"Executor CPU Time":75000000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":575792,"Records Read":8194},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":95,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":433,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"954\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[432],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":429,"Name":"FileScanRDD","Scope":"{\"id\":\"951\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":430,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"951\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[429],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":432,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"953\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[431],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":431,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"950\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[430],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522020,"Completion Time":1629344522111,"Accumulables":[{"ID":2903,"Name":"internal.metrics.executorDeserializeTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":2924,"Name":"internal.metrics.input.bytesRead","Value":575792,"Internal":true,"Count Failed Values":true},{"ID":2906,"Name":"internal.metrics.executorCpuTime","Value":75000000,"Internal":true,"Count Failed Values":true},{"ID":2902,"Name":"duration total (min, med, max)","Value":"75","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2905,"Name":"internal.metrics.executorRunTime","Value":77,"Internal":true,"Count Failed Values":true},{"ID":2898,"Name":"number of output rows","Value":"8194","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2925,"Name":"internal.metrics.input.recordsRead","Value":8194,"Internal":true,"Count Failed Values":true},{"ID":2907,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2904,"Name":"internal.metrics.executorDeserializeCpuTime","Value":2576000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":95,"Completion Time":1629344522111,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":48,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1784, None)) > 0)\n      +- Project [value#1784]\n         +- Relation[value#1784] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1784, None)) > 0)\n      +- Project [value#1784]\n         +- Relation[value#1784] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1784, None)) > 0)\n      +- Relation[value#1784] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1784, None)) > 0)\n   +- *(1) FileScan text [value#1784] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/drama_new3.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1784, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1784] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/drama_new3.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/drama_new3.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2930,"metricType":"sum"},{"name":"number of files","accumulatorId":2931,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2932,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2933,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2929,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2928,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344522174}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":48,"accumUpdates":[[2931,1],[2932,0]]}
{"Event":"SparkListenerJobStart","Job ID":96,"Submission Time":1629344522213,"Stage Infos":[{"Stage ID":96,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":437,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"965\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[436],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":435,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"961\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[434],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":434,"Name":"FileScanRDD","Scope":"{\"id\":\"961\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":436,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"964\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[435],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[96],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"48","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":96,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":437,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"965\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[436],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":435,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"961\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[434],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":434,"Name":"FileScanRDD","Scope":"{\"id\":\"961\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":436,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"964\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[435],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522214,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"48","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":96,"Stage Attempt ID":0,"Task Info":{"Task ID":96,"Index":0,"Attempt":0,"Launch Time":1629344522222,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":96,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":96,"Index":0,"Attempt":0,"Launch Time":1629344522222,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344522233,"Failed":false,"Killed":false,"Accumulables":[{"ID":2929,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2930,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2956,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":2955,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2938,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2937,"Name":"internal.metrics.executorCpuTime","Update":3891000,"Value":3891000,"Internal":true,"Count Failed Values":true},{"ID":2936,"Name":"internal.metrics.executorRunTime","Update":6,"Value":6,"Internal":true,"Count Failed Values":true},{"ID":2935,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1650000,"Value":1650000,"Internal":true,"Count Failed Values":true},{"ID":2934,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1650000,"Executor Run Time":6,"Executor CPU Time":3891000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":96,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":437,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"965\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[436],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":435,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"961\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[434],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":434,"Name":"FileScanRDD","Scope":"{\"id\":\"961\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":436,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"964\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[435],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522214,"Completion Time":1629344522233,"Accumulables":[{"ID":2930,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2936,"Name":"internal.metrics.executorRunTime","Value":6,"Internal":true,"Count Failed Values":true},{"ID":2935,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1650000,"Internal":true,"Count Failed Values":true},{"ID":2929,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2956,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2938,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2934,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":2955,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2937,"Name":"internal.metrics.executorCpuTime","Value":3891000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":96,"Completion Time":1629344522233,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":48,"time":1629344522235}
{"Event":"SparkListenerJobStart","Job ID":97,"Submission Time":1629344522270,"Stage Infos":[{"Stage ID":97,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":442,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"974\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[441],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":441,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"973\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[440],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":440,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"970\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[439],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":438,"Name":"FileScanRDD","Scope":"{\"id\":\"971\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":439,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"971\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[438],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[97],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"975\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":97,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":442,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"974\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[441],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":441,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"973\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[440],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":440,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"970\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[439],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":438,"Name":"FileScanRDD","Scope":"{\"id\":\"971\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":439,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"971\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[438],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522270,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"975\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":97,"Stage Attempt ID":0,"Task Info":{"Task ID":97,"Index":0,"Attempt":0,"Launch Time":1629344522274,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":97,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":97,"Index":0,"Attempt":0,"Launch Time":1629344522274,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344522388,"Failed":false,"Killed":false,"Accumulables":[{"ID":2959,"Name":"number of output rows","Update":"14628","Value":"14628","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2963,"Name":"duration total (min, med, max)","Update":"108","Value":"107","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2986,"Name":"internal.metrics.input.recordsRead","Update":14628,"Value":14628,"Internal":true,"Count Failed Values":true},{"ID":2985,"Name":"internal.metrics.input.bytesRead","Update":1154057,"Value":1154057,"Internal":true,"Count Failed Values":true},{"ID":2968,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2967,"Name":"internal.metrics.executorCpuTime","Update":109321000,"Value":109321000,"Internal":true,"Count Failed Values":true},{"ID":2966,"Name":"internal.metrics.executorRunTime","Update":110,"Value":110,"Internal":true,"Count Failed Values":true},{"ID":2965,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1342000,"Value":1342000,"Internal":true,"Count Failed Values":true},{"ID":2964,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1342000,"Executor Run Time":110,"Executor CPU Time":109321000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1154057,"Records Read":14628},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":97,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":442,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"974\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[441],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":441,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"973\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[440],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":440,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"970\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[439],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":438,"Name":"FileScanRDD","Scope":"{\"id\":\"971\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":439,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"971\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[438],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522270,"Completion Time":1629344522389,"Accumulables":[{"ID":2963,"Name":"duration total (min, med, max)","Value":"107","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2966,"Name":"internal.metrics.executorRunTime","Value":110,"Internal":true,"Count Failed Values":true},{"ID":2986,"Name":"internal.metrics.input.recordsRead","Value":14628,"Internal":true,"Count Failed Values":true},{"ID":2968,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":2965,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1342000,"Internal":true,"Count Failed Values":true},{"ID":2959,"Name":"number of output rows","Value":"14628","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2985,"Name":"internal.metrics.input.bytesRead","Value":1154057,"Internal":true,"Count Failed Values":true},{"ID":2967,"Name":"internal.metrics.executorCpuTime","Value":109321000,"Internal":true,"Count Failed Values":true},{"ID":2964,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":97,"Completion Time":1629344522389,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":49,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1821, None)) > 0)\n      +- Project [value#1821]\n         +- Relation[value#1821] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1821, None)) > 0)\n      +- Project [value#1821]\n         +- Relation[value#1821] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1821, None)) > 0)\n      +- Relation[value#1821] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1821, None)) > 0)\n   +- *(1) FileScan text [value#1821] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/smartphone.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1821, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1821] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/smartphone.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/smartphone.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":2991,"metricType":"sum"},{"name":"number of files","accumulatorId":2992,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":2993,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":2994,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2990,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":2989,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344522440}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":49,"accumUpdates":[[2992,1],[2993,0]]}
{"Event":"SparkListenerJobStart","Job ID":98,"Submission Time":1629344522462,"Stage Infos":[{"Stage ID":98,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":446,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"985\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[445],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":445,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"984\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[444],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":443,"Name":"FileScanRDD","Scope":"{\"id\":\"981\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":444,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"981\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[443],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[98],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"49","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":98,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":446,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"985\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[445],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":445,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"984\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[444],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":443,"Name":"FileScanRDD","Scope":"{\"id\":\"981\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":444,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"981\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[443],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522462,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"49","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":98,"Stage Attempt ID":0,"Task Info":{"Task ID":98,"Index":0,"Attempt":0,"Launch Time":1629344522465,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":98,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":98,"Index":0,"Attempt":0,"Launch Time":1629344522465,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344522470,"Failed":false,"Killed":false,"Accumulables":[{"ID":2990,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2991,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3017,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3016,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2999,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2998,"Name":"internal.metrics.executorCpuTime","Update":1391000,"Value":1391000,"Internal":true,"Count Failed Values":true},{"ID":2997,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":2996,"Name":"internal.metrics.executorDeserializeCpuTime","Update":709000,"Value":709000,"Internal":true,"Count Failed Values":true},{"ID":2995,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":709000,"Executor Run Time":3,"Executor CPU Time":1391000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":98,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":446,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"985\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[445],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":445,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"984\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[444],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":443,"Name":"FileScanRDD","Scope":"{\"id\":\"981\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":444,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"981\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[443],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522462,"Completion Time":1629344522470,"Accumulables":[{"ID":2990,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3017,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":2999,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":2996,"Name":"internal.metrics.executorDeserializeCpuTime","Value":709000,"Internal":true,"Count Failed Values":true},{"ID":2995,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3016,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":2998,"Name":"internal.metrics.executorCpuTime","Value":1391000,"Internal":true,"Count Failed Values":true},{"ID":2991,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":2997,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":98,"Completion Time":1629344522470,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":49,"time":1629344522471}
{"Event":"SparkListenerJobStart","Job ID":99,"Submission Time":1629344522501,"Stage Infos":[{"Stage ID":99,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":451,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"994\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[450],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":447,"Name":"FileScanRDD","Scope":"{\"id\":\"991\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":450,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"993\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[449],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":449,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"990\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[448],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":448,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"991\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[447],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[99],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"995\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":99,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":451,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"994\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[450],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":447,"Name":"FileScanRDD","Scope":"{\"id\":\"991\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":450,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"993\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[449],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":449,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"990\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[448],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":448,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"991\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[447],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522501,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"995\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":99,"Stage Attempt ID":0,"Task Info":{"Task ID":99,"Index":0,"Attempt":0,"Launch Time":1629344522504,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":99,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":99,"Index":0,"Attempt":0,"Launch Time":1629344522504,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344522586,"Failed":false,"Killed":false,"Accumulables":[{"ID":3020,"Name":"number of output rows","Update":"8536","Value":"8536","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3024,"Name":"duration total (min, med, max)","Update":"76","Value":"75","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3047,"Name":"internal.metrics.input.recordsRead","Update":8536,"Value":8536,"Internal":true,"Count Failed Values":true},{"ID":3046,"Name":"internal.metrics.input.bytesRead","Update":653903,"Value":653903,"Internal":true,"Count Failed Values":true},{"ID":3029,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3028,"Name":"internal.metrics.executorCpuTime","Update":74800000,"Value":74800000,"Internal":true,"Count Failed Values":true},{"ID":3027,"Name":"internal.metrics.executorRunTime","Update":77,"Value":77,"Internal":true,"Count Failed Values":true},{"ID":3026,"Name":"internal.metrics.executorDeserializeCpuTime","Update":982000,"Value":982000,"Internal":true,"Count Failed Values":true},{"ID":3025,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":982000,"Executor Run Time":77,"Executor CPU Time":74800000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":653903,"Records Read":8536},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":99,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":451,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"994\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[450],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":447,"Name":"FileScanRDD","Scope":"{\"id\":\"991\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":450,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"993\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[449],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":449,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"990\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[448],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":448,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"991\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[447],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522501,"Completion Time":1629344522586,"Accumulables":[{"ID":3026,"Name":"internal.metrics.executorDeserializeCpuTime","Value":982000,"Internal":true,"Count Failed Values":true},{"ID":3020,"Name":"number of output rows","Value":"8536","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3047,"Name":"internal.metrics.input.recordsRead","Value":8536,"Internal":true,"Count Failed Values":true},{"ID":3029,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3046,"Name":"internal.metrics.input.bytesRead","Value":653903,"Internal":true,"Count Failed Values":true},{"ID":3028,"Name":"internal.metrics.executorCpuTime","Value":74800000,"Internal":true,"Count Failed Values":true},{"ID":3025,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":3027,"Name":"internal.metrics.executorRunTime","Value":77,"Internal":true,"Count Failed Values":true},{"ID":3024,"Name":"duration total (min, med, max)","Value":"75","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":99,"Completion Time":1629344522587,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":50,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1858, None)) > 0)\n      +- Project [value#1858]\n         +- Relation[value#1858] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1858, None)) > 0)\n      +- Project [value#1858]\n         +- Relation[value#1858] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1858, None)) > 0)\n      +- Relation[value#1858] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1858, None)) > 0)\n   +- *(1) FileScan text [value#1858] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lotto_new2.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1858, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1858] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lotto_new2.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lotto_new2.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3052,"metricType":"sum"},{"name":"number of files","accumulatorId":3053,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3054,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3055,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3051,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3050,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344522662}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":50,"accumUpdates":[[3053,1],[3054,0]]}
{"Event":"SparkListenerJobStart","Job ID":100,"Submission Time":1629344522696,"Stage Infos":[{"Stage ID":100,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":455,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1005\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[454],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":453,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1001\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[452],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":454,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1004\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[453],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":452,"Name":"FileScanRDD","Scope":"{\"id\":\"1001\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[100],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"50","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":100,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":455,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1005\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[454],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":453,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1001\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[452],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":454,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1004\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[453],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":452,"Name":"FileScanRDD","Scope":"{\"id\":\"1001\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522696,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"50","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":100,"Stage Attempt ID":0,"Task Info":{"Task ID":100,"Index":0,"Attempt":0,"Launch Time":1629344522702,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":100,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":100,"Index":0,"Attempt":0,"Launch Time":1629344522702,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344522710,"Failed":false,"Killed":false,"Accumulables":[{"ID":3051,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3052,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3078,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3077,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3060,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":3059,"Name":"internal.metrics.executorCpuTime","Update":2088000,"Value":2088000,"Internal":true,"Count Failed Values":true},{"ID":3058,"Name":"internal.metrics.executorRunTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true},{"ID":3057,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1111000,"Value":1111000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":1111000,"Executor Run Time":5,"Executor CPU Time":2088000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":100,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":455,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1005\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[454],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":453,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1001\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[452],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":454,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1004\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[453],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":452,"Name":"FileScanRDD","Scope":"{\"id\":\"1001\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522696,"Completion Time":1629344522711,"Accumulables":[{"ID":3058,"Name":"internal.metrics.executorRunTime","Value":5,"Internal":true,"Count Failed Values":true},{"ID":3052,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3051,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3078,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3060,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":3057,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1111000,"Internal":true,"Count Failed Values":true},{"ID":3077,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3059,"Name":"internal.metrics.executorCpuTime","Value":2088000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":100,"Completion Time":1629344522711,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":50,"time":1629344522711}
{"Event":"SparkListenerJobStart","Job ID":101,"Submission Time":1629344522748,"Stage Infos":[{"Stage ID":101,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":460,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1014\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[459],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":457,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1011\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[456],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":459,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1013\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[458],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":458,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1010\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[457],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":456,"Name":"FileScanRDD","Scope":"{\"id\":\"1011\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[101],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1015\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":101,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":460,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1014\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[459],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":457,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1011\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[456],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":459,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1013\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[458],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":458,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1010\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[457],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":456,"Name":"FileScanRDD","Scope":"{\"id\":\"1011\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522749,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1015\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":101,"Stage Attempt ID":0,"Task Info":{"Task ID":101,"Index":0,"Attempt":0,"Launch Time":1629344522756,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":101,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":101,"Index":0,"Attempt":0,"Launch Time":1629344522756,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344522813,"Failed":false,"Killed":false,"Accumulables":[{"ID":3081,"Name":"number of output rows","Update":"6425","Value":"6425","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3085,"Name":"duration total (min, med, max)","Update":"52","Value":"51","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3108,"Name":"internal.metrics.input.recordsRead","Update":6425,"Value":6425,"Internal":true,"Count Failed Values":true},{"ID":3107,"Name":"internal.metrics.input.bytesRead","Update":458645,"Value":458645,"Internal":true,"Count Failed Values":true},{"ID":3090,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3089,"Name":"internal.metrics.executorCpuTime","Update":50783000,"Value":50783000,"Internal":true,"Count Failed Values":true},{"ID":3088,"Name":"internal.metrics.executorRunTime","Update":53,"Value":53,"Internal":true,"Count Failed Values":true},{"ID":3087,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1289000,"Value":1289000,"Internal":true,"Count Failed Values":true},{"ID":3086,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1289000,"Executor Run Time":53,"Executor CPU Time":50783000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":458645,"Records Read":6425},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":101,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":460,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1014\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[459],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":457,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1011\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[456],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":459,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1013\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[458],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":458,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1010\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[457],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":456,"Name":"FileScanRDD","Scope":"{\"id\":\"1011\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522749,"Completion Time":1629344522813,"Accumulables":[{"ID":3107,"Name":"internal.metrics.input.bytesRead","Value":458645,"Internal":true,"Count Failed Values":true},{"ID":3089,"Name":"internal.metrics.executorCpuTime","Value":50783000,"Internal":true,"Count Failed Values":true},{"ID":3088,"Name":"internal.metrics.executorRunTime","Value":53,"Internal":true,"Count Failed Values":true},{"ID":3085,"Name":"duration total (min, med, max)","Value":"51","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3087,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1289000,"Internal":true,"Count Failed Values":true},{"ID":3081,"Name":"number of output rows","Value":"6425","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3108,"Name":"internal.metrics.input.recordsRead","Value":6425,"Internal":true,"Count Failed Values":true},{"ID":3090,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3086,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":101,"Completion Time":1629344522813,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":51,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1895, None)) > 0)\n      +- Project [value#1895]\n         +- Relation[value#1895] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1895, None)) > 0)\n      +- Project [value#1895]\n         +- Relation[value#1895] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1895, None)) > 0)\n      +- Relation[value#1895] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1895, None)) > 0)\n   +- *(1) FileScan text [value#1895] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ib_new2.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1895, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1895] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ib_new2.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ib_new2.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3113,"metricType":"sum"},{"name":"number of files","accumulatorId":3114,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3115,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3116,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3112,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3111,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344522877}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":51,"accumUpdates":[[3114,1],[3115,0]]}
{"Event":"SparkListenerJobStart","Job ID":102,"Submission Time":1629344522910,"Stage Infos":[{"Stage ID":102,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":464,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1025\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[463],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":463,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1024\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[462],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":461,"Name":"FileScanRDD","Scope":"{\"id\":\"1021\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":462,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1021\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[461],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[102],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"51","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":102,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":464,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1025\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[463],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":463,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1024\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[462],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":461,"Name":"FileScanRDD","Scope":"{\"id\":\"1021\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":462,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1021\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[461],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522910,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"51","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":102,"Stage Attempt ID":0,"Task Info":{"Task ID":102,"Index":0,"Attempt":0,"Launch Time":1629344522913,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":102,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":102,"Index":0,"Attempt":0,"Launch Time":1629344522913,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344522922,"Failed":false,"Killed":false,"Accumulables":[{"ID":3112,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3113,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3139,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3138,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3121,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3120,"Name":"internal.metrics.executorCpuTime","Update":4295000,"Value":4295000,"Internal":true,"Count Failed Values":true},{"ID":3119,"Name":"internal.metrics.executorRunTime","Update":6,"Value":6,"Internal":true,"Count Failed Values":true},{"ID":3118,"Name":"internal.metrics.executorDeserializeCpuTime","Update":926000,"Value":926000,"Internal":true,"Count Failed Values":true},{"ID":3117,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":926000,"Executor Run Time":6,"Executor CPU Time":4295000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":102,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":464,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1025\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[463],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":463,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1024\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[462],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":461,"Name":"FileScanRDD","Scope":"{\"id\":\"1021\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":462,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1021\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[461],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522910,"Completion Time":1629344522922,"Accumulables":[{"ID":3118,"Name":"internal.metrics.executorDeserializeCpuTime","Value":926000,"Internal":true,"Count Failed Values":true},{"ID":3112,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3139,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3121,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3138,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3120,"Name":"internal.metrics.executorCpuTime","Value":4295000,"Internal":true,"Count Failed Values":true},{"ID":3117,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3119,"Name":"internal.metrics.executorRunTime","Value":6,"Internal":true,"Count Failed Values":true},{"ID":3113,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":102,"Completion Time":1629344522922,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":51,"time":1629344522923}
{"Event":"SparkListenerJobStart","Job ID":103,"Submission Time":1629344522963,"Stage Infos":[{"Stage ID":103,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":469,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1034\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[468],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":468,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1033\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[467],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":467,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1030\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[466],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":466,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1031\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[465],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":465,"Name":"FileScanRDD","Scope":"{\"id\":\"1031\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[103],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1035\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":103,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":469,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1034\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[468],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":468,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1033\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[467],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":467,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1030\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[466],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":466,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1031\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[465],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":465,"Name":"FileScanRDD","Scope":"{\"id\":\"1031\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522963,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1035\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":103,"Stage Attempt ID":0,"Task Info":{"Task ID":103,"Index":0,"Attempt":0,"Launch Time":1629344522971,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":103,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":103,"Index":0,"Attempt":0,"Launch Time":1629344522971,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344523205,"Failed":false,"Killed":false,"Accumulables":[{"ID":3142,"Name":"number of output rows","Update":"30567","Value":"30567","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3146,"Name":"duration total (min, med, max)","Update":"228","Value":"227","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3169,"Name":"internal.metrics.input.recordsRead","Update":30567,"Value":30567,"Internal":true,"Count Failed Values":true},{"ID":3168,"Name":"internal.metrics.input.bytesRead","Update":2528934,"Value":2528934,"Internal":true,"Count Failed Values":true},{"ID":3151,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3150,"Name":"internal.metrics.executorCpuTime","Update":225859000,"Value":225859000,"Internal":true,"Count Failed Values":true},{"ID":3149,"Name":"internal.metrics.executorRunTime","Update":231,"Value":231,"Internal":true,"Count Failed Values":true},{"ID":3148,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1239000,"Value":1239000,"Internal":true,"Count Failed Values":true},{"ID":3147,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1239000,"Executor Run Time":231,"Executor CPU Time":225859000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":2528934,"Records Read":30567},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":103,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":469,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1034\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[468],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":468,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1033\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[467],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":467,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1030\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[466],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":466,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1031\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[465],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":465,"Name":"FileScanRDD","Scope":"{\"id\":\"1031\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344522963,"Completion Time":1629344523205,"Accumulables":[{"ID":3148,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1239000,"Internal":true,"Count Failed Values":true},{"ID":3142,"Name":"number of output rows","Value":"30567","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3169,"Name":"internal.metrics.input.recordsRead","Value":30567,"Internal":true,"Count Failed Values":true},{"ID":3151,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3147,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3168,"Name":"internal.metrics.input.bytesRead","Value":2528934,"Internal":true,"Count Failed Values":true},{"ID":3150,"Name":"internal.metrics.executorCpuTime","Value":225859000,"Internal":true,"Count Failed Values":true},{"ID":3146,"Name":"duration total (min, med, max)","Value":"227","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3149,"Name":"internal.metrics.executorRunTime","Value":231,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":103,"Completion Time":1629344523205,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":52,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1932, None)) > 0)\n      +- Project [value#1932]\n         +- Relation[value#1932] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1932, None)) > 0)\n      +- Project [value#1932]\n         +- Relation[value#1932] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1932, None)) > 0)\n      +- Relation[value#1932] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1932, None)) > 0)\n   +- *(1) FileScan text [value#1932] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/etc_program2..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1932, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1932] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/etc_program2..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/etc_program2.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3174,"metricType":"sum"},{"name":"number of files","accumulatorId":3175,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3176,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3177,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3173,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3172,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344523263}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":52,"accumUpdates":[[3175,1],[3176,0]]}
{"Event":"SparkListenerJobStart","Job ID":104,"Submission Time":1629344523295,"Stage Infos":[{"Stage ID":104,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":473,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1045\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[472],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":470,"Name":"FileScanRDD","Scope":"{\"id\":\"1041\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":472,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1044\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[471],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":471,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1041\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[470],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[104],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"52","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":104,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":473,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1045\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[472],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":470,"Name":"FileScanRDD","Scope":"{\"id\":\"1041\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":472,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1044\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[471],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":471,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1041\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[470],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523295,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"52","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":104,"Stage Attempt ID":0,"Task Info":{"Task ID":104,"Index":0,"Attempt":0,"Launch Time":1629344523298,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":104,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":104,"Index":0,"Attempt":0,"Launch Time":1629344523298,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344523306,"Failed":false,"Killed":false,"Accumulables":[{"ID":3173,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3174,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3200,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3199,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3182,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3181,"Name":"internal.metrics.executorCpuTime","Update":3657000,"Value":3657000,"Internal":true,"Count Failed Values":true},{"ID":3180,"Name":"internal.metrics.executorRunTime","Update":6,"Value":6,"Internal":true,"Count Failed Values":true},{"ID":3179,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1173000,"Value":1173000,"Internal":true,"Count Failed Values":true},{"ID":3178,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1173000,"Executor Run Time":6,"Executor CPU Time":3657000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":104,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":473,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1045\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[472],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":470,"Name":"FileScanRDD","Scope":"{\"id\":\"1041\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":472,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1044\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[471],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":471,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1041\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[470],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523295,"Completion Time":1629344523307,"Accumulables":[{"ID":3178,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3199,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3181,"Name":"internal.metrics.executorCpuTime","Value":3657000,"Internal":true,"Count Failed Values":true},{"ID":3180,"Name":"internal.metrics.executorRunTime","Value":6,"Internal":true,"Count Failed Values":true},{"ID":3174,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3179,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1173000,"Internal":true,"Count Failed Values":true},{"ID":3173,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3200,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3182,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":104,"Completion Time":1629344523307,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":52,"time":1629344523307}
{"Event":"SparkListenerJobStart","Job ID":105,"Submission Time":1629344523346,"Stage Infos":[{"Stage ID":105,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":478,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1054\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[477],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":477,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1053\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[476],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":474,"Name":"FileScanRDD","Scope":"{\"id\":\"1051\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":476,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1050\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[475],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":475,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1051\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[474],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[105],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1055\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":105,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":478,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1054\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[477],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":477,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1053\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[476],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":474,"Name":"FileScanRDD","Scope":"{\"id\":\"1051\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":476,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1050\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[475],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":475,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1051\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[474],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523346,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1055\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":105,"Stage Attempt ID":0,"Task Info":{"Task ID":105,"Index":0,"Attempt":0,"Launch Time":1629344523351,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":105,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":105,"Index":0,"Attempt":0,"Launch Time":1629344523351,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344523376,"Failed":false,"Killed":false,"Accumulables":[{"ID":3203,"Name":"number of output rows","Update":"2311","Value":"2311","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3207,"Name":"duration total (min, med, max)","Update":"19","Value":"18","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3230,"Name":"internal.metrics.input.recordsRead","Update":2311,"Value":2311,"Internal":true,"Count Failed Values":true},{"ID":3229,"Name":"internal.metrics.input.bytesRead","Update":171135,"Value":171135,"Internal":true,"Count Failed Values":true},{"ID":3212,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3211,"Name":"internal.metrics.executorCpuTime","Update":19469000,"Value":19469000,"Internal":true,"Count Failed Values":true},{"ID":3210,"Name":"internal.metrics.executorRunTime","Update":22,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":3209,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1721000,"Value":1721000,"Internal":true,"Count Failed Values":true},{"ID":3208,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1721000,"Executor Run Time":22,"Executor CPU Time":19469000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":171135,"Records Read":2311},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":105,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":478,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1054\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[477],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":477,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1053\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[476],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":474,"Name":"FileScanRDD","Scope":"{\"id\":\"1051\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":476,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1050\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[475],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":475,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1051\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[474],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523346,"Completion Time":1629344523377,"Accumulables":[{"ID":3208,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3229,"Name":"internal.metrics.input.bytesRead","Value":171135,"Internal":true,"Count Failed Values":true},{"ID":3211,"Name":"internal.metrics.executorCpuTime","Value":19469000,"Internal":true,"Count Failed Values":true},{"ID":3207,"Name":"duration total (min, med, max)","Value":"18","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3210,"Name":"internal.metrics.executorRunTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":3203,"Name":"number of output rows","Value":"2311","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3230,"Name":"internal.metrics.input.recordsRead","Value":2311,"Internal":true,"Count Failed Values":true},{"ID":3212,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3209,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1721000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":105,"Completion Time":1629344523377,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":53,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1969, None)) > 0)\n      +- Project [value#1969]\n         +- Relation[value#1969] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1969, None)) > 0)\n      +- Project [value#1969]\n         +- Relation[value#1969] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#1969, None)) > 0)\n      +- Relation[value#1969] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#1969, None)) > 0)\n   +- *(1) FileScan text [value#1969] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/gf.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#1969, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#1969] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/gf.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/gf.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3235,"metricType":"sum"},{"name":"number of files","accumulatorId":3236,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3237,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3238,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3234,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3233,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344523423}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":53,"accumUpdates":[[3236,1],[3237,0]]}
{"Event":"SparkListenerJobStart","Job ID":106,"Submission Time":1629344523445,"Stage Infos":[{"Stage ID":106,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":482,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1065\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[481],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":479,"Name":"FileScanRDD","Scope":"{\"id\":\"1061\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":480,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1061\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[479],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":481,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1064\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[480],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[106],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"53","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":106,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":482,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1065\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[481],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":479,"Name":"FileScanRDD","Scope":"{\"id\":\"1061\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":480,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1061\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[479],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":481,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1064\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[480],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523446,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"53","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":106,"Stage Attempt ID":0,"Task Info":{"Task ID":106,"Index":0,"Attempt":0,"Launch Time":1629344523448,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":106,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":106,"Index":0,"Attempt":0,"Launch Time":1629344523448,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344523454,"Failed":false,"Killed":false,"Accumulables":[{"ID":3234,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3235,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3261,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3260,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3243,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":3242,"Name":"internal.metrics.executorCpuTime","Update":1430000,"Value":1430000,"Internal":true,"Count Failed Values":true},{"ID":3241,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":3240,"Name":"internal.metrics.executorDeserializeCpuTime","Update":671000,"Value":671000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":671000,"Executor Run Time":3,"Executor CPU Time":1430000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":106,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":482,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1065\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[481],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":479,"Name":"FileScanRDD","Scope":"{\"id\":\"1061\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":480,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1061\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[479],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":481,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1064\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[480],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523446,"Completion Time":1629344523454,"Accumulables":[{"ID":3235,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3241,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":3240,"Name":"internal.metrics.executorDeserializeCpuTime","Value":671000,"Internal":true,"Count Failed Values":true},{"ID":3234,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3261,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3243,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":3260,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3242,"Name":"internal.metrics.executorCpuTime","Value":1430000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":106,"Completion Time":1629344523454,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":53,"time":1629344523454}
{"Event":"SparkListenerJobStart","Job ID":107,"Submission Time":1629344523484,"Stage Infos":[{"Stage ID":107,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":487,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1074\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[486],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":485,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1070\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[484],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":484,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1071\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[483],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":483,"Name":"FileScanRDD","Scope":"{\"id\":\"1071\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":486,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1073\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[485],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[107],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1075\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":107,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":487,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1074\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[486],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":485,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1070\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[484],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":484,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1071\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[483],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":483,"Name":"FileScanRDD","Scope":"{\"id\":\"1071\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":486,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1073\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[485],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523484,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1075\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":107,"Stage Attempt ID":0,"Task Info":{"Task ID":107,"Index":0,"Attempt":0,"Launch Time":1629344523487,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":107,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":107,"Index":0,"Attempt":0,"Launch Time":1629344523487,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344523522,"Failed":false,"Killed":false,"Accumulables":[{"ID":3264,"Name":"number of output rows","Update":"4979","Value":"4979","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3268,"Name":"duration total (min, med, max)","Update":"30","Value":"29","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3291,"Name":"internal.metrics.input.recordsRead","Update":4979,"Value":4979,"Internal":true,"Count Failed Values":true},{"ID":3290,"Name":"internal.metrics.input.bytesRead","Update":292954,"Value":292954,"Internal":true,"Count Failed Values":true},{"ID":3275,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3273,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":3272,"Name":"internal.metrics.executorCpuTime","Update":30340000,"Value":30340000,"Internal":true,"Count Failed Values":true},{"ID":3271,"Name":"internal.metrics.executorRunTime","Update":32,"Value":32,"Internal":true,"Count Failed Values":true},{"ID":3270,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1002000,"Value":1002000,"Internal":true,"Count Failed Values":true},{"ID":3269,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1002000,"Executor Run Time":32,"Executor CPU Time":30340000,"Result Size":1571,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":292954,"Records Read":4979},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":107,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":487,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1074\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[486],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":485,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1070\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[484],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":484,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1071\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[483],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":483,"Name":"FileScanRDD","Scope":"{\"id\":\"1071\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":486,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1073\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[485],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523484,"Completion Time":1629344523522,"Accumulables":[{"ID":3268,"Name":"duration total (min, med, max)","Value":"29","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3271,"Name":"internal.metrics.executorRunTime","Value":32,"Internal":true,"Count Failed Values":true},{"ID":3291,"Name":"internal.metrics.input.recordsRead","Value":4979,"Internal":true,"Count Failed Values":true},{"ID":3270,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1002000,"Internal":true,"Count Failed Values":true},{"ID":3264,"Name":"number of output rows","Value":"4979","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3273,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true},{"ID":3290,"Name":"internal.metrics.input.bytesRead","Value":292954,"Internal":true,"Count Failed Values":true},{"ID":3272,"Name":"internal.metrics.executorCpuTime","Value":30340000,"Internal":true,"Count Failed Values":true},{"ID":3275,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3269,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":107,"Completion Time":1629344523522,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":54,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2006, None)) > 0)\n      +- Project [value#2006]\n         +- Relation[value#2006] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2006, None)) > 0)\n      +- Project [value#2006]\n         +- Relation[value#2006] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2006, None)) > 0)\n      +- Relation[value#2006] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2006, None)) > 0)\n   +- *(1) FileScan text [value#2006] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/chicken.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2006, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2006] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/chicken.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/chicken.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3296,"metricType":"sum"},{"name":"number of files","accumulatorId":3297,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3298,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3299,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3295,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3294,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344523565}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":54,"accumUpdates":[[3297,1],[3298,0]]}
{"Event":"SparkListenerJobStart","Job ID":108,"Submission Time":1629344523586,"Stage Infos":[{"Stage ID":108,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":491,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1085\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[490],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":488,"Name":"FileScanRDD","Scope":"{\"id\":\"1081\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":489,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1081\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[488],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":490,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1084\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[489],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[108],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"54","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":108,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":491,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1085\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[490],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":488,"Name":"FileScanRDD","Scope":"{\"id\":\"1081\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":489,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1081\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[488],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":490,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1084\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[489],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523586,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"54","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":108,"Stage Attempt ID":0,"Task Info":{"Task ID":108,"Index":0,"Attempt":0,"Launch Time":1629344523590,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":108,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":108,"Index":0,"Attempt":0,"Launch Time":1629344523590,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344523595,"Failed":false,"Killed":false,"Accumulables":[{"ID":3295,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3296,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3322,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3321,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3304,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3303,"Name":"internal.metrics.executorCpuTime","Update":1533000,"Value":1533000,"Internal":true,"Count Failed Values":true},{"ID":3302,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":3301,"Name":"internal.metrics.executorDeserializeCpuTime","Update":749000,"Value":749000,"Internal":true,"Count Failed Values":true},{"ID":3300,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":749000,"Executor Run Time":3,"Executor CPU Time":1533000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":108,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":491,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1085\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[490],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":488,"Name":"FileScanRDD","Scope":"{\"id\":\"1081\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":489,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1081\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[488],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":490,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1084\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[489],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523586,"Completion Time":1629344523596,"Accumulables":[{"ID":3295,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3322,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3304,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3301,"Name":"internal.metrics.executorDeserializeCpuTime","Value":749000,"Internal":true,"Count Failed Values":true},{"ID":3300,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3321,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3303,"Name":"internal.metrics.executorCpuTime","Value":1533000,"Internal":true,"Count Failed Values":true},{"ID":3302,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":3296,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":108,"Completion Time":1629344523596,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":54,"time":1629344523596}
{"Event":"SparkListenerJobStart","Job ID":109,"Submission Time":1629344523626,"Stage Infos":[{"Stage ID":109,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":496,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1094\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[495],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":494,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1090\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[493],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":495,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1093\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[494],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":493,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1091\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[492],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":492,"Name":"FileScanRDD","Scope":"{\"id\":\"1091\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[109],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1095\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":109,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":496,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1094\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[495],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":494,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1090\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[493],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":495,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1093\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[494],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":493,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1091\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[492],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":492,"Name":"FileScanRDD","Scope":"{\"id\":\"1091\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523627,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1095\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":109,"Stage Attempt ID":0,"Task Info":{"Task ID":109,"Index":0,"Attempt":0,"Launch Time":1629344523631,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":109,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":109,"Index":0,"Attempt":0,"Launch Time":1629344523631,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344523660,"Failed":false,"Killed":false,"Accumulables":[{"ID":3325,"Name":"number of output rows","Update":"2636","Value":"2636","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3329,"Name":"duration total (min, med, max)","Update":"23","Value":"22","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3352,"Name":"internal.metrics.input.recordsRead","Update":2636,"Value":2636,"Internal":true,"Count Failed Values":true},{"ID":3351,"Name":"internal.metrics.input.bytesRead","Update":188989,"Value":188989,"Internal":true,"Count Failed Values":true},{"ID":3334,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3333,"Name":"internal.metrics.executorCpuTime","Update":23212000,"Value":23212000,"Internal":true,"Count Failed Values":true},{"ID":3332,"Name":"internal.metrics.executorRunTime","Update":25,"Value":25,"Internal":true,"Count Failed Values":true},{"ID":3331,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1467000,"Value":1467000,"Internal":true,"Count Failed Values":true},{"ID":3330,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1467000,"Executor Run Time":25,"Executor CPU Time":23212000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":188989,"Records Read":2636},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":109,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":496,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1094\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[495],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":494,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1090\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[493],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":495,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1093\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[494],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":493,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1091\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[492],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":492,"Name":"FileScanRDD","Scope":"{\"id\":\"1091\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523627,"Completion Time":1629344523660,"Accumulables":[{"ID":3331,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1467000,"Internal":true,"Count Failed Values":true},{"ID":3325,"Name":"number of output rows","Value":"2636","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3352,"Name":"internal.metrics.input.recordsRead","Value":2636,"Internal":true,"Count Failed Values":true},{"ID":3334,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3351,"Name":"internal.metrics.input.bytesRead","Value":188989,"Internal":true,"Count Failed Values":true},{"ID":3330,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":3333,"Name":"internal.metrics.executorCpuTime","Value":23212000,"Internal":true,"Count Failed Values":true},{"ID":3332,"Name":"internal.metrics.executorRunTime","Value":25,"Internal":true,"Count Failed Values":true},{"ID":3329,"Name":"duration total (min, med, max)","Value":"22","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":109,"Completion Time":1629344523660,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":55,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2043, None)) > 0)\n      +- Project [value#2043]\n         +- Relation[value#2043] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2043, None)) > 0)\n      +- Project [value#2043]\n         +- Relation[value#2043] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2043, None)) > 0)\n      +- Relation[value#2043] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2043, None)) > 0)\n   +- *(1) FileScan text [value#2043] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ufc.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2043, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2043] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ufc.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ufc.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3357,"metricType":"sum"},{"name":"number of files","accumulatorId":3358,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3359,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3360,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3356,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3355,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344523713}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":55,"accumUpdates":[[3358,1],[3359,0]]}
{"Event":"SparkListenerJobStart","Job ID":110,"Submission Time":1629344523740,"Stage Infos":[{"Stage ID":110,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":500,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1105\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[499],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":497,"Name":"FileScanRDD","Scope":"{\"id\":\"1101\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":498,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1101\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[497],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":499,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1104\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[498],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[110],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"55","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":110,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":500,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1105\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[499],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":497,"Name":"FileScanRDD","Scope":"{\"id\":\"1101\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":498,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1101\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[497],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":499,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1104\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[498],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523740,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"55","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":110,"Stage Attempt ID":0,"Task Info":{"Task ID":110,"Index":0,"Attempt":0,"Launch Time":1629344523744,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":110,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":110,"Index":0,"Attempt":0,"Launch Time":1629344523744,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344523752,"Failed":false,"Killed":false,"Accumulables":[{"ID":3356,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3357,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3383,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3382,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3365,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":3364,"Name":"internal.metrics.executorCpuTime","Update":2373000,"Value":2373000,"Internal":true,"Count Failed Values":true},{"ID":3363,"Name":"internal.metrics.executorRunTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true},{"ID":3362,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1340000,"Value":1340000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":1340000,"Executor Run Time":5,"Executor CPU Time":2373000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":110,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":500,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1105\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[499],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":497,"Name":"FileScanRDD","Scope":"{\"id\":\"1101\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":498,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1101\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[497],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":499,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1104\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[498],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523740,"Completion Time":1629344523752,"Accumulables":[{"ID":3363,"Name":"internal.metrics.executorRunTime","Value":5,"Internal":true,"Count Failed Values":true},{"ID":3357,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3383,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3365,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":3362,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1340000,"Internal":true,"Count Failed Values":true},{"ID":3356,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3382,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3364,"Name":"internal.metrics.executorCpuTime","Value":2373000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":110,"Completion Time":1629344523753,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":55,"time":1629344523754}
{"Event":"SparkListenerJobStart","Job ID":111,"Submission Time":1629344523806,"Stage Infos":[{"Stage ID":111,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":505,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1114\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[504],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":503,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1110\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[502],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":504,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1113\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[503],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":501,"Name":"FileScanRDD","Scope":"{\"id\":\"1111\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":502,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1111\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[501],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[111],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1115\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":111,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":505,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1114\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[504],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":503,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1110\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[502],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":504,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1113\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[503],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":501,"Name":"FileScanRDD","Scope":"{\"id\":\"1111\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":502,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1111\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[501],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523806,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1115\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":111,"Stage Attempt ID":0,"Task Info":{"Task ID":111,"Index":0,"Attempt":0,"Launch Time":1629344523813,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":111,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":111,"Index":0,"Attempt":0,"Launch Time":1629344523813,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344523837,"Failed":false,"Killed":false,"Accumulables":[{"ID":3386,"Name":"number of output rows","Update":"1386","Value":"1386","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3390,"Name":"duration total (min, med, max)","Update":"17","Value":"16","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3413,"Name":"internal.metrics.input.recordsRead","Update":1386,"Value":1386,"Internal":true,"Count Failed Values":true},{"ID":3412,"Name":"internal.metrics.input.bytesRead","Update":104994,"Value":104994,"Internal":true,"Count Failed Values":true},{"ID":3395,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3394,"Name":"internal.metrics.executorCpuTime","Update":17053000,"Value":17053000,"Internal":true,"Count Failed Values":true},{"ID":3393,"Name":"internal.metrics.executorRunTime","Update":20,"Value":20,"Internal":true,"Count Failed Values":true},{"ID":3392,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1854000,"Value":1854000,"Internal":true,"Count Failed Values":true},{"ID":3391,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1854000,"Executor Run Time":20,"Executor CPU Time":17053000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":104994,"Records Read":1386},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":111,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":505,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1114\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[504],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":503,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1110\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[502],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":504,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1113\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[503],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":501,"Name":"FileScanRDD","Scope":"{\"id\":\"1111\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":502,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1111\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[501],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523806,"Completion Time":1629344523838,"Accumulables":[{"ID":3412,"Name":"internal.metrics.input.bytesRead","Value":104994,"Internal":true,"Count Failed Values":true},{"ID":3394,"Name":"internal.metrics.executorCpuTime","Value":17053000,"Internal":true,"Count Failed Values":true},{"ID":3390,"Name":"duration total (min, med, max)","Value":"16","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3393,"Name":"internal.metrics.executorRunTime","Value":20,"Internal":true,"Count Failed Values":true},{"ID":3392,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1854000,"Internal":true,"Count Failed Values":true},{"ID":3386,"Name":"number of output rows","Value":"1386","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3413,"Name":"internal.metrics.input.recordsRead","Value":1386,"Internal":true,"Count Failed Values":true},{"ID":3395,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3391,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":111,"Completion Time":1629344523838,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":56,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2080, None)) > 0)\n      +- Project [value#2080]\n         +- Relation[value#2080] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2080, None)) > 0)\n      +- Project [value#2080]\n         +- Relation[value#2080] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2080, None)) > 0)\n      +- Relation[value#2080] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2080, None)) > 0)\n   +- *(1) FileScan text [value#2080] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ani1_new1.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2080, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2080] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ani1_new1.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ani1_new1.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3418,"metricType":"sum"},{"name":"number of files","accumulatorId":3419,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3420,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3421,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3417,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3416,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344523912}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":56,"accumUpdates":[[3419,1],[3420,0]]}
{"Event":"SparkListenerJobStart","Job ID":112,"Submission Time":1629344523949,"Stage Infos":[{"Stage ID":112,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":509,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1125\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[508],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":506,"Name":"FileScanRDD","Scope":"{\"id\":\"1121\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":508,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1124\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[507],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":507,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1121\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[506],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[112],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"56","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":112,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":509,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1125\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[508],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":506,"Name":"FileScanRDD","Scope":"{\"id\":\"1121\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":508,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1124\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[507],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":507,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1121\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[506],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523951,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"56","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":112,"Stage Attempt ID":0,"Task Info":{"Task ID":112,"Index":0,"Attempt":0,"Launch Time":1629344523957,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":112,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":112,"Index":0,"Attempt":0,"Launch Time":1629344523957,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344523964,"Failed":false,"Killed":false,"Accumulables":[{"ID":3417,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3418,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3444,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3443,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3426,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3425,"Name":"internal.metrics.executorCpuTime","Update":1946000,"Value":1946000,"Internal":true,"Count Failed Values":true},{"ID":3424,"Name":"internal.metrics.executorRunTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true},{"ID":3423,"Name":"internal.metrics.executorDeserializeCpuTime","Update":824000,"Value":824000,"Internal":true,"Count Failed Values":true},{"ID":3422,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":824000,"Executor Run Time":5,"Executor CPU Time":1946000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":112,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":509,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1125\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[508],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":506,"Name":"FileScanRDD","Scope":"{\"id\":\"1121\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":508,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1124\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[507],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":507,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1121\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[506],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344523951,"Completion Time":1629344523964,"Accumulables":[{"ID":3423,"Name":"internal.metrics.executorDeserializeCpuTime","Value":824000,"Internal":true,"Count Failed Values":true},{"ID":3417,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3444,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3426,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3443,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3425,"Name":"internal.metrics.executorCpuTime","Value":1946000,"Internal":true,"Count Failed Values":true},{"ID":3422,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3424,"Name":"internal.metrics.executorRunTime","Value":5,"Internal":true,"Count Failed Values":true},{"ID":3418,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":112,"Completion Time":1629344523964,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":56,"time":1629344523965}
{"Event":"SparkListenerJobStart","Job ID":113,"Submission Time":1629344524032,"Stage Infos":[{"Stage ID":113,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":514,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1134\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[513],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":510,"Name":"FileScanRDD","Scope":"{\"id\":\"1131\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":512,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1130\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[511],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":511,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1131\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[510],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":513,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1133\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[512],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[113],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1135\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":113,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":514,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1134\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[513],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":510,"Name":"FileScanRDD","Scope":"{\"id\":\"1131\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":512,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1130\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[511],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":511,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1131\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[510],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":513,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1133\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[512],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524033,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1135\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":113,"Stage Attempt ID":0,"Task Info":{"Task ID":113,"Index":0,"Attempt":0,"Launch Time":1629344524040,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":113,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":113,"Index":0,"Attempt":0,"Launch Time":1629344524040,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344524100,"Failed":false,"Killed":false,"Accumulables":[{"ID":3447,"Name":"number of output rows","Update":"5578","Value":"5578","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3451,"Name":"duration total (min, med, max)","Update":"54","Value":"53","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3474,"Name":"internal.metrics.input.recordsRead","Update":5578,"Value":5578,"Internal":true,"Count Failed Values":true},{"ID":3473,"Name":"internal.metrics.input.bytesRead","Update":360374,"Value":360374,"Internal":true,"Count Failed Values":true},{"ID":3456,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3455,"Name":"internal.metrics.executorCpuTime","Update":53110000,"Value":53110000,"Internal":true,"Count Failed Values":true},{"ID":3454,"Name":"internal.metrics.executorRunTime","Update":58,"Value":58,"Internal":true,"Count Failed Values":true},{"ID":3453,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1752000,"Value":1752000,"Internal":true,"Count Failed Values":true},{"ID":3452,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1752000,"Executor Run Time":58,"Executor CPU Time":53110000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":360374,"Records Read":5578},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":113,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":514,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1134\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[513],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":510,"Name":"FileScanRDD","Scope":"{\"id\":\"1131\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":512,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1130\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[511],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":511,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1131\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[510],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":513,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1133\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[512],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524033,"Completion Time":1629344524100,"Accumulables":[{"ID":3447,"Name":"number of output rows","Value":"5578","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3474,"Name":"internal.metrics.input.recordsRead","Value":5578,"Internal":true,"Count Failed Values":true},{"ID":3456,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3453,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1752000,"Internal":true,"Count Failed Values":true},{"ID":3452,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3473,"Name":"internal.metrics.input.bytesRead","Value":360374,"Internal":true,"Count Failed Values":true},{"ID":3455,"Name":"internal.metrics.executorCpuTime","Value":53110000,"Internal":true,"Count Failed Values":true},{"ID":3451,"Name":"duration total (min, med, max)","Value":"53","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3454,"Name":"internal.metrics.executorRunTime","Value":58,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":113,"Completion Time":1629344524101,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":57,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2117, None)) > 0)\n      +- Project [value#2117]\n         +- Relation[value#2117] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2117, None)) > 0)\n      +- Project [value#2117]\n         +- Relation[value#2117] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2117, None)) > 0)\n      +- Relation[value#2117] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2117, None)) > 0)\n   +- *(1) FileScan text [value#2117] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/mystery.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2117, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2117] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/mystery.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/mystery.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3479,"metricType":"sum"},{"name":"number of files","accumulatorId":3480,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3481,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3482,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3478,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3477,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344524148}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":57,"accumUpdates":[[3480,1],[3481,0]]}
{"Event":"SparkListenerJobStart","Job ID":114,"Submission Time":1629344524169,"Stage Infos":[{"Stage ID":114,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":518,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1145\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[517],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":517,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1144\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[516],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":516,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1141\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[515],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":515,"Name":"FileScanRDD","Scope":"{\"id\":\"1141\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[114],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"57","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":114,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":518,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1145\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[517],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":517,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1144\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[516],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":516,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1141\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[515],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":515,"Name":"FileScanRDD","Scope":"{\"id\":\"1141\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524170,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"57","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":114,"Stage Attempt ID":0,"Task Info":{"Task ID":114,"Index":0,"Attempt":0,"Launch Time":1629344524173,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":114,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":114,"Index":0,"Attempt":0,"Launch Time":1629344524173,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344524178,"Failed":false,"Killed":false,"Accumulables":[{"ID":3478,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3479,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3505,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3504,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3487,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3486,"Name":"internal.metrics.executorCpuTime","Update":1366000,"Value":1366000,"Internal":true,"Count Failed Values":true},{"ID":3485,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":3484,"Name":"internal.metrics.executorDeserializeCpuTime","Update":642000,"Value":642000,"Internal":true,"Count Failed Values":true},{"ID":3483,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":642000,"Executor Run Time":3,"Executor CPU Time":1366000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":114,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":518,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1145\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[517],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":517,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1144\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[516],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":516,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1141\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[515],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":515,"Name":"FileScanRDD","Scope":"{\"id\":\"1141\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524170,"Completion Time":1629344524178,"Accumulables":[{"ID":3483,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3504,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3486,"Name":"internal.metrics.executorCpuTime","Value":1366000,"Internal":true,"Count Failed Values":true},{"ID":3485,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":3479,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3484,"Name":"internal.metrics.executorDeserializeCpuTime","Value":642000,"Internal":true,"Count Failed Values":true},{"ID":3478,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3505,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3487,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":114,"Completion Time":1629344524178,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":57,"time":1629344524178}
{"Event":"SparkListenerJobStart","Job ID":115,"Submission Time":1629344524206,"Stage Infos":[{"Stage ID":115,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":523,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1154\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[522],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":521,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1150\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[520],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":520,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1151\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[519],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":522,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1153\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[521],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":519,"Name":"FileScanRDD","Scope":"{\"id\":\"1151\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[115],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1155\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":115,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":523,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1154\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[522],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":521,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1150\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[520],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":520,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1151\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[519],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":522,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1153\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[521],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":519,"Name":"FileScanRDD","Scope":"{\"id\":\"1151\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524206,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1155\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":115,"Stage Attempt ID":0,"Task Info":{"Task ID":115,"Index":0,"Attempt":0,"Launch Time":1629344524209,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":115,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":115,"Index":0,"Attempt":0,"Launch Time":1629344524209,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344524229,"Failed":false,"Killed":false,"Accumulables":[{"ID":3508,"Name":"number of output rows","Update":"2125","Value":"2125","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3512,"Name":"duration total (min, med, max)","Update":"15","Value":"14","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3535,"Name":"internal.metrics.input.recordsRead","Update":2125,"Value":2125,"Internal":true,"Count Failed Values":true},{"ID":3534,"Name":"internal.metrics.input.bytesRead","Update":162343,"Value":162343,"Internal":true,"Count Failed Values":true},{"ID":3517,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3516,"Name":"internal.metrics.executorCpuTime","Update":14860000,"Value":14860000,"Internal":true,"Count Failed Values":true},{"ID":3515,"Name":"internal.metrics.executorRunTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":3514,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1108000,"Value":1108000,"Internal":true,"Count Failed Values":true},{"ID":3513,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1108000,"Executor Run Time":17,"Executor CPU Time":14860000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":162343,"Records Read":2125},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":115,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":523,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1154\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[522],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":521,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1150\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[520],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":520,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1151\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[519],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":522,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1153\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[521],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":519,"Name":"FileScanRDD","Scope":"{\"id\":\"1151\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524206,"Completion Time":1629344524229,"Accumulables":[{"ID":3534,"Name":"internal.metrics.input.bytesRead","Value":162343,"Internal":true,"Count Failed Values":true},{"ID":3516,"Name":"internal.metrics.executorCpuTime","Value":14860000,"Internal":true,"Count Failed Values":true},{"ID":3513,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3512,"Name":"duration total (min, med, max)","Value":"14","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3515,"Name":"internal.metrics.executorRunTime","Value":17,"Internal":true,"Count Failed Values":true},{"ID":3508,"Name":"number of output rows","Value":"2125","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3535,"Name":"internal.metrics.input.recordsRead","Value":2125,"Internal":true,"Count Failed Values":true},{"ID":3517,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3514,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1108000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":115,"Completion Time":1629344524229,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":58,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2154, None)) > 0)\n      +- Project [value#2154]\n         +- Relation[value#2154] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2154, None)) > 0)\n      +- Project [value#2154]\n         +- Relation[value#2154] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2154, None)) > 0)\n      +- Relation[value#2154] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2154, None)) > 0)\n   +- *(1) FileScan text [value#2154] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/bike.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2154, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2154] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/bike.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/bike.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3540,"metricType":"sum"},{"name":"number of files","accumulatorId":3541,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3542,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3543,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3539,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3538,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344524284}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":58,"accumUpdates":[[3541,1],[3542,0]]}
{"Event":"SparkListenerJobStart","Job ID":116,"Submission Time":1629344524306,"Stage Infos":[{"Stage ID":116,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":527,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1165\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[526],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":526,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1164\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[525],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":525,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1161\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[524],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":524,"Name":"FileScanRDD","Scope":"{\"id\":\"1161\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[116],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"58","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":116,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":527,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1165\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[526],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":526,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1164\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[525],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":525,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1161\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[524],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":524,"Name":"FileScanRDD","Scope":"{\"id\":\"1161\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524306,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"58","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":116,"Stage Attempt ID":0,"Task Info":{"Task ID":116,"Index":0,"Attempt":0,"Launch Time":1629344524309,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":116,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":116,"Index":0,"Attempt":0,"Launch Time":1629344524309,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344524314,"Failed":false,"Killed":false,"Accumulables":[{"ID":3539,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3540,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3566,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3565,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3548,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3547,"Name":"internal.metrics.executorCpuTime","Update":1541000,"Value":1541000,"Internal":true,"Count Failed Values":true},{"ID":3546,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":3545,"Name":"internal.metrics.executorDeserializeCpuTime","Update":701000,"Value":701000,"Internal":true,"Count Failed Values":true},{"ID":3544,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":701000,"Executor Run Time":3,"Executor CPU Time":1541000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":116,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":527,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1165\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[526],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":526,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1164\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[525],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":525,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1161\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[524],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":524,"Name":"FileScanRDD","Scope":"{\"id\":\"1161\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524306,"Completion Time":1629344524314,"Accumulables":[{"ID":3540,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3546,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":3545,"Name":"internal.metrics.executorDeserializeCpuTime","Value":701000,"Internal":true,"Count Failed Values":true},{"ID":3539,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3566,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3548,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3544,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3565,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3547,"Name":"internal.metrics.executorCpuTime","Value":1541000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":116,"Completion Time":1629344524314,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":58,"time":1629344524315}
{"Event":"SparkListenerJobStart","Job ID":117,"Submission Time":1629344524344,"Stage Infos":[{"Stage ID":117,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":532,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1174\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[531],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":529,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1171\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[528],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":530,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1170\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[529],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":531,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1173\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[530],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":528,"Name":"FileScanRDD","Scope":"{\"id\":\"1171\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[117],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1175\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":117,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":532,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1174\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[531],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":529,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1171\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[528],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":530,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1170\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[529],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":531,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1173\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[530],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":528,"Name":"FileScanRDD","Scope":"{\"id\":\"1171\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524344,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1175\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":117,"Stage Attempt ID":0,"Task Info":{"Task ID":117,"Index":0,"Attempt":0,"Launch Time":1629344524347,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":117,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":117,"Index":0,"Attempt":0,"Launch Time":1629344524347,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344524386,"Failed":false,"Killed":false,"Accumulables":[{"ID":3569,"Name":"number of output rows","Update":"5484","Value":"5484","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3573,"Name":"duration total (min, med, max)","Update":"34","Value":"33","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3596,"Name":"internal.metrics.input.recordsRead","Update":5484,"Value":5484,"Internal":true,"Count Failed Values":true},{"ID":3595,"Name":"internal.metrics.input.bytesRead","Update":364555,"Value":364555,"Internal":true,"Count Failed Values":true},{"ID":3578,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3577,"Name":"internal.metrics.executorCpuTime","Update":33955000,"Value":33955000,"Internal":true,"Count Failed Values":true},{"ID":3576,"Name":"internal.metrics.executorRunTime","Update":36,"Value":36,"Internal":true,"Count Failed Values":true},{"ID":3575,"Name":"internal.metrics.executorDeserializeCpuTime","Update":973000,"Value":973000,"Internal":true,"Count Failed Values":true},{"ID":3574,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":973000,"Executor Run Time":36,"Executor CPU Time":33955000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":364555,"Records Read":5484},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":117,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":532,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1174\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[531],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":529,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1171\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[528],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":530,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1170\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[529],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":531,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1173\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[530],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":528,"Name":"FileScanRDD","Scope":"{\"id\":\"1171\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524344,"Completion Time":1629344524386,"Accumulables":[{"ID":3576,"Name":"internal.metrics.executorRunTime","Value":36,"Internal":true,"Count Failed Values":true},{"ID":3573,"Name":"duration total (min, med, max)","Value":"33","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3575,"Name":"internal.metrics.executorDeserializeCpuTime","Value":973000,"Internal":true,"Count Failed Values":true},{"ID":3569,"Name":"number of output rows","Value":"5484","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3596,"Name":"internal.metrics.input.recordsRead","Value":5484,"Internal":true,"Count Failed Values":true},{"ID":3578,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3595,"Name":"internal.metrics.input.bytesRead","Value":364555,"Internal":true,"Count Failed Values":true},{"ID":3577,"Name":"internal.metrics.executorCpuTime","Value":33955000,"Internal":true,"Count Failed Values":true},{"ID":3574,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":117,"Completion Time":1629344524386,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":59,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2191, None)) > 0)\n      +- Project [value#2191]\n         +- Relation[value#2191] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2191, None)) > 0)\n      +- Project [value#2191]\n         +- Relation[value#2191] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2191, None)) > 0)\n      +- Relation[value#2191] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2191, None)) > 0)\n   +- *(1) FileScan text [value#2191] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/pokemon.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2191, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2191] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/pokemon.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/pokemon.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3601,"metricType":"sum"},{"name":"number of files","accumulatorId":3602,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3603,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3604,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3600,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3599,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344524437}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":59,"accumUpdates":[[3602,1],[3603,0]]}
{"Event":"SparkListenerJobStart","Job ID":118,"Submission Time":1629344524467,"Stage Infos":[{"Stage ID":118,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":536,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1185\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[535],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":534,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1181\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[533],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":535,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1184\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[534],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":533,"Name":"FileScanRDD","Scope":"{\"id\":\"1181\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[118],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"59","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":118,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":536,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1185\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[535],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":534,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1181\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[533],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":535,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1184\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[534],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":533,"Name":"FileScanRDD","Scope":"{\"id\":\"1181\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524468,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"59","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":118,"Stage Attempt ID":0,"Task Info":{"Task ID":118,"Index":0,"Attempt":0,"Launch Time":1629344524476,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":118,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":118,"Index":0,"Attempt":0,"Launch Time":1629344524476,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344524481,"Failed":false,"Killed":false,"Accumulables":[{"ID":3600,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3601,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3627,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3626,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3609,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":3608,"Name":"internal.metrics.executorCpuTime","Update":1707000,"Value":1707000,"Internal":true,"Count Failed Values":true},{"ID":3607,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":3606,"Name":"internal.metrics.executorDeserializeCpuTime","Update":832000,"Value":832000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":832000,"Executor Run Time":3,"Executor CPU Time":1707000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":118,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":536,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1185\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[535],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":534,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1181\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[533],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":535,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1184\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[534],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":533,"Name":"FileScanRDD","Scope":"{\"id\":\"1181\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524468,"Completion Time":1629344524482,"Accumulables":[{"ID":3600,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3627,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3609,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":3606,"Name":"internal.metrics.executorDeserializeCpuTime","Value":832000,"Internal":true,"Count Failed Values":true},{"ID":3626,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3608,"Name":"internal.metrics.executorCpuTime","Value":1707000,"Internal":true,"Count Failed Values":true},{"ID":3607,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":3601,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":118,"Completion Time":1629344524482,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":59,"time":1629344524483}
{"Event":"SparkListenerJobStart","Job ID":119,"Submission Time":1629344524536,"Stage Infos":[{"Stage ID":119,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":541,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1194\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[540],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":537,"Name":"FileScanRDD","Scope":"{\"id\":\"1191\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":540,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1193\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[539],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":539,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1190\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[538],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":538,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1191\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[537],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[119],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1195\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":119,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":541,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1194\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[540],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":537,"Name":"FileScanRDD","Scope":"{\"id\":\"1191\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":540,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1193\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[539],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":539,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1190\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[538],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":538,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1191\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[537],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524536,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1195\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":119,"Stage Attempt ID":0,"Task Info":{"Task ID":119,"Index":0,"Attempt":0,"Launch Time":1629344524542,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":119,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":119,"Index":0,"Attempt":0,"Launch Time":1629344524542,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344524639,"Failed":false,"Killed":false,"Accumulables":[{"ID":3630,"Name":"number of output rows","Update":"11175","Value":"11175","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3634,"Name":"duration total (min, med, max)","Update":"88","Value":"87","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3657,"Name":"internal.metrics.input.recordsRead","Update":11175,"Value":11175,"Internal":true,"Count Failed Values":true},{"ID":3656,"Name":"internal.metrics.input.bytesRead","Update":740657,"Value":740657,"Internal":true,"Count Failed Values":true},{"ID":3639,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3638,"Name":"internal.metrics.executorCpuTime","Update":87554000,"Value":87554000,"Internal":true,"Count Failed Values":true},{"ID":3637,"Name":"internal.metrics.executorRunTime","Update":91,"Value":91,"Internal":true,"Count Failed Values":true},{"ID":3636,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1337000,"Value":1337000,"Internal":true,"Count Failed Values":true},{"ID":3635,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1337000,"Executor Run Time":91,"Executor CPU Time":87554000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":740657,"Records Read":11175},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":119,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":541,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1194\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[540],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":537,"Name":"FileScanRDD","Scope":"{\"id\":\"1191\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":540,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1193\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[539],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":539,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1190\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[538],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":538,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1191\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[537],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524536,"Completion Time":1629344524639,"Accumulables":[{"ID":3636,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1337000,"Internal":true,"Count Failed Values":true},{"ID":3630,"Name":"number of output rows","Value":"11175","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3657,"Name":"internal.metrics.input.recordsRead","Value":11175,"Internal":true,"Count Failed Values":true},{"ID":3639,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3635,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3656,"Name":"internal.metrics.input.bytesRead","Value":740657,"Internal":true,"Count Failed Values":true},{"ID":3638,"Name":"internal.metrics.executorCpuTime","Value":87554000,"Internal":true,"Count Failed Values":true},{"ID":3637,"Name":"internal.metrics.executorRunTime","Value":91,"Internal":true,"Count Failed Values":true},{"ID":3634,"Name":"duration total (min, med, max)","Value":"87","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":119,"Completion Time":1629344524639,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":60,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2228, None)) > 0)\n      +- Project [value#2228]\n         +- Relation[value#2228] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2228, None)) > 0)\n      +- Project [value#2228]\n         +- Relation[value#2228] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2228, None)) > 0)\n      +- Relation[value#2228] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2228, None)) > 0)\n   +- *(1) FileScan text [value#2228] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/sbsdocu.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2228, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2228] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/sbsdocu.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/sbsdocu.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3662,"metricType":"sum"},{"name":"number of files","accumulatorId":3663,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3664,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3665,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3661,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3660,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344524695}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":60,"accumUpdates":[[3663,1],[3664,0]]}
{"Event":"SparkListenerJobStart","Job ID":120,"Submission Time":1629344524718,"Stage Infos":[{"Stage ID":120,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":545,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1205\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[544],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":544,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1204\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[543],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":542,"Name":"FileScanRDD","Scope":"{\"id\":\"1201\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":543,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1201\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[542],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[120],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"60","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":120,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":545,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1205\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[544],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":544,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1204\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[543],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":542,"Name":"FileScanRDD","Scope":"{\"id\":\"1201\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":543,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1201\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[542],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524719,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"60","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":120,"Stage Attempt ID":0,"Task Info":{"Task ID":120,"Index":0,"Attempt":0,"Launch Time":1629344524722,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":120,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":120,"Index":0,"Attempt":0,"Launch Time":1629344524722,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344524728,"Failed":false,"Killed":false,"Accumulables":[{"ID":3661,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3662,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3688,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3687,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3670,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":3669,"Name":"internal.metrics.executorCpuTime","Update":1530000,"Value":1530000,"Internal":true,"Count Failed Values":true},{"ID":3668,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":3667,"Name":"internal.metrics.executorDeserializeCpuTime","Update":709000,"Value":709000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":709000,"Executor Run Time":4,"Executor CPU Time":1530000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":120,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":545,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1205\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[544],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":544,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1204\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[543],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":542,"Name":"FileScanRDD","Scope":"{\"id\":\"1201\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":543,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1201\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[542],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524719,"Completion Time":1629344524728,"Accumulables":[{"ID":3668,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":3662,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3688,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3667,"Name":"internal.metrics.executorDeserializeCpuTime","Value":709000,"Internal":true,"Count Failed Values":true},{"ID":3661,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3670,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":3687,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3669,"Name":"internal.metrics.executorCpuTime","Value":1530000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":120,"Completion Time":1629344524728,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":60,"time":1629344524728}
{"Event":"SparkListenerJobStart","Job ID":121,"Submission Time":1629344524756,"Stage Infos":[{"Stage ID":121,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":550,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1214\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[549],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":549,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1213\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[548],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":546,"Name":"FileScanRDD","Scope":"{\"id\":\"1211\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":548,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1210\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[547],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":547,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1211\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[546],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[121],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1215\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":121,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":550,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1214\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[549],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":549,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1213\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[548],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":546,"Name":"FileScanRDD","Scope":"{\"id\":\"1211\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":548,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1210\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[547],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":547,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1211\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[546],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524756,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1215\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":121,"Stage Attempt ID":0,"Task Info":{"Task ID":121,"Index":0,"Attempt":0,"Launch Time":1629344524758,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":121,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":121,"Index":0,"Attempt":0,"Launch Time":1629344524758,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344524779,"Failed":false,"Killed":false,"Accumulables":[{"ID":3691,"Name":"number of output rows","Update":"1627","Value":"1627","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3695,"Name":"duration total (min, med, max)","Update":"16","Value":"15","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3718,"Name":"internal.metrics.input.recordsRead","Update":1627,"Value":1627,"Internal":true,"Count Failed Values":true},{"ID":3717,"Name":"internal.metrics.input.bytesRead","Update":124214,"Value":124214,"Internal":true,"Count Failed Values":true},{"ID":3700,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3699,"Name":"internal.metrics.executorCpuTime","Update":16234000,"Value":16234000,"Internal":true,"Count Failed Values":true},{"ID":3698,"Name":"internal.metrics.executorRunTime","Update":18,"Value":18,"Internal":true,"Count Failed Values":true},{"ID":3697,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1019000,"Value":1019000,"Internal":true,"Count Failed Values":true},{"ID":3696,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1019000,"Executor Run Time":18,"Executor CPU Time":16234000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":124214,"Records Read":1627},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":121,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":550,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1214\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[549],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":549,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1213\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[548],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":546,"Name":"FileScanRDD","Scope":"{\"id\":\"1211\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":548,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1210\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[547],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":547,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1211\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[546],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524756,"Completion Time":1629344524780,"Accumulables":[{"ID":3717,"Name":"internal.metrics.input.bytesRead","Value":124214,"Internal":true,"Count Failed Values":true},{"ID":3699,"Name":"internal.metrics.executorCpuTime","Value":16234000,"Internal":true,"Count Failed Values":true},{"ID":3695,"Name":"duration total (min, med, max)","Value":"15","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3698,"Name":"internal.metrics.executorRunTime","Value":18,"Internal":true,"Count Failed Values":true},{"ID":3697,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1019000,"Internal":true,"Count Failed Values":true},{"ID":3691,"Name":"number of output rows","Value":"1627","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3718,"Name":"internal.metrics.input.recordsRead","Value":1627,"Internal":true,"Count Failed Values":true},{"ID":3700,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3696,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":121,"Completion Time":1629344524780,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":61,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2265, None)) > 0)\n      +- Project [value#2265]\n         +- Relation[value#2265] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2265, None)) > 0)\n      +- Project [value#2265]\n         +- Relation[value#2265] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2265, None)) > 0)\n      +- Relation[value#2265] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2265, None)) > 0)\n   +- *(1) FileScan text [value#2265] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/sdvx.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2265, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2265] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/sdvx.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/sdvx.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3723,"metricType":"sum"},{"name":"number of files","accumulatorId":3724,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3725,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3726,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3722,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3721,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344524826}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":61,"accumUpdates":[[3724,1],[3725,0]]}
{"Event":"SparkListenerJobStart","Job ID":122,"Submission Time":1629344524851,"Stage Infos":[{"Stage ID":122,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":554,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1225\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[553],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":552,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1221\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[551],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":551,"Name":"FileScanRDD","Scope":"{\"id\":\"1221\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":553,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1224\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[552],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[122],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"61","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":122,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":554,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1225\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[553],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":552,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1221\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[551],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":551,"Name":"FileScanRDD","Scope":"{\"id\":\"1221\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":553,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1224\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[552],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524853,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"61","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":122,"Stage Attempt ID":0,"Task Info":{"Task ID":122,"Index":0,"Attempt":0,"Launch Time":1629344524856,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":122,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":122,"Index":0,"Attempt":0,"Launch Time":1629344524856,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344524862,"Failed":false,"Killed":false,"Accumulables":[{"ID":3722,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3723,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3749,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3748,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3731,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3730,"Name":"internal.metrics.executorCpuTime","Update":1563000,"Value":1563000,"Internal":true,"Count Failed Values":true},{"ID":3729,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":3728,"Name":"internal.metrics.executorDeserializeCpuTime","Update":799000,"Value":799000,"Internal":true,"Count Failed Values":true},{"ID":3727,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":799000,"Executor Run Time":3,"Executor CPU Time":1563000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":122,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":554,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1225\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[553],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":552,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1221\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[551],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":551,"Name":"FileScanRDD","Scope":"{\"id\":\"1221\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":553,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1224\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[552],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524853,"Completion Time":1629344524862,"Accumulables":[{"ID":3728,"Name":"internal.metrics.executorDeserializeCpuTime","Value":799000,"Internal":true,"Count Failed Values":true},{"ID":3722,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3749,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3731,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3748,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3727,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3730,"Name":"internal.metrics.executorCpuTime","Value":1563000,"Internal":true,"Count Failed Values":true},{"ID":3729,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":3723,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":122,"Completion Time":1629344524862,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":61,"time":1629344524862}
{"Event":"SparkListenerJobStart","Job ID":123,"Submission Time":1629344524892,"Stage Infos":[{"Stage ID":123,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":559,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1234\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[558],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":558,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1233\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[557],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":556,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1231\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[555],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":557,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1230\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[556],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":555,"Name":"FileScanRDD","Scope":"{\"id\":\"1231\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[123],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1235\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":123,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":559,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1234\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[558],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":558,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1233\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[557],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":556,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1231\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[555],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":557,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1230\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[556],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":555,"Name":"FileScanRDD","Scope":"{\"id\":\"1231\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524892,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1235\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":123,"Stage Attempt ID":0,"Task Info":{"Task ID":123,"Index":0,"Attempt":0,"Launch Time":1629344524895,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":123,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":123,"Index":0,"Attempt":0,"Launch Time":1629344524895,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344524922,"Failed":false,"Killed":false,"Accumulables":[{"ID":3752,"Name":"number of output rows","Update":"3450","Value":"3450","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3756,"Name":"duration total (min, med, max)","Update":"22","Value":"21","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3779,"Name":"internal.metrics.input.recordsRead","Update":3450,"Value":3450,"Internal":true,"Count Failed Values":true},{"ID":3778,"Name":"internal.metrics.input.bytesRead","Update":199621,"Value":199621,"Internal":true,"Count Failed Values":true},{"ID":3761,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3760,"Name":"internal.metrics.executorCpuTime","Update":22023000,"Value":22023000,"Internal":true,"Count Failed Values":true},{"ID":3759,"Name":"internal.metrics.executorRunTime","Update":24,"Value":24,"Internal":true,"Count Failed Values":true},{"ID":3758,"Name":"internal.metrics.executorDeserializeCpuTime","Update":956000,"Value":956000,"Internal":true,"Count Failed Values":true},{"ID":3757,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":956000,"Executor Run Time":24,"Executor CPU Time":22023000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":199621,"Records Read":3450},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":123,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":559,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1234\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[558],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":558,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1233\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[557],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":556,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1231\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[555],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":557,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1230\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[556],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":555,"Name":"FileScanRDD","Scope":"{\"id\":\"1231\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524892,"Completion Time":1629344524922,"Accumulables":[{"ID":3752,"Name":"number of output rows","Value":"3450","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3779,"Name":"internal.metrics.input.recordsRead","Value":3450,"Internal":true,"Count Failed Values":true},{"ID":3761,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":3758,"Name":"internal.metrics.executorDeserializeCpuTime","Value":956000,"Internal":true,"Count Failed Values":true},{"ID":3757,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":3778,"Name":"internal.metrics.input.bytesRead","Value":199621,"Internal":true,"Count Failed Values":true},{"ID":3760,"Name":"internal.metrics.executorCpuTime","Value":22023000,"Internal":true,"Count Failed Values":true},{"ID":3756,"Name":"duration total (min, med, max)","Value":"21","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3759,"Name":"internal.metrics.executorRunTime","Value":24,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":123,"Completion Time":1629344524922,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":62,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2302, None)) > 0)\n      +- Project [value#2302]\n         +- Relation[value#2302] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2302, None)) > 0)\n      +- Project [value#2302]\n         +- Relation[value#2302] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2302, None)) > 0)\n      +- Relation[value#2302] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2302, None)) > 0)\n   +- *(1) FileScan text [value#2302] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/toy.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2302, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2302] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/toy.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/toy.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3784,"metricType":"sum"},{"name":"number of files","accumulatorId":3785,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3786,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3787,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3783,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3782,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344524970}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":62,"accumUpdates":[[3785,1],[3786,0]]}
{"Event":"SparkListenerJobStart","Job ID":124,"Submission Time":1629344524991,"Stage Infos":[{"Stage ID":124,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":563,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1245\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[562],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":562,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1244\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[561],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":560,"Name":"FileScanRDD","Scope":"{\"id\":\"1241\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":561,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1241\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[560],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[124],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"62","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":124,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":563,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1245\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[562],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":562,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1244\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[561],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":560,"Name":"FileScanRDD","Scope":"{\"id\":\"1241\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":561,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1241\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[560],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524992,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"62","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":124,"Stage Attempt ID":0,"Task Info":{"Task ID":124,"Index":0,"Attempt":0,"Launch Time":1629344524995,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":124,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":124,"Index":0,"Attempt":0,"Launch Time":1629344524995,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344525000,"Failed":false,"Killed":false,"Accumulables":[{"ID":3783,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3784,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3810,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3809,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3792,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3791,"Name":"internal.metrics.executorCpuTime","Update":1753000,"Value":1753000,"Internal":true,"Count Failed Values":true},{"ID":3790,"Name":"internal.metrics.executorRunTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true},{"ID":3789,"Name":"internal.metrics.executorDeserializeCpuTime","Update":695000,"Value":695000,"Internal":true,"Count Failed Values":true},{"ID":3788,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":695000,"Executor Run Time":2,"Executor CPU Time":1753000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":124,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":563,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1245\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[562],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":562,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1244\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[561],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":560,"Name":"FileScanRDD","Scope":"{\"id\":\"1241\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":561,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1241\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[560],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344524992,"Completion Time":1629344525000,"Accumulables":[{"ID":3788,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3809,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3791,"Name":"internal.metrics.executorCpuTime","Value":1753000,"Internal":true,"Count Failed Values":true},{"ID":3784,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3790,"Name":"internal.metrics.executorRunTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":3789,"Name":"internal.metrics.executorDeserializeCpuTime","Value":695000,"Internal":true,"Count Failed Values":true},{"ID":3783,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3810,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3792,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":124,"Completion Time":1629344525001,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":62,"time":1629344525001}
{"Event":"SparkListenerJobStart","Job ID":125,"Submission Time":1629344525030,"Stage Infos":[{"Stage ID":125,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":568,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1254\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[567],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":565,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1251\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[564],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":567,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1253\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[566],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":564,"Name":"FileScanRDD","Scope":"{\"id\":\"1251\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":566,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1250\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[565],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[125],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1255\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":125,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":568,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1254\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[567],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":565,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1251\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[564],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":567,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1253\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[566],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":564,"Name":"FileScanRDD","Scope":"{\"id\":\"1251\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":566,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1250\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[565],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525031,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1255\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":125,"Stage Attempt ID":0,"Task Info":{"Task ID":125,"Index":0,"Attempt":0,"Launch Time":1629344525034,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":125,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":125,"Index":0,"Attempt":0,"Launch Time":1629344525034,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344525073,"Failed":false,"Killed":false,"Accumulables":[{"ID":3813,"Name":"number of output rows","Update":"5596","Value":"5596","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3817,"Name":"duration total (min, med, max)","Update":"34","Value":"33","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3840,"Name":"internal.metrics.input.recordsRead","Update":5596,"Value":5596,"Internal":true,"Count Failed Values":true},{"ID":3839,"Name":"internal.metrics.input.bytesRead","Update":362923,"Value":362923,"Internal":true,"Count Failed Values":true},{"ID":3822,"Name":"internal.metrics.resultSize","Update":1485,"Value":1485,"Internal":true,"Count Failed Values":true},{"ID":3821,"Name":"internal.metrics.executorCpuTime","Update":33901000,"Value":33901000,"Internal":true,"Count Failed Values":true},{"ID":3820,"Name":"internal.metrics.executorRunTime","Update":37,"Value":37,"Internal":true,"Count Failed Values":true},{"ID":3819,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1035000,"Value":1035000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":1035000,"Executor Run Time":37,"Executor CPU Time":33901000,"Result Size":1485,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":362923,"Records Read":5596},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":125,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":568,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1254\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[567],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":565,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1251\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[564],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":567,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1253\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[566],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":564,"Name":"FileScanRDD","Scope":"{\"id\":\"1251\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":566,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1250\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[565],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525031,"Completion Time":1629344525073,"Accumulables":[{"ID":3839,"Name":"internal.metrics.input.bytesRead","Value":362923,"Internal":true,"Count Failed Values":true},{"ID":3821,"Name":"internal.metrics.executorCpuTime","Value":33901000,"Internal":true,"Count Failed Values":true},{"ID":3817,"Name":"duration total (min, med, max)","Value":"33","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3820,"Name":"internal.metrics.executorRunTime","Value":37,"Internal":true,"Count Failed Values":true},{"ID":3840,"Name":"internal.metrics.input.recordsRead","Value":5596,"Internal":true,"Count Failed Values":true},{"ID":3819,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1035000,"Internal":true,"Count Failed Values":true},{"ID":3813,"Name":"number of output rows","Value":"5596","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3822,"Name":"internal.metrics.resultSize","Value":1485,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":125,"Completion Time":1629344525073,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":63,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2339, None)) > 0)\n      +- Project [value#2339]\n         +- Relation[value#2339] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2339, None)) > 0)\n      +- Project [value#2339]\n         +- Relation[value#2339] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2339, None)) > 0)\n      +- Relation[value#2339] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2339, None)) > 0)\n   +- *(1) FileScan text [value#2339] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/gongik_new.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2339, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2339] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/gongik_new.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/gongik_new.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3845,"metricType":"sum"},{"name":"number of files","accumulatorId":3846,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3847,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3848,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3844,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3843,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344525122}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":63,"accumUpdates":[[3846,1],[3847,0]]}
{"Event":"SparkListenerJobStart","Job ID":126,"Submission Time":1629344525145,"Stage Infos":[{"Stage ID":126,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":572,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1265\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[571],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":571,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1264\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[570],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":569,"Name":"FileScanRDD","Scope":"{\"id\":\"1261\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":570,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1261\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[569],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[126],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"63","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":126,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":572,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1265\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[571],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":571,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1264\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[570],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":569,"Name":"FileScanRDD","Scope":"{\"id\":\"1261\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":570,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1261\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[569],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525146,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"63","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":126,"Stage Attempt ID":0,"Task Info":{"Task ID":126,"Index":0,"Attempt":0,"Launch Time":1629344525149,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":126,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":126,"Index":0,"Attempt":0,"Launch Time":1629344525149,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344525154,"Failed":false,"Killed":false,"Accumulables":[{"ID":3844,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3845,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3871,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3870,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3853,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3852,"Name":"internal.metrics.executorCpuTime","Update":1513000,"Value":1513000,"Internal":true,"Count Failed Values":true},{"ID":3851,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":3850,"Name":"internal.metrics.executorDeserializeCpuTime","Update":742000,"Value":742000,"Internal":true,"Count Failed Values":true},{"ID":3849,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":742000,"Executor Run Time":3,"Executor CPU Time":1513000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":126,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":572,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1265\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[571],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":571,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1264\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[570],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":569,"Name":"FileScanRDD","Scope":"{\"id\":\"1261\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":570,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1261\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[569],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525146,"Completion Time":1629344525155,"Accumulables":[{"ID":3845,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3851,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":3844,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3871,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3853,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3850,"Name":"internal.metrics.executorDeserializeCpuTime","Value":742000,"Internal":true,"Count Failed Values":true},{"ID":3849,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3870,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3852,"Name":"internal.metrics.executorCpuTime","Value":1513000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":126,"Completion Time":1629344525155,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":63,"time":1629344525155}
{"Event":"SparkListenerJobStart","Job ID":127,"Submission Time":1629344525184,"Stage Infos":[{"Stage ID":127,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":577,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1274\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[576],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":575,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1270\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[574],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":574,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1271\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[573],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":573,"Name":"FileScanRDD","Scope":"{\"id\":\"1271\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":576,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1273\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[575],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[127],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1275\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":127,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":577,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1274\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[576],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":575,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1270\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[574],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":574,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1271\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[573],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":573,"Name":"FileScanRDD","Scope":"{\"id\":\"1271\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":576,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1273\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[575],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525184,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1275\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":127,"Stage Attempt ID":0,"Task Info":{"Task ID":127,"Index":0,"Attempt":0,"Launch Time":1629344525187,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":127,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":127,"Index":0,"Attempt":0,"Launch Time":1629344525187,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344525217,"Failed":false,"Killed":false,"Accumulables":[{"ID":3874,"Name":"number of output rows","Update":"3932","Value":"3932","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3878,"Name":"duration total (min, med, max)","Update":"25","Value":"24","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3901,"Name":"internal.metrics.input.recordsRead","Update":3932,"Value":3932,"Internal":true,"Count Failed Values":true},{"ID":3900,"Name":"internal.metrics.input.bytesRead","Update":283995,"Value":283995,"Internal":true,"Count Failed Values":true},{"ID":3885,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3883,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":3882,"Name":"internal.metrics.executorCpuTime","Update":24803000,"Value":24803000,"Internal":true,"Count Failed Values":true},{"ID":3881,"Name":"internal.metrics.executorRunTime","Update":27,"Value":27,"Internal":true,"Count Failed Values":true},{"ID":3880,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1073000,"Value":1073000,"Internal":true,"Count Failed Values":true},{"ID":3879,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1073000,"Executor Run Time":27,"Executor CPU Time":24803000,"Result Size":1571,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":283995,"Records Read":3932},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":127,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":577,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1274\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[576],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":575,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1270\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[574],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":574,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1271\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[573],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":573,"Name":"FileScanRDD","Scope":"{\"id\":\"1271\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":576,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1273\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[575],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525184,"Completion Time":1629344525218,"Accumulables":[{"ID":3881,"Name":"internal.metrics.executorRunTime","Value":27,"Internal":true,"Count Failed Values":true},{"ID":3878,"Name":"duration total (min, med, max)","Value":"24","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3880,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1073000,"Internal":true,"Count Failed Values":true},{"ID":3874,"Name":"number of output rows","Value":"3932","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3901,"Name":"internal.metrics.input.recordsRead","Value":3932,"Internal":true,"Count Failed Values":true},{"ID":3883,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true},{"ID":3900,"Name":"internal.metrics.input.bytesRead","Value":283995,"Internal":true,"Count Failed Values":true},{"ID":3885,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3879,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":3882,"Name":"internal.metrics.executorCpuTime","Value":24803000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":127,"Completion Time":1629344525218,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":64,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2376, None)) > 0)\n      +- Project [value#2376]\n         +- Relation[value#2376] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2376, None)) > 0)\n      +- Project [value#2376]\n         +- Relation[value#2376] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2376, None)) > 0)\n      +- Relation[value#2376] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2376, None)) > 0)\n   +- *(1) FileScan text [value#2376] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lovegame.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2376, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2376] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lovegame.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lovegame.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3906,"metricType":"sum"},{"name":"number of files","accumulatorId":3907,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3908,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3909,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3905,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3904,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344525266}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":64,"accumUpdates":[[3907,1],[3908,0]]}
{"Event":"SparkListenerJobStart","Job ID":128,"Submission Time":1629344525288,"Stage Infos":[{"Stage ID":128,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":581,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1285\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[580],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":579,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1281\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[578],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":580,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1284\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[579],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":578,"Name":"FileScanRDD","Scope":"{\"id\":\"1281\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[128],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"64","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":128,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":581,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1285\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[580],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":579,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1281\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[578],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":580,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1284\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[579],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":578,"Name":"FileScanRDD","Scope":"{\"id\":\"1281\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525288,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"64","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":128,"Stage Attempt ID":0,"Task Info":{"Task ID":128,"Index":0,"Attempt":0,"Launch Time":1629344525291,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":128,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":128,"Index":0,"Attempt":0,"Launch Time":1629344525291,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344525295,"Failed":false,"Killed":false,"Accumulables":[{"ID":3905,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3906,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3932,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3931,"Name":"internal.metrics.input.bytesRead","Update":43,"Value":43,"Internal":true,"Count Failed Values":true},{"ID":3914,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":3913,"Name":"internal.metrics.executorCpuTime","Update":1564000,"Value":1564000,"Internal":true,"Count Failed Values":true},{"ID":3912,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":3911,"Name":"internal.metrics.executorDeserializeCpuTime","Update":790000,"Value":790000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":790000,"Executor Run Time":3,"Executor CPU Time":1564000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":43,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":128,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":581,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1285\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[580],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":579,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1281\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[578],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":580,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1284\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[579],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":578,"Name":"FileScanRDD","Scope":"{\"id\":\"1281\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525288,"Completion Time":1629344525295,"Accumulables":[{"ID":3905,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3932,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3914,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":3911,"Name":"internal.metrics.executorDeserializeCpuTime","Value":790000,"Internal":true,"Count Failed Values":true},{"ID":3931,"Name":"internal.metrics.input.bytesRead","Value":43,"Internal":true,"Count Failed Values":true},{"ID":3913,"Name":"internal.metrics.executorCpuTime","Value":1564000,"Internal":true,"Count Failed Values":true},{"ID":3912,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":3906,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":128,"Completion Time":1629344525295,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":64,"time":1629344525296}
{"Event":"SparkListenerJobStart","Job ID":129,"Submission Time":1629344525332,"Stage Infos":[{"Stage ID":129,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":586,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1294\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[585],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":582,"Name":"FileScanRDD","Scope":"{\"id\":\"1291\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":584,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1290\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[583],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":583,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1291\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[582],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":585,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1293\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[584],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[129],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1295\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":129,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":586,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1294\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[585],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":582,"Name":"FileScanRDD","Scope":"{\"id\":\"1291\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":584,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1290\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[583],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":583,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1291\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[582],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":585,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1293\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[584],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525332,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1295\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":129,"Stage Attempt ID":0,"Task Info":{"Task ID":129,"Index":0,"Attempt":0,"Launch Time":1629344525339,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":129,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":129,"Index":0,"Attempt":0,"Launch Time":1629344525339,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344525347,"Failed":false,"Killed":false,"Accumulables":[{"ID":3935,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3939,"Name":"duration total (min, med, max)","Update":"2","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3962,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3961,"Name":"internal.metrics.input.bytesRead","Update":43,"Value":43,"Internal":true,"Count Failed Values":true},{"ID":3944,"Name":"internal.metrics.resultSize","Update":1446,"Value":1446,"Internal":true,"Count Failed Values":true},{"ID":3943,"Name":"internal.metrics.executorCpuTime","Update":3435000,"Value":3435000,"Internal":true,"Count Failed Values":true},{"ID":3942,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":3941,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1987000,"Value":1987000,"Internal":true,"Count Failed Values":true},{"ID":3940,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1987000,"Executor Run Time":3,"Executor CPU Time":3435000,"Result Size":1446,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":43,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":129,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":586,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1294\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[585],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":582,"Name":"FileScanRDD","Scope":"{\"id\":\"1291\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":584,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1290\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[583],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":583,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1291\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[582],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":585,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1293\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[584],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525332,"Completion Time":1629344525347,"Accumulables":[{"ID":3941,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1987000,"Internal":true,"Count Failed Values":true},{"ID":3935,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3962,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3944,"Name":"internal.metrics.resultSize","Value":1446,"Internal":true,"Count Failed Values":true},{"ID":3940,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":3961,"Name":"internal.metrics.input.bytesRead","Value":43,"Internal":true,"Count Failed Values":true},{"ID":3943,"Name":"internal.metrics.executorCpuTime","Value":3435000,"Internal":true,"Count Failed Values":true},{"ID":3942,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":3939,"Name":"duration total (min, med, max)","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":129,"Completion Time":1629344525347,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":65,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2412, None)) > 0)\n      +- Project [value#2412]\n         +- Relation[value#2412] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2412, None)) > 0)\n      +- Project [value#2412]\n         +- Relation[value#2412] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2412, None)) > 0)\n      +- Relation[value#2412] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2412, None)) > 0)\n   +- *(1) FileScan text [value#2412] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/kart.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2412, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2412] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/kart.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/kart.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":3967,"metricType":"sum"},{"name":"number of files","accumulatorId":3968,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":3969,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":3970,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3966,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":3965,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344525405}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":65,"accumUpdates":[[3968,1],[3969,0]]}
{"Event":"SparkListenerJobStart","Job ID":130,"Submission Time":1629344525442,"Stage Infos":[{"Stage ID":130,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":590,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1305\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[589],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":587,"Name":"FileScanRDD","Scope":"{\"id\":\"1301\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":588,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1301\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[587],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":589,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1304\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[588],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[130],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"65","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":130,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":590,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1305\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[589],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":587,"Name":"FileScanRDD","Scope":"{\"id\":\"1301\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":588,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1301\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[587],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":589,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1304\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[588],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525442,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"65","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":130,"Stage Attempt ID":0,"Task Info":{"Task ID":130,"Index":0,"Attempt":0,"Launch Time":1629344525446,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":130,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":130,"Index":0,"Attempt":0,"Launch Time":1629344525446,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344525455,"Failed":false,"Killed":false,"Accumulables":[{"ID":3966,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3967,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3993,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":3992,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3975,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3974,"Name":"internal.metrics.executorCpuTime","Update":3351000,"Value":3351000,"Internal":true,"Count Failed Values":true},{"ID":3973,"Name":"internal.metrics.executorRunTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true},{"ID":3972,"Name":"internal.metrics.executorDeserializeCpuTime","Update":952000,"Value":952000,"Internal":true,"Count Failed Values":true},{"ID":3971,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":952000,"Executor Run Time":5,"Executor CPU Time":3351000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":130,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":590,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1305\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[589],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":587,"Name":"FileScanRDD","Scope":"{\"id\":\"1301\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":588,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1301\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[587],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":589,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1304\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[588],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525442,"Completion Time":1629344525456,"Accumulables":[{"ID":3971,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3973,"Name":"internal.metrics.executorRunTime","Value":5,"Internal":true,"Count Failed Values":true},{"ID":3967,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3972,"Name":"internal.metrics.executorDeserializeCpuTime","Value":952000,"Internal":true,"Count Failed Values":true},{"ID":3966,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3993,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":3975,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":3992,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":3974,"Name":"internal.metrics.executorCpuTime","Value":3351000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":130,"Completion Time":1629344525456,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":65,"time":1629344525457}
{"Event":"SparkListenerJobStart","Job ID":131,"Submission Time":1629344525506,"Stage Infos":[{"Stage ID":131,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":595,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1314\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[594],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":592,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1311\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[591],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":594,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1313\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[593],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":591,"Name":"FileScanRDD","Scope":"{\"id\":\"1311\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":593,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1310\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[592],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[131],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1315\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":131,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":595,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1314\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[594],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":592,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1311\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[591],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":594,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1313\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[593],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":591,"Name":"FileScanRDD","Scope":"{\"id\":\"1311\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":593,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1310\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[592],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525507,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1315\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":131,"Stage Attempt ID":0,"Task Info":{"Task ID":131,"Index":0,"Attempt":0,"Launch Time":1629344525511,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":131,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":131,"Index":0,"Attempt":0,"Launch Time":1629344525511,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344525538,"Failed":false,"Killed":false,"Accumulables":[{"ID":3996,"Name":"number of output rows","Update":"2412","Value":"2412","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4000,"Name":"duration total (min, med, max)","Update":"22","Value":"21","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4023,"Name":"internal.metrics.input.recordsRead","Update":2412,"Value":2412,"Internal":true,"Count Failed Values":true},{"ID":4022,"Name":"internal.metrics.input.bytesRead","Update":176023,"Value":176023,"Internal":true,"Count Failed Values":true},{"ID":4005,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4004,"Name":"internal.metrics.executorCpuTime","Update":22151000,"Value":22151000,"Internal":true,"Count Failed Values":true},{"ID":4003,"Name":"internal.metrics.executorRunTime","Update":23,"Value":23,"Internal":true,"Count Failed Values":true},{"ID":4002,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1077000,"Value":1077000,"Internal":true,"Count Failed Values":true},{"ID":4001,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1077000,"Executor Run Time":23,"Executor CPU Time":22151000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":176023,"Records Read":2412},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":131,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":595,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1314\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[594],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":592,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1311\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[591],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":594,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1313\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[593],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":591,"Name":"FileScanRDD","Scope":"{\"id\":\"1311\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":593,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1310\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[592],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525507,"Completion Time":1629344525538,"Accumulables":[{"ID":4022,"Name":"internal.metrics.input.bytesRead","Value":176023,"Internal":true,"Count Failed Values":true},{"ID":4004,"Name":"internal.metrics.executorCpuTime","Value":22151000,"Internal":true,"Count Failed Values":true},{"ID":4000,"Name":"duration total (min, med, max)","Value":"21","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4003,"Name":"internal.metrics.executorRunTime","Value":23,"Internal":true,"Count Failed Values":true},{"ID":4002,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1077000,"Internal":true,"Count Failed Values":true},{"ID":3996,"Name":"number of output rows","Value":"2412","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4023,"Name":"internal.metrics.input.recordsRead","Value":2412,"Internal":true,"Count Failed Values":true},{"ID":4005,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4001,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":131,"Completion Time":1629344525538,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":66,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2449, None)) > 0)\n      +- Project [value#2449]\n         +- Relation[value#2449] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2449, None)) > 0)\n      +- Project [value#2449]\n         +- Relation[value#2449] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2449, None)) > 0)\n      +- Relation[value#2449] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2449, None)) > 0)\n   +- *(1) FileScan text [value#2449] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/leagueoflege..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2449, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2449] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/leagueoflege..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/leagueoflegends4.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4028,"metricType":"sum"},{"name":"number of files","accumulatorId":4029,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4030,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4031,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4027,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4026,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344525593}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":66,"accumUpdates":[[4029,1],[4030,0]]}
{"Event":"SparkListenerJobStart","Job ID":132,"Submission Time":1629344525615,"Stage Infos":[{"Stage ID":132,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":599,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1325\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[598],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":597,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1321\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[596],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":596,"Name":"FileScanRDD","Scope":"{\"id\":\"1321\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":598,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1324\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[597],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[132],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"66","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":132,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":599,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1325\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[598],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":597,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1321\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[596],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":596,"Name":"FileScanRDD","Scope":"{\"id\":\"1321\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":598,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1324\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[597],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525615,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"66","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":132,"Stage Attempt ID":0,"Task Info":{"Task ID":132,"Index":0,"Attempt":0,"Launch Time":1629344525618,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":132,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":132,"Index":0,"Attempt":0,"Launch Time":1629344525618,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344525623,"Failed":false,"Killed":false,"Accumulables":[{"ID":4027,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4028,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4054,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4053,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4036,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":4035,"Name":"internal.metrics.executorCpuTime","Update":1435000,"Value":1435000,"Internal":true,"Count Failed Values":true},{"ID":4034,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":4033,"Name":"internal.metrics.executorDeserializeCpuTime","Update":655000,"Value":655000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":655000,"Executor Run Time":4,"Executor CPU Time":1435000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":132,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":599,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1325\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[598],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":597,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1321\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[596],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":596,"Name":"FileScanRDD","Scope":"{\"id\":\"1321\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":598,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1324\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[597],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525615,"Completion Time":1629344525623,"Accumulables":[{"ID":4033,"Name":"internal.metrics.executorDeserializeCpuTime","Value":655000,"Internal":true,"Count Failed Values":true},{"ID":4027,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4054,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4036,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":4053,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4035,"Name":"internal.metrics.executorCpuTime","Value":1435000,"Internal":true,"Count Failed Values":true},{"ID":4034,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":4028,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":132,"Completion Time":1629344525623,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":66,"time":1629344525624}
{"Event":"SparkListenerJobStart","Job ID":133,"Submission Time":1629344525654,"Stage Infos":[{"Stage ID":133,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":604,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1334\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[603],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":603,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1333\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[602],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":601,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1331\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[600],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":602,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1330\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[601],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":600,"Name":"FileScanRDD","Scope":"{\"id\":\"1331\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[133],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1335\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":133,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":604,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1334\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[603],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":603,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1333\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[602],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":601,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1331\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[600],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":602,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1330\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[601],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":600,"Name":"FileScanRDD","Scope":"{\"id\":\"1331\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525654,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1335\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":133,"Stage Attempt ID":0,"Task Info":{"Task ID":133,"Index":0,"Attempt":0,"Launch Time":1629344525657,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":133,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":133,"Index":0,"Attempt":0,"Launch Time":1629344525657,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344525943,"Failed":false,"Killed":false,"Accumulables":[{"ID":4057,"Name":"number of output rows","Update":"39209","Value":"39209","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4061,"Name":"duration total (min, med, max)","Update":"281","Value":"280","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4084,"Name":"internal.metrics.input.recordsRead","Update":39209,"Value":39209,"Internal":true,"Count Failed Values":true},{"ID":4083,"Name":"internal.metrics.input.bytesRead","Update":3033440,"Value":3033440,"Internal":true,"Count Failed Values":true},{"ID":4068,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4066,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":4065,"Name":"internal.metrics.executorCpuTime","Update":280232000,"Value":280232000,"Internal":true,"Count Failed Values":true},{"ID":4064,"Name":"internal.metrics.executorRunTime","Update":282,"Value":282,"Internal":true,"Count Failed Values":true},{"ID":4063,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1026000,"Value":1026000,"Internal":true,"Count Failed Values":true},{"ID":4062,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1026000,"Executor Run Time":282,"Executor CPU Time":280232000,"Result Size":1571,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":3033440,"Records Read":39209},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":133,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":604,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1334\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[603],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":603,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1333\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[602],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":601,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1331\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[600],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":602,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1330\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[601],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":600,"Name":"FileScanRDD","Scope":"{\"id\":\"1331\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344525654,"Completion Time":1629344525943,"Accumulables":[{"ID":4057,"Name":"number of output rows","Value":"39209","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4084,"Name":"internal.metrics.input.recordsRead","Value":39209,"Internal":true,"Count Failed Values":true},{"ID":4066,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true},{"ID":4063,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1026000,"Internal":true,"Count Failed Values":true},{"ID":4062,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":4083,"Name":"internal.metrics.input.bytesRead","Value":3033440,"Internal":true,"Count Failed Values":true},{"ID":4065,"Name":"internal.metrics.executorCpuTime","Value":280232000,"Internal":true,"Count Failed Values":true},{"ID":4068,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4061,"Name":"duration total (min, med, max)","Value":"280","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4064,"Name":"internal.metrics.executorRunTime","Value":282,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":133,"Completion Time":1629344525943,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":67,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2486, None)) > 0)\n      +- Project [value#2486]\n         +- Relation[value#2486] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2486, None)) > 0)\n      +- Project [value#2486]\n         +- Relation[value#2486] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2486, None)) > 0)\n      +- Relation[value#2486] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2486, None)) > 0)\n   +- *(1) FileScan text [value#2486] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/fantasy_new...., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2486, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2486] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/fantasy_new...., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/fantasy_new.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4089,"metricType":"sum"},{"name":"number of files","accumulatorId":4090,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4091,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4092,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4088,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4087,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344526024}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":67,"accumUpdates":[[4090,1],[4091,0]]}
{"Event":"SparkListenerJobStart","Job ID":134,"Submission Time":1629344526056,"Stage Infos":[{"Stage ID":134,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":608,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1345\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[607],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":607,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1344\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[606],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":606,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1341\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[605],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":605,"Name":"FileScanRDD","Scope":"{\"id\":\"1341\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[134],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"67","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":134,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":608,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1345\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[607],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":607,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1344\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[606],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":606,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1341\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[605],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":605,"Name":"FileScanRDD","Scope":"{\"id\":\"1341\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526057,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"67","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":134,"Stage Attempt ID":0,"Task Info":{"Task ID":134,"Index":0,"Attempt":0,"Launch Time":1629344526061,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":134,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":134,"Index":0,"Attempt":0,"Launch Time":1629344526061,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344526068,"Failed":false,"Killed":false,"Accumulables":[{"ID":4088,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4089,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4115,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4114,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4097,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4096,"Name":"internal.metrics.executorCpuTime","Update":2280000,"Value":2280000,"Internal":true,"Count Failed Values":true},{"ID":4095,"Name":"internal.metrics.executorRunTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true},{"ID":4094,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1096000,"Value":1096000,"Internal":true,"Count Failed Values":true},{"ID":4093,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1096000,"Executor Run Time":2,"Executor CPU Time":2280000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":134,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":608,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1345\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[607],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":607,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1344\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[606],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":606,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1341\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[605],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":605,"Name":"FileScanRDD","Scope":"{\"id\":\"1341\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526057,"Completion Time":1629344526069,"Accumulables":[{"ID":4093,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":4114,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4096,"Name":"internal.metrics.executorCpuTime","Value":2280000,"Internal":true,"Count Failed Values":true},{"ID":4089,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4095,"Name":"internal.metrics.executorRunTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":4094,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1096000,"Internal":true,"Count Failed Values":true},{"ID":4088,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4115,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4097,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":134,"Completion Time":1629344526069,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":67,"time":1629344526070}
{"Event":"SparkListenerJobStart","Job ID":135,"Submission Time":1629344526106,"Stage Infos":[{"Stage ID":135,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":613,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1354\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[612],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":610,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1351\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[609],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":609,"Name":"FileScanRDD","Scope":"{\"id\":\"1351\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":612,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1353\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[611],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":611,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1350\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[610],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[135],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1355\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":135,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":613,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1354\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[612],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":610,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1351\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[609],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":609,"Name":"FileScanRDD","Scope":"{\"id\":\"1351\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":612,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1353\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[611],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":611,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1350\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[610],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526107,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1355\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":135,"Stage Attempt ID":0,"Task Info":{"Task ID":135,"Index":0,"Attempt":0,"Launch Time":1629344526110,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":135,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":135,"Index":0,"Attempt":0,"Launch Time":1629344526110,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344526306,"Failed":false,"Killed":false,"Accumulables":[{"ID":4118,"Name":"number of output rows","Update":"25009","Value":"25009","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4122,"Name":"duration total (min, med, max)","Update":"191","Value":"190","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4145,"Name":"internal.metrics.input.recordsRead","Update":25009,"Value":25009,"Internal":true,"Count Failed Values":true},{"ID":4144,"Name":"internal.metrics.input.bytesRead","Update":1879734,"Value":1879734,"Internal":true,"Count Failed Values":true},{"ID":4127,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4126,"Name":"internal.metrics.executorCpuTime","Update":188677000,"Value":188677000,"Internal":true,"Count Failed Values":true},{"ID":4125,"Name":"internal.metrics.executorRunTime","Update":193,"Value":193,"Internal":true,"Count Failed Values":true},{"ID":4124,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1319000,"Value":1319000,"Internal":true,"Count Failed Values":true},{"ID":4123,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1319000,"Executor Run Time":193,"Executor CPU Time":188677000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1879734,"Records Read":25009},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":135,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":613,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1354\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[612],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":610,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1351\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[609],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":609,"Name":"FileScanRDD","Scope":"{\"id\":\"1351\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":612,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1353\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[611],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":611,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1350\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[610],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526107,"Completion Time":1629344526307,"Accumulables":[{"ID":4144,"Name":"internal.metrics.input.bytesRead","Value":1879734,"Internal":true,"Count Failed Values":true},{"ID":4126,"Name":"internal.metrics.executorCpuTime","Value":188677000,"Internal":true,"Count Failed Values":true},{"ID":4123,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4122,"Name":"duration total (min, med, max)","Value":"190","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4125,"Name":"internal.metrics.executorRunTime","Value":193,"Internal":true,"Count Failed Values":true},{"ID":4145,"Name":"internal.metrics.input.recordsRead","Value":25009,"Internal":true,"Count Failed Values":true},{"ID":4124,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1319000,"Internal":true,"Count Failed Values":true},{"ID":4118,"Name":"number of output rows","Value":"25009","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4127,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":135,"Completion Time":1629344526307,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":68,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2523, None)) > 0)\n      +- Project [value#2523]\n         +- Relation[value#2523] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2523, None)) > 0)\n      +- Project [value#2523]\n         +- Relation[value#2523] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2523, None)) > 0)\n      +- Relation[value#2523] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2523, None)) > 0)\n   +- *(1) FileScan text [value#2523] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/earphone.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2523, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2523] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/earphone.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/earphone.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4150,"metricType":"sum"},{"name":"number of files","accumulatorId":4151,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4152,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4153,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4149,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4148,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344526376}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":68,"accumUpdates":[[4151,1],[4152,0]]}
{"Event":"SparkListenerJobStart","Job ID":136,"Submission Time":1629344526416,"Stage Infos":[{"Stage ID":136,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":617,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1365\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[616],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":615,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1361\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[614],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":616,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1364\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[615],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":614,"Name":"FileScanRDD","Scope":"{\"id\":\"1361\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[136],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"68","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":136,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":617,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1365\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[616],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":615,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1361\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[614],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":616,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1364\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[615],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":614,"Name":"FileScanRDD","Scope":"{\"id\":\"1361\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526417,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"68","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":136,"Stage Attempt ID":0,"Task Info":{"Task ID":136,"Index":0,"Attempt":0,"Launch Time":1629344526421,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":136,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":136,"Index":0,"Attempt":0,"Launch Time":1629344526421,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344526427,"Failed":false,"Killed":false,"Accumulables":[{"ID":4149,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4150,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4176,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4175,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4158,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4157,"Name":"internal.metrics.executorCpuTime","Update":1826000,"Value":1826000,"Internal":true,"Count Failed Values":true},{"ID":4156,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":4155,"Name":"internal.metrics.executorDeserializeCpuTime","Update":764000,"Value":764000,"Internal":true,"Count Failed Values":true},{"ID":4154,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":764000,"Executor Run Time":4,"Executor CPU Time":1826000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":136,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":617,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1365\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[616],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":615,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1361\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[614],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":616,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1364\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[615],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":614,"Name":"FileScanRDD","Scope":"{\"id\":\"1361\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526417,"Completion Time":1629344526427,"Accumulables":[{"ID":4156,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":4150,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4149,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4176,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4158,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4155,"Name":"internal.metrics.executorDeserializeCpuTime","Value":764000,"Internal":true,"Count Failed Values":true},{"ID":4154,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4175,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4157,"Name":"internal.metrics.executorCpuTime","Value":1826000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":136,"Completion Time":1629344526427,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":68,"time":1629344526428}
{"Event":"SparkListenerJobStart","Job ID":137,"Submission Time":1629344526467,"Stage Infos":[{"Stage ID":137,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":622,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1374\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[621],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":618,"Name":"FileScanRDD","Scope":"{\"id\":\"1371\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":621,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1373\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[620],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":620,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1370\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[619],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":619,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1371\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[618],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[137],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1375\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":137,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":622,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1374\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[621],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":618,"Name":"FileScanRDD","Scope":"{\"id\":\"1371\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":621,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1373\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[620],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":620,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1370\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[619],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":619,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1371\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[618],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526468,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1375\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":137,"Stage Attempt ID":0,"Task Info":{"Task ID":137,"Index":0,"Attempt":0,"Launch Time":1629344526472,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":137,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":137,"Index":0,"Attempt":0,"Launch Time":1629344526472,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344526521,"Failed":false,"Killed":false,"Accumulables":[{"ID":4179,"Name":"number of output rows","Update":"4270","Value":"4270","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4183,"Name":"duration total (min, med, max)","Update":"44","Value":"43","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4206,"Name":"internal.metrics.input.recordsRead","Update":4270,"Value":4270,"Internal":true,"Count Failed Values":true},{"ID":4205,"Name":"internal.metrics.input.bytesRead","Update":287557,"Value":287557,"Internal":true,"Count Failed Values":true},{"ID":4188,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4187,"Name":"internal.metrics.executorCpuTime","Update":43783000,"Value":43783000,"Internal":true,"Count Failed Values":true},{"ID":4186,"Name":"internal.metrics.executorRunTime","Update":47,"Value":47,"Internal":true,"Count Failed Values":true},{"ID":4185,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1722000,"Value":1722000,"Internal":true,"Count Failed Values":true},{"ID":4184,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1722000,"Executor Run Time":47,"Executor CPU Time":43783000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":287557,"Records Read":4270},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":137,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":622,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1374\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[621],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":618,"Name":"FileScanRDD","Scope":"{\"id\":\"1371\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":621,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1373\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[620],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":620,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1370\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[619],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":619,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1371\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[618],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526468,"Completion Time":1629344526522,"Accumulables":[{"ID":4186,"Name":"internal.metrics.executorRunTime","Value":47,"Internal":true,"Count Failed Values":true},{"ID":4183,"Name":"duration total (min, med, max)","Value":"43","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4185,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1722000,"Internal":true,"Count Failed Values":true},{"ID":4179,"Name":"number of output rows","Value":"4270","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4206,"Name":"internal.metrics.input.recordsRead","Value":4270,"Internal":true,"Count Failed Values":true},{"ID":4188,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4205,"Name":"internal.metrics.input.bytesRead","Value":287557,"Internal":true,"Count Failed Values":true},{"ID":4184,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4187,"Name":"internal.metrics.executorCpuTime","Value":43783000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":137,"Completion Time":1629344526522,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":69,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2560, None)) > 0)\n      +- Project [value#2560]\n         +- Relation[value#2560] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2560, None)) > 0)\n      +- Project [value#2560]\n         +- Relation[value#2560] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2560, None)) > 0)\n      +- Relation[value#2560] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2560, None)) > 0)\n   +- *(1) FileScan text [value#2560] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/m_entertaine..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2560, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2560] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/m_entertaine..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/m_entertainer1.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4211,"metricType":"sum"},{"name":"number of files","accumulatorId":4212,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4213,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4214,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4210,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4209,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344526590}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":69,"accumUpdates":[[4212,1],[4213,0]]}
{"Event":"SparkListenerJobStart","Job ID":138,"Submission Time":1629344526616,"Stage Infos":[{"Stage ID":138,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":626,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1385\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[625],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":624,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1381\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[623],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":625,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1384\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[624],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":623,"Name":"FileScanRDD","Scope":"{\"id\":\"1381\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[138],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"69","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":138,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":626,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1385\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[625],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":624,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1381\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[623],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":625,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1384\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[624],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":623,"Name":"FileScanRDD","Scope":"{\"id\":\"1381\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526617,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"69","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":138,"Stage Attempt ID":0,"Task Info":{"Task ID":138,"Index":0,"Attempt":0,"Launch Time":1629344526620,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":138,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":138,"Index":0,"Attempt":0,"Launch Time":1629344526620,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344526623,"Failed":false,"Killed":false,"Accumulables":[{"ID":4210,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4211,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4237,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4236,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4219,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4218,"Name":"internal.metrics.executorCpuTime","Update":1453000,"Value":1453000,"Internal":true,"Count Failed Values":true},{"ID":4217,"Name":"internal.metrics.executorRunTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4216,"Name":"internal.metrics.executorDeserializeCpuTime","Update":679000,"Value":679000,"Internal":true,"Count Failed Values":true},{"ID":4215,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":679000,"Executor Run Time":1,"Executor CPU Time":1453000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":138,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":626,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1385\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[625],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":624,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1381\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[623],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":625,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1384\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[624],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":623,"Name":"FileScanRDD","Scope":"{\"id\":\"1381\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526617,"Completion Time":1629344526624,"Accumulables":[{"ID":4237,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4216,"Name":"internal.metrics.executorDeserializeCpuTime","Value":679000,"Internal":true,"Count Failed Values":true},{"ID":4210,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4219,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4236,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4218,"Name":"internal.metrics.executorCpuTime","Value":1453000,"Internal":true,"Count Failed Values":true},{"ID":4215,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4217,"Name":"internal.metrics.executorRunTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4211,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":138,"Completion Time":1629344526624,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":69,"time":1629344526624}
{"Event":"SparkListenerJobStart","Job ID":139,"Submission Time":1629344526656,"Stage Infos":[{"Stage ID":139,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":631,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1394\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[630],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":630,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1393\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[629],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":629,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1390\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[628],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":627,"Name":"FileScanRDD","Scope":"{\"id\":\"1391\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":628,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1391\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[627],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[139],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1395\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":139,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":631,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1394\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[630],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":630,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1393\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[629],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":629,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1390\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[628],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":627,"Name":"FileScanRDD","Scope":"{\"id\":\"1391\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":628,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1391\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[627],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526657,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1395\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":139,"Stage Attempt ID":0,"Task Info":{"Task ID":139,"Index":0,"Attempt":0,"Launch Time":1629344526659,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":139,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":139,"Index":0,"Attempt":0,"Launch Time":1629344526659,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344526765,"Failed":false,"Killed":false,"Accumulables":[{"ID":4240,"Name":"number of output rows","Update":"15891","Value":"15891","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4244,"Name":"duration total (min, med, max)","Update":"101","Value":"100","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4267,"Name":"internal.metrics.input.recordsRead","Update":15891,"Value":15891,"Internal":true,"Count Failed Values":true},{"ID":4266,"Name":"internal.metrics.input.bytesRead","Update":1234206,"Value":1234206,"Internal":true,"Count Failed Values":true},{"ID":4249,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4248,"Name":"internal.metrics.executorCpuTime","Update":101978000,"Value":101978000,"Internal":true,"Count Failed Values":true},{"ID":4247,"Name":"internal.metrics.executorRunTime","Update":102,"Value":102,"Internal":true,"Count Failed Values":true},{"ID":4246,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1176000,"Value":1176000,"Internal":true,"Count Failed Values":true},{"ID":4245,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1176000,"Executor Run Time":102,"Executor CPU Time":101978000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1234206,"Records Read":15891},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":139,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":631,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1394\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[630],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":630,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1393\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[629],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":629,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1390\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[628],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":627,"Name":"FileScanRDD","Scope":"{\"id\":\"1391\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":628,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1391\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[627],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526657,"Completion Time":1629344526766,"Accumulables":[{"ID":4246,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1176000,"Internal":true,"Count Failed Values":true},{"ID":4240,"Name":"number of output rows","Value":"15891","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4267,"Name":"internal.metrics.input.recordsRead","Value":15891,"Internal":true,"Count Failed Values":true},{"ID":4249,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4245,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4266,"Name":"internal.metrics.input.bytesRead","Value":1234206,"Internal":true,"Count Failed Values":true},{"ID":4248,"Name":"internal.metrics.executorCpuTime","Value":101978000,"Internal":true,"Count Failed Values":true},{"ID":4244,"Name":"duration total (min, med, max)","Value":"100","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4247,"Name":"internal.metrics.executorRunTime","Value":102,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":139,"Completion Time":1629344526766,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":70,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2597, None)) > 0)\n      +- Project [value#2597]\n         +- Relation[value#2597] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2597, None)) > 0)\n      +- Project [value#2597]\n         +- Relation[value#2597] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2597, None)) > 0)\n      +- Relation[value#2597] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2597, None)) > 0)\n   +- *(1) FileScan text [value#2597] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/stream.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2597, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2597] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/stream.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/stream.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4272,"metricType":"sum"},{"name":"number of files","accumulatorId":4273,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4274,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4275,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4271,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4270,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344526824}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":70,"accumUpdates":[[4273,1],[4274,0]]}
{"Event":"SparkListenerJobStart","Job ID":140,"Submission Time":1629344526846,"Stage Infos":[{"Stage ID":140,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":635,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1405\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[634],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":632,"Name":"FileScanRDD","Scope":"{\"id\":\"1401\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":634,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1404\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[633],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":633,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1401\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[632],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[140],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"70","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":140,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":635,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1405\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[634],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":632,"Name":"FileScanRDD","Scope":"{\"id\":\"1401\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":634,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1404\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[633],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":633,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1401\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[632],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526847,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"70","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":140,"Stage Attempt ID":0,"Task Info":{"Task ID":140,"Index":0,"Attempt":0,"Launch Time":1629344526850,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":140,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":140,"Index":0,"Attempt":0,"Launch Time":1629344526850,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344526857,"Failed":false,"Killed":false,"Accumulables":[{"ID":4271,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4272,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4298,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4297,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4280,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":4279,"Name":"internal.metrics.executorCpuTime","Update":2342000,"Value":2342000,"Internal":true,"Count Failed Values":true},{"ID":4278,"Name":"internal.metrics.executorRunTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true},{"ID":4277,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1485000,"Value":1485000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":1485000,"Executor Run Time":5,"Executor CPU Time":2342000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":140,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":635,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1405\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[634],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":632,"Name":"FileScanRDD","Scope":"{\"id\":\"1401\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":634,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1404\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[633],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":633,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1401\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[632],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526847,"Completion Time":1629344526858,"Accumulables":[{"ID":4279,"Name":"internal.metrics.executorCpuTime","Value":2342000,"Internal":true,"Count Failed Values":true},{"ID":4278,"Name":"internal.metrics.executorRunTime","Value":5,"Internal":true,"Count Failed Values":true},{"ID":4272,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4277,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1485000,"Internal":true,"Count Failed Values":true},{"ID":4271,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4298,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4280,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":4297,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":140,"Completion Time":1629344526858,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":70,"time":1629344526858}
{"Event":"SparkListenerJobStart","Job ID":141,"Submission Time":1629344526885,"Stage Infos":[{"Stage ID":141,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":640,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1414\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[639],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":636,"Name":"FileScanRDD","Scope":"{\"id\":\"1411\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":638,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1410\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[637],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":637,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1411\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[636],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":639,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1413\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[638],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[141],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1415\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":141,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":640,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1414\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[639],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":636,"Name":"FileScanRDD","Scope":"{\"id\":\"1411\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":638,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1410\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[637],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":637,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1411\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[636],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":639,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1413\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[638],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526885,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1415\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":141,"Stage Attempt ID":0,"Task Info":{"Task ID":141,"Index":0,"Attempt":0,"Launch Time":1629344526888,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":141,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":141,"Index":0,"Attempt":0,"Launch Time":1629344526888,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344527188,"Failed":false,"Killed":false,"Accumulables":[{"ID":4301,"Name":"number of output rows","Update":"42297","Value":"42297","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4305,"Name":"duration total (min, med, max)","Update":"294","Value":"293","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4328,"Name":"internal.metrics.input.recordsRead","Update":42297,"Value":42297,"Internal":true,"Count Failed Values":true},{"ID":4327,"Name":"internal.metrics.input.bytesRead","Update":3397717,"Value":3397717,"Internal":true,"Count Failed Values":true},{"ID":4310,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4309,"Name":"internal.metrics.executorCpuTime","Update":291315000,"Value":291315000,"Internal":true,"Count Failed Values":true},{"ID":4308,"Name":"internal.metrics.executorRunTime","Update":296,"Value":296,"Internal":true,"Count Failed Values":true},{"ID":4307,"Name":"internal.metrics.executorDeserializeCpuTime","Update":959000,"Value":959000,"Internal":true,"Count Failed Values":true},{"ID":4306,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":959000,"Executor Run Time":296,"Executor CPU Time":291315000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":3397717,"Records Read":42297},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":141,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":640,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1414\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[639],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":636,"Name":"FileScanRDD","Scope":"{\"id\":\"1411\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":638,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1410\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[637],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":637,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1411\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[636],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":639,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1413\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[638],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344526885,"Completion Time":1629344527188,"Accumulables":[{"ID":4327,"Name":"internal.metrics.input.bytesRead","Value":3397717,"Internal":true,"Count Failed Values":true},{"ID":4309,"Name":"internal.metrics.executorCpuTime","Value":291315000,"Internal":true,"Count Failed Values":true},{"ID":4305,"Name":"duration total (min, med, max)","Value":"293","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4308,"Name":"internal.metrics.executorRunTime","Value":296,"Internal":true,"Count Failed Values":true},{"ID":4301,"Name":"number of output rows","Value":"42297","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4328,"Name":"internal.metrics.input.recordsRead","Value":42297,"Internal":true,"Count Failed Values":true},{"ID":4310,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4307,"Name":"internal.metrics.executorDeserializeCpuTime","Value":959000,"Internal":true,"Count Failed Values":true},{"ID":4306,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":141,"Completion Time":1629344527188,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":71,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2634, None)) > 0)\n      +- Project [value#2634]\n         +- Relation[value#2634] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2634, None)) > 0)\n      +- Project [value#2634]\n         +- Relation[value#2634] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2634, None)) > 0)\n      +- Relation[value#2634] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2634, None)) > 0)\n   +- *(1) FileScan text [value#2634] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/w_entertaine..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2634, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2634] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/w_entertaine..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/w_entertainer.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4333,"metricType":"sum"},{"name":"number of files","accumulatorId":4334,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4335,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4336,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4332,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4331,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344527250}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":71,"accumUpdates":[[4334,1],[4335,0]]}
{"Event":"SparkListenerJobStart","Job ID":142,"Submission Time":1629344527284,"Stage Infos":[{"Stage ID":142,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":644,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1425\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[643],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":641,"Name":"FileScanRDD","Scope":"{\"id\":\"1421\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":642,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1421\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[641],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":643,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1424\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[642],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[142],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"71","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":142,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":644,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1425\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[643],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":641,"Name":"FileScanRDD","Scope":"{\"id\":\"1421\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":642,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1421\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[641],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":643,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1424\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[642],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527285,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"71","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":142,"Stage Attempt ID":0,"Task Info":{"Task ID":142,"Index":0,"Attempt":0,"Launch Time":1629344527290,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":142,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":142,"Index":0,"Attempt":0,"Launch Time":1629344527290,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344527294,"Failed":false,"Killed":false,"Accumulables":[{"ID":4332,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4333,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4359,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4358,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4341,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":4340,"Name":"internal.metrics.executorCpuTime","Update":1824000,"Value":1824000,"Internal":true,"Count Failed Values":true},{"ID":4339,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":4338,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1079000,"Value":1079000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":1079000,"Executor Run Time":3,"Executor CPU Time":1824000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":142,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":644,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1425\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[643],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":641,"Name":"FileScanRDD","Scope":"{\"id\":\"1421\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":642,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1421\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[641],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":643,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1424\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[642],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527285,"Completion Time":1629344527294,"Accumulables":[{"ID":4339,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":4338,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1079000,"Internal":true,"Count Failed Values":true},{"ID":4332,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4359,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4341,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":4358,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4340,"Name":"internal.metrics.executorCpuTime","Value":1824000,"Internal":true,"Count Failed Values":true},{"ID":4333,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":142,"Completion Time":1629344527295,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":71,"time":1629344527295}
{"Event":"SparkListenerJobStart","Job ID":143,"Submission Time":1629344527328,"Stage Infos":[{"Stage ID":143,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":649,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1434\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[648],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":648,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1433\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[647],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":647,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1430\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[646],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":646,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1431\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[645],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":645,"Name":"FileScanRDD","Scope":"{\"id\":\"1431\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[143],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1435\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":143,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":649,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1434\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[648],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":648,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1433\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[647],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":647,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1430\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[646],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":646,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1431\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[645],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":645,"Name":"FileScanRDD","Scope":"{\"id\":\"1431\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527328,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1435\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":143,"Stage Attempt ID":0,"Task Info":{"Task ID":143,"Index":0,"Attempt":0,"Launch Time":1629344527331,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":143,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":143,"Index":0,"Attempt":0,"Launch Time":1629344527331,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344527512,"Failed":false,"Killed":false,"Accumulables":[{"ID":4362,"Name":"number of output rows","Update":"28465","Value":"28465","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4366,"Name":"duration total (min, med, max)","Update":"176","Value":"175","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4389,"Name":"internal.metrics.input.recordsRead","Update":28465,"Value":28465,"Internal":true,"Count Failed Values":true},{"ID":4388,"Name":"internal.metrics.input.bytesRead","Update":2181885,"Value":2181885,"Internal":true,"Count Failed Values":true},{"ID":4371,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4370,"Name":"internal.metrics.executorCpuTime","Update":175506000,"Value":175506000,"Internal":true,"Count Failed Values":true},{"ID":4369,"Name":"internal.metrics.executorRunTime","Update":178,"Value":178,"Internal":true,"Count Failed Values":true},{"ID":4368,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1208000,"Value":1208000,"Internal":true,"Count Failed Values":true},{"ID":4367,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1208000,"Executor Run Time":178,"Executor CPU Time":175506000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":2181885,"Records Read":28465},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":143,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":649,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1434\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[648],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":648,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1433\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[647],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":647,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1430\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[646],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":646,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1431\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[645],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":645,"Name":"FileScanRDD","Scope":"{\"id\":\"1431\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527328,"Completion Time":1629344527512,"Accumulables":[{"ID":4362,"Name":"number of output rows","Value":"28465","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4389,"Name":"internal.metrics.input.recordsRead","Value":28465,"Internal":true,"Count Failed Values":true},{"ID":4371,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4368,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1208000,"Internal":true,"Count Failed Values":true},{"ID":4388,"Name":"internal.metrics.input.bytesRead","Value":2181885,"Internal":true,"Count Failed Values":true},{"ID":4370,"Name":"internal.metrics.executorCpuTime","Value":175506000,"Internal":true,"Count Failed Values":true},{"ID":4367,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4366,"Name":"duration total (min, med, max)","Value":"175","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4369,"Name":"internal.metrics.executorRunTime","Value":178,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":143,"Completion Time":1629344527512,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":72,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2671, None)) > 0)\n      +- Project [value#2671]\n         +- Relation[value#2671] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2671, None)) > 0)\n      +- Project [value#2671]\n         +- Relation[value#2671] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2671, None)) > 0)\n      +- Relation[value#2671] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2671, None)) > 0)\n   +- *(1) FileScan text [value#2671] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/d_fighter_ne..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2671, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2671] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/d_fighter_ne..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/d_fighter_new2.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4394,"metricType":"sum"},{"name":"number of files","accumulatorId":4395,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4396,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4397,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4393,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4392,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344527571}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":72,"accumUpdates":[[4395,1],[4396,0]]}
{"Event":"SparkListenerJobStart","Job ID":144,"Submission Time":1629344527597,"Stage Infos":[{"Stage ID":144,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":653,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1445\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[652],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":651,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1441\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[650],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":650,"Name":"FileScanRDD","Scope":"{\"id\":\"1441\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":652,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1444\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[651],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[144],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"72","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":144,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":653,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1445\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[652],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":651,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1441\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[650],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":650,"Name":"FileScanRDD","Scope":"{\"id\":\"1441\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":652,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1444\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[651],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527598,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"72","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":144,"Stage Attempt ID":0,"Task Info":{"Task ID":144,"Index":0,"Attempt":0,"Launch Time":1629344527601,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":144,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":144,"Index":0,"Attempt":0,"Launch Time":1629344527601,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344527607,"Failed":false,"Killed":false,"Accumulables":[{"ID":4393,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4394,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4420,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4419,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4402,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":4401,"Name":"internal.metrics.executorCpuTime","Update":1704000,"Value":1704000,"Internal":true,"Count Failed Values":true},{"ID":4400,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":4399,"Name":"internal.metrics.executorDeserializeCpuTime","Update":658000,"Value":658000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":658000,"Executor Run Time":4,"Executor CPU Time":1704000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":144,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":653,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1445\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[652],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":651,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1441\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[650],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":650,"Name":"FileScanRDD","Scope":"{\"id\":\"1441\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":652,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1444\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[651],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527598,"Completion Time":1629344527608,"Accumulables":[{"ID":4399,"Name":"internal.metrics.executorDeserializeCpuTime","Value":658000,"Internal":true,"Count Failed Values":true},{"ID":4419,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4401,"Name":"internal.metrics.executorCpuTime","Value":1704000,"Internal":true,"Count Failed Values":true},{"ID":4394,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4400,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":4393,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4420,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4402,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":144,"Completion Time":1629344527608,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":72,"time":1629344527608}
{"Event":"SparkListenerJobStart","Job ID":145,"Submission Time":1629344527641,"Stage Infos":[{"Stage ID":145,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":658,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1454\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[657],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":655,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1451\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[654],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":654,"Name":"FileScanRDD","Scope":"{\"id\":\"1451\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":656,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1450\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[655],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":657,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1453\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[656],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[145],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1455\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":145,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":658,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1454\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[657],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":655,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1451\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[654],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":654,"Name":"FileScanRDD","Scope":"{\"id\":\"1451\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":656,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1450\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[655],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":657,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1453\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[656],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527641,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1455\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":145,"Stage Attempt ID":0,"Task Info":{"Task ID":145,"Index":0,"Attempt":0,"Launch Time":1629344527644,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":145,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":145,"Index":0,"Attempt":0,"Launch Time":1629344527644,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344527735,"Failed":false,"Killed":false,"Accumulables":[{"ID":4423,"Name":"number of output rows","Update":"12591","Value":"12591","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4427,"Name":"duration total (min, med, max)","Update":"86","Value":"85","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4450,"Name":"internal.metrics.input.recordsRead","Update":12591,"Value":12591,"Internal":true,"Count Failed Values":true},{"ID":4449,"Name":"internal.metrics.input.bytesRead","Update":831841,"Value":831841,"Internal":true,"Count Failed Values":true},{"ID":4432,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4431,"Name":"internal.metrics.executorCpuTime","Update":85739000,"Value":85739000,"Internal":true,"Count Failed Values":true},{"ID":4430,"Name":"internal.metrics.executorRunTime","Update":87,"Value":87,"Internal":true,"Count Failed Values":true},{"ID":4429,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1036000,"Value":1036000,"Internal":true,"Count Failed Values":true},{"ID":4428,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1036000,"Executor Run Time":87,"Executor CPU Time":85739000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":831841,"Records Read":12591},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":145,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":658,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1454\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[657],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":655,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1451\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[654],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":654,"Name":"FileScanRDD","Scope":"{\"id\":\"1451\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":656,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1450\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[655],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":657,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1453\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[656],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527641,"Completion Time":1629344527736,"Accumulables":[{"ID":4449,"Name":"internal.metrics.input.bytesRead","Value":831841,"Internal":true,"Count Failed Values":true},{"ID":4431,"Name":"internal.metrics.executorCpuTime","Value":85739000,"Internal":true,"Count Failed Values":true},{"ID":4428,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":4430,"Name":"internal.metrics.executorRunTime","Value":87,"Internal":true,"Count Failed Values":true},{"ID":4427,"Name":"duration total (min, med, max)","Value":"85","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4429,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1036000,"Internal":true,"Count Failed Values":true},{"ID":4423,"Name":"number of output rows","Value":"12591","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4450,"Name":"internal.metrics.input.recordsRead","Value":12591,"Internal":true,"Count Failed Values":true},{"ID":4432,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":145,"Completion Time":1629344527736,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":73,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2708, None)) > 0)\n      +- Project [value#2708]\n         +- Relation[value#2708] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2708, None)) > 0)\n      +- Project [value#2708]\n         +- Relation[value#2708] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2708, None)) > 0)\n      +- Relation[value#2708] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2708, None)) > 0)\n   +- *(1) FileScan text [value#2708] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ohmygirl.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2708, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2708] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ohmygirl.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ohmygirl.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4455,"metricType":"sum"},{"name":"number of files","accumulatorId":4456,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4457,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4458,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4454,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4453,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344527792}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":73,"accumUpdates":[[4456,1],[4457,0]]}
{"Event":"SparkListenerJobStart","Job ID":146,"Submission Time":1629344527814,"Stage Infos":[{"Stage ID":146,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":662,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1465\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[661],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":661,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1464\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[660],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":660,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1461\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[659],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":659,"Name":"FileScanRDD","Scope":"{\"id\":\"1461\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[146],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"73","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":146,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":662,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1465\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[661],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":661,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1464\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[660],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":660,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1461\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[659],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":659,"Name":"FileScanRDD","Scope":"{\"id\":\"1461\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527814,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"73","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":146,"Stage Attempt ID":0,"Task Info":{"Task ID":146,"Index":0,"Attempt":0,"Launch Time":1629344527818,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":146,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":146,"Index":0,"Attempt":0,"Launch Time":1629344527818,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344527823,"Failed":false,"Killed":false,"Accumulables":[{"ID":4454,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4455,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4481,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4480,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4463,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4462,"Name":"internal.metrics.executorCpuTime","Update":1509000,"Value":1509000,"Internal":true,"Count Failed Values":true},{"ID":4461,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":4460,"Name":"internal.metrics.executorDeserializeCpuTime","Update":639000,"Value":639000,"Internal":true,"Count Failed Values":true},{"ID":4459,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":639000,"Executor Run Time":3,"Executor CPU Time":1509000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":146,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":662,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1465\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[661],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":661,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1464\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[660],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":660,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1461\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[659],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":659,"Name":"FileScanRDD","Scope":"{\"id\":\"1461\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527814,"Completion Time":1629344527823,"Accumulables":[{"ID":4461,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":4455,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4454,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4481,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4463,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4460,"Name":"internal.metrics.executorDeserializeCpuTime","Value":639000,"Internal":true,"Count Failed Values":true},{"ID":4480,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4462,"Name":"internal.metrics.executorCpuTime","Value":1509000,"Internal":true,"Count Failed Values":true},{"ID":4459,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":146,"Completion Time":1629344527823,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":73,"time":1629344527823}
{"Event":"SparkListenerJobStart","Job ID":147,"Submission Time":1629344527850,"Stage Infos":[{"Stage ID":147,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":667,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1474\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[666],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":664,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1471\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[663],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":666,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1473\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[665],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":665,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1470\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[664],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":663,"Name":"FileScanRDD","Scope":"{\"id\":\"1471\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[147],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1475\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":147,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":667,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1474\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[666],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":664,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1471\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[663],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":666,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1473\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[665],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":665,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1470\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[664],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":663,"Name":"FileScanRDD","Scope":"{\"id\":\"1471\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527851,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1475\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":147,"Stage Attempt ID":0,"Task Info":{"Task ID":147,"Index":0,"Attempt":0,"Launch Time":1629344527864,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":147,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":147,"Index":0,"Attempt":0,"Launch Time":1629344527864,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344527881,"Failed":false,"Killed":false,"Accumulables":[{"ID":4484,"Name":"number of output rows","Update":"1493","Value":"1493","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4488,"Name":"duration total (min, med, max)","Update":"12","Value":"11","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4511,"Name":"internal.metrics.input.recordsRead","Update":1493,"Value":1493,"Internal":true,"Count Failed Values":true},{"ID":4510,"Name":"internal.metrics.input.bytesRead","Update":99464,"Value":99464,"Internal":true,"Count Failed Values":true},{"ID":4493,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4492,"Name":"internal.metrics.executorCpuTime","Update":12569000,"Value":12569000,"Internal":true,"Count Failed Values":true},{"ID":4491,"Name":"internal.metrics.executorRunTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":4490,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1044000,"Value":1044000,"Internal":true,"Count Failed Values":true},{"ID":4489,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1044000,"Executor Run Time":14,"Executor CPU Time":12569000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":99464,"Records Read":1493},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":147,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":667,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1474\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[666],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":664,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1471\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[663],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":666,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1473\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[665],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":665,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1470\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[664],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":663,"Name":"FileScanRDD","Scope":"{\"id\":\"1471\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527851,"Completion Time":1629344527882,"Accumulables":[{"ID":4491,"Name":"internal.metrics.executorRunTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":4488,"Name":"duration total (min, med, max)","Value":"11","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4490,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1044000,"Internal":true,"Count Failed Values":true},{"ID":4484,"Name":"number of output rows","Value":"1493","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4511,"Name":"internal.metrics.input.recordsRead","Value":1493,"Internal":true,"Count Failed Values":true},{"ID":4493,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4489,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4510,"Name":"internal.metrics.input.bytesRead","Value":99464,"Internal":true,"Count Failed Values":true},{"ID":4492,"Name":"internal.metrics.executorCpuTime","Value":12569000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":147,"Completion Time":1629344527882,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":74,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2745, None)) > 0)\n      +- Project [value#2745]\n         +- Relation[value#2745] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2745, None)) > 0)\n      +- Project [value#2745]\n         +- Relation[value#2745] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2745, None)) > 0)\n      +- Relation[value#2745] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2745, None)) > 0)\n   +- *(1) FileScan text [value#2745] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/tigers_new.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2745, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2745] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/tigers_new.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/tigers_new.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4516,"metricType":"sum"},{"name":"number of files","accumulatorId":4517,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4518,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4519,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4515,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4514,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344527933}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":74,"accumUpdates":[[4517,1],[4518,0]]}
{"Event":"SparkListenerJobStart","Job ID":148,"Submission Time":1629344527954,"Stage Infos":[{"Stage ID":148,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":671,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1485\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[670],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":668,"Name":"FileScanRDD","Scope":"{\"id\":\"1481\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":670,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1484\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[669],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":669,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1481\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[668],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[148],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"74","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":148,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":671,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1485\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[670],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":668,"Name":"FileScanRDD","Scope":"{\"id\":\"1481\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":670,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1484\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[669],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":669,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1481\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[668],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527955,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"74","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":148,"Stage Attempt ID":0,"Task Info":{"Task ID":148,"Index":0,"Attempt":0,"Launch Time":1629344527957,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":148,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":148,"Index":0,"Attempt":0,"Launch Time":1629344527957,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344527963,"Failed":false,"Killed":false,"Accumulables":[{"ID":4515,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4516,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4542,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4541,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4524,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":4523,"Name":"internal.metrics.executorCpuTime","Update":1407000,"Value":1407000,"Internal":true,"Count Failed Values":true},{"ID":4522,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":4521,"Name":"internal.metrics.executorDeserializeCpuTime","Update":651000,"Value":651000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":651000,"Executor Run Time":4,"Executor CPU Time":1407000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":148,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":671,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1485\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[670],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":668,"Name":"FileScanRDD","Scope":"{\"id\":\"1481\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":670,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1484\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[669],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":669,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1481\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[668],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527955,"Completion Time":1629344527963,"Accumulables":[{"ID":4542,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4521,"Name":"internal.metrics.executorDeserializeCpuTime","Value":651000,"Internal":true,"Count Failed Values":true},{"ID":4515,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4524,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":4541,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4523,"Name":"internal.metrics.executorCpuTime","Value":1407000,"Internal":true,"Count Failed Values":true},{"ID":4522,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":4516,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":148,"Completion Time":1629344527963,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":74,"time":1629344527963}
{"Event":"SparkListenerJobStart","Job ID":149,"Submission Time":1629344527991,"Stage Infos":[{"Stage ID":149,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":676,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1494\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[675],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":672,"Name":"FileScanRDD","Scope":"{\"id\":\"1491\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":673,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1491\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[672],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":675,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1493\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[674],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":674,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1490\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[673],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[149],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1495\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":149,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":676,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1494\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[675],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":672,"Name":"FileScanRDD","Scope":"{\"id\":\"1491\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":673,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1491\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[672],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":675,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1493\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[674],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":674,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1490\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[673],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527991,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1495\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":149,"Stage Attempt ID":0,"Task Info":{"Task ID":149,"Index":0,"Attempt":0,"Launch Time":1629344527994,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":149,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":149,"Index":0,"Attempt":0,"Launch Time":1629344527994,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344528069,"Failed":false,"Killed":false,"Accumulables":[{"ID":4545,"Name":"number of output rows","Update":"12007","Value":"12007","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4549,"Name":"duration total (min, med, max)","Update":"71","Value":"70","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4572,"Name":"internal.metrics.input.recordsRead","Update":12007,"Value":12007,"Internal":true,"Count Failed Values":true},{"ID":4571,"Name":"internal.metrics.input.bytesRead","Update":879492,"Value":879492,"Internal":true,"Count Failed Values":true},{"ID":4554,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4553,"Name":"internal.metrics.executorCpuTime","Update":72027000,"Value":72027000,"Internal":true,"Count Failed Values":true},{"ID":4552,"Name":"internal.metrics.executorRunTime","Update":72,"Value":72,"Internal":true,"Count Failed Values":true},{"ID":4551,"Name":"internal.metrics.executorDeserializeCpuTime","Update":921000,"Value":921000,"Internal":true,"Count Failed Values":true},{"ID":4550,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":921000,"Executor Run Time":72,"Executor CPU Time":72027000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":879492,"Records Read":12007},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":149,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":676,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1494\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[675],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":672,"Name":"FileScanRDD","Scope":"{\"id\":\"1491\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":673,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1491\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[672],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":675,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1493\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[674],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":674,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1490\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[673],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344527991,"Completion Time":1629344528069,"Accumulables":[{"ID":4551,"Name":"internal.metrics.executorDeserializeCpuTime","Value":921000,"Internal":true,"Count Failed Values":true},{"ID":4545,"Name":"number of output rows","Value":"12007","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4572,"Name":"internal.metrics.input.recordsRead","Value":12007,"Internal":true,"Count Failed Values":true},{"ID":4554,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4550,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4571,"Name":"internal.metrics.input.bytesRead","Value":879492,"Internal":true,"Count Failed Values":true},{"ID":4553,"Name":"internal.metrics.executorCpuTime","Value":72027000,"Internal":true,"Count Failed Values":true},{"ID":4549,"Name":"duration total (min, med, max)","Value":"70","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4552,"Name":"internal.metrics.executorRunTime","Value":72,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":149,"Completion Time":1629344528069,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":75,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2782, None)) > 0)\n      +- Project [value#2782]\n         +- Relation[value#2782] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2782, None)) > 0)\n      +- Project [value#2782]\n         +- Relation[value#2782] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2782, None)) > 0)\n      +- Relation[value#2782] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2782, None)) > 0)\n   +- *(1) FileScan text [value#2782] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/blackpink.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2782, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2782] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/blackpink.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/blackpink.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4577,"metricType":"sum"},{"name":"number of files","accumulatorId":4578,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4579,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4580,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4576,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4575,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344528120}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":75,"accumUpdates":[[4578,1],[4579,0]]}
{"Event":"SparkListenerJobStart","Job ID":150,"Submission Time":1629344528143,"Stage Infos":[{"Stage ID":150,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":680,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1505\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[679],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":678,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1501\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[677],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":679,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1504\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[678],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":677,"Name":"FileScanRDD","Scope":"{\"id\":\"1501\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[150],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"75","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":150,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":680,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1505\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[679],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":678,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1501\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[677],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":679,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1504\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[678],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":677,"Name":"FileScanRDD","Scope":"{\"id\":\"1501\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528143,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"75","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":150,"Stage Attempt ID":0,"Task Info":{"Task ID":150,"Index":0,"Attempt":0,"Launch Time":1629344528146,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":150,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":150,"Index":0,"Attempt":0,"Launch Time":1629344528146,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344528151,"Failed":false,"Killed":false,"Accumulables":[{"ID":4576,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4577,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4603,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4602,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4585,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4584,"Name":"internal.metrics.executorCpuTime","Update":1503000,"Value":1503000,"Internal":true,"Count Failed Values":true},{"ID":4583,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":4582,"Name":"internal.metrics.executorDeserializeCpuTime","Update":666000,"Value":666000,"Internal":true,"Count Failed Values":true},{"ID":4581,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":666000,"Executor Run Time":3,"Executor CPU Time":1503000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":150,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":680,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1505\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[679],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":678,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1501\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[677],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":679,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1504\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[678],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":677,"Name":"FileScanRDD","Scope":"{\"id\":\"1501\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528143,"Completion Time":1629344528151,"Accumulables":[{"ID":4581,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4584,"Name":"internal.metrics.executorCpuTime","Value":1503000,"Internal":true,"Count Failed Values":true},{"ID":4583,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":4577,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4582,"Name":"internal.metrics.executorDeserializeCpuTime","Value":666000,"Internal":true,"Count Failed Values":true},{"ID":4576,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4603,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4585,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4602,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":150,"Completion Time":1629344528151,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":75,"time":1629344528152}
{"Event":"SparkListenerJobStart","Job ID":151,"Submission Time":1629344528181,"Stage Infos":[{"Stage ID":151,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":685,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1514\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[684],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":684,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1513\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[683],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":682,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1511\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[681],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":683,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1510\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[682],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":681,"Name":"FileScanRDD","Scope":"{\"id\":\"1511\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[151],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1515\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":151,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":685,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1514\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[684],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":684,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1513\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[683],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":682,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1511\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[681],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":683,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1510\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[682],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":681,"Name":"FileScanRDD","Scope":"{\"id\":\"1511\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528181,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1515\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":151,"Stage Attempt ID":0,"Task Info":{"Task ID":151,"Index":0,"Attempt":0,"Launch Time":1629344528183,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":151,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":151,"Index":0,"Attempt":0,"Launch Time":1629344528183,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344528215,"Failed":false,"Killed":false,"Accumulables":[{"ID":4606,"Name":"number of output rows","Update":"4776","Value":"4776","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4610,"Name":"duration total (min, med, max)","Update":"27","Value":"26","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4633,"Name":"internal.metrics.input.recordsRead","Update":4776,"Value":4776,"Internal":true,"Count Failed Values":true},{"ID":4632,"Name":"internal.metrics.input.bytesRead","Update":324652,"Value":324652,"Internal":true,"Count Failed Values":true},{"ID":4615,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4614,"Name":"internal.metrics.executorCpuTime","Update":28105000,"Value":28105000,"Internal":true,"Count Failed Values":true},{"ID":4613,"Name":"internal.metrics.executorRunTime","Update":28,"Value":28,"Internal":true,"Count Failed Values":true},{"ID":4612,"Name":"internal.metrics.executorDeserializeCpuTime","Update":936000,"Value":936000,"Internal":true,"Count Failed Values":true},{"ID":4611,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":936000,"Executor Run Time":28,"Executor CPU Time":28105000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":324652,"Records Read":4776},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":151,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":685,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1514\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[684],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":684,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1513\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[683],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":682,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1511\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[681],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":683,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1510\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[682],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":681,"Name":"FileScanRDD","Scope":"{\"id\":\"1511\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528181,"Completion Time":1629344528215,"Accumulables":[{"ID":4632,"Name":"internal.metrics.input.bytesRead","Value":324652,"Internal":true,"Count Failed Values":true},{"ID":4614,"Name":"internal.metrics.executorCpuTime","Value":28105000,"Internal":true,"Count Failed Values":true},{"ID":4610,"Name":"duration total (min, med, max)","Value":"26","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4613,"Name":"internal.metrics.executorRunTime","Value":28,"Internal":true,"Count Failed Values":true},{"ID":4606,"Name":"number of output rows","Value":"4776","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4633,"Name":"internal.metrics.input.recordsRead","Value":4776,"Internal":true,"Count Failed Values":true},{"ID":4615,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4612,"Name":"internal.metrics.executorDeserializeCpuTime","Value":936000,"Internal":true,"Count Failed Values":true},{"ID":4611,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":151,"Completion Time":1629344528215,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":76,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2819, None)) > 0)\n      +- Project [value#2819]\n         +- Relation[value#2819] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2819, None)) > 0)\n      +- Project [value#2819]\n         +- Relation[value#2819] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2819, None)) > 0)\n      +- Relation[value#2819] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2819, None)) > 0)\n   +- *(1) FileScan text [value#2819] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lovelyz.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2819, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2819] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lovelyz.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lovelyz.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4638,"metricType":"sum"},{"name":"number of files","accumulatorId":4639,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4640,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4641,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4637,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4636,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344528267}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":76,"accumUpdates":[[4639,1],[4640,0]]}
{"Event":"SparkListenerJobStart","Job ID":152,"Submission Time":1629344528289,"Stage Infos":[{"Stage ID":152,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":689,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1525\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[688],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":686,"Name":"FileScanRDD","Scope":"{\"id\":\"1521\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":687,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1521\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[686],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":688,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1524\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[687],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[152],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"76","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":152,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":689,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1525\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[688],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":686,"Name":"FileScanRDD","Scope":"{\"id\":\"1521\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":687,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1521\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[686],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":688,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1524\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[687],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528290,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"76","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":152,"Stage Attempt ID":0,"Task Info":{"Task ID":152,"Index":0,"Attempt":0,"Launch Time":1629344528293,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":152,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":152,"Index":0,"Attempt":0,"Launch Time":1629344528293,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344528298,"Failed":false,"Killed":false,"Accumulables":[{"ID":4637,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4638,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4664,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4663,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4646,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4645,"Name":"internal.metrics.executorCpuTime","Update":1391000,"Value":1391000,"Internal":true,"Count Failed Values":true},{"ID":4644,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":4643,"Name":"internal.metrics.executorDeserializeCpuTime","Update":639000,"Value":639000,"Internal":true,"Count Failed Values":true},{"ID":4642,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":639000,"Executor Run Time":3,"Executor CPU Time":1391000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":152,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":689,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1525\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[688],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":686,"Name":"FileScanRDD","Scope":"{\"id\":\"1521\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":687,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1521\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[686],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":688,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1524\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[687],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528290,"Completion Time":1629344528298,"Accumulables":[{"ID":4644,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":4643,"Name":"internal.metrics.executorDeserializeCpuTime","Value":639000,"Internal":true,"Count Failed Values":true},{"ID":4637,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4664,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4646,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4642,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4663,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4645,"Name":"internal.metrics.executorCpuTime","Value":1391000,"Internal":true,"Count Failed Values":true},{"ID":4638,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":152,"Completion Time":1629344528298,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":76,"time":1629344528298}
{"Event":"SparkListenerJobStart","Job ID":153,"Submission Time":1629344528326,"Stage Infos":[{"Stage ID":153,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":694,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1534\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[693],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":693,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1533\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[692],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":691,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1531\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[690],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":690,"Name":"FileScanRDD","Scope":"{\"id\":\"1531\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":692,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1530\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[691],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[153],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1535\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":153,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":694,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1534\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[693],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":693,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1533\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[692],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":691,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1531\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[690],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":690,"Name":"FileScanRDD","Scope":"{\"id\":\"1531\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":692,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1530\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[691],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528326,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1535\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":153,"Stage Attempt ID":0,"Task Info":{"Task ID":153,"Index":0,"Attempt":0,"Launch Time":1629344528329,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":153,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":153,"Index":0,"Attempt":0,"Launch Time":1629344528329,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344528348,"Failed":false,"Killed":false,"Accumulables":[{"ID":4667,"Name":"number of output rows","Update":"1633","Value":"1633","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4671,"Name":"duration total (min, med, max)","Update":"13","Value":"12","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4694,"Name":"internal.metrics.input.recordsRead","Update":1633,"Value":1633,"Internal":true,"Count Failed Values":true},{"ID":4693,"Name":"internal.metrics.input.bytesRead","Update":101635,"Value":101635,"Internal":true,"Count Failed Values":true},{"ID":4676,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4675,"Name":"internal.metrics.executorCpuTime","Update":13939000,"Value":13939000,"Internal":true,"Count Failed Values":true},{"ID":4674,"Name":"internal.metrics.executorRunTime","Update":15,"Value":15,"Internal":true,"Count Failed Values":true},{"ID":4673,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1110000,"Value":1110000,"Internal":true,"Count Failed Values":true},{"ID":4672,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1110000,"Executor Run Time":15,"Executor CPU Time":13939000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":101635,"Records Read":1633},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":153,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":694,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1534\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[693],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":693,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1533\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[692],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":691,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1531\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[690],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":690,"Name":"FileScanRDD","Scope":"{\"id\":\"1531\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":692,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1530\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[691],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528326,"Completion Time":1629344528348,"Accumulables":[{"ID":4694,"Name":"internal.metrics.input.recordsRead","Value":1633,"Internal":true,"Count Failed Values":true},{"ID":4673,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1110000,"Internal":true,"Count Failed Values":true},{"ID":4667,"Name":"number of output rows","Value":"1633","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4676,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4693,"Name":"internal.metrics.input.bytesRead","Value":101635,"Internal":true,"Count Failed Values":true},{"ID":4675,"Name":"internal.metrics.executorCpuTime","Value":13939000,"Internal":true,"Count Failed Values":true},{"ID":4672,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":4671,"Name":"duration total (min, med, max)","Value":"12","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4674,"Name":"internal.metrics.executorRunTime","Value":15,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":153,"Completion Time":1629344528348,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":77,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2856, None)) > 0)\n      +- Project [value#2856]\n         +- Relation[value#2856] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2856, None)) > 0)\n      +- Project [value#2856]\n         +- Relation[value#2856] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2856, None)) > 0)\n      +- Relation[value#2856] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2856, None)) > 0)\n   +- *(1) FileScan text [value#2856] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/army.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2856, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2856] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/army.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/army.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4699,"metricType":"sum"},{"name":"number of files","accumulatorId":4700,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4701,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4702,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4698,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4697,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344528403}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":77,"accumUpdates":[[4700,1],[4701,0]]}
{"Event":"SparkListenerJobStart","Job ID":154,"Submission Time":1629344528423,"Stage Infos":[{"Stage ID":154,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":698,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1545\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[697],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":695,"Name":"FileScanRDD","Scope":"{\"id\":\"1541\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":697,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1544\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[696],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":696,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1541\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[695],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[154],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"77","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":154,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":698,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1545\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[697],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":695,"Name":"FileScanRDD","Scope":"{\"id\":\"1541\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":697,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1544\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[696],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":696,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1541\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[695],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528424,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"77","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":154,"Stage Attempt ID":0,"Task Info":{"Task ID":154,"Index":0,"Attempt":0,"Launch Time":1629344528427,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":154,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":154,"Index":0,"Attempt":0,"Launch Time":1629344528427,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344528431,"Failed":false,"Killed":false,"Accumulables":[{"ID":4698,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4699,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4725,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4724,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4707,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4706,"Name":"internal.metrics.executorCpuTime","Update":1457000,"Value":1457000,"Internal":true,"Count Failed Values":true},{"ID":4705,"Name":"internal.metrics.executorRunTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4704,"Name":"internal.metrics.executorDeserializeCpuTime","Update":661000,"Value":661000,"Internal":true,"Count Failed Values":true},{"ID":4703,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":661000,"Executor Run Time":1,"Executor CPU Time":1457000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":154,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":698,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1545\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[697],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":695,"Name":"FileScanRDD","Scope":"{\"id\":\"1541\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":697,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1544\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[696],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":696,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1541\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[695],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528424,"Completion Time":1629344528431,"Accumulables":[{"ID":4704,"Name":"internal.metrics.executorDeserializeCpuTime","Value":661000,"Internal":true,"Count Failed Values":true},{"ID":4703,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4724,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4706,"Name":"internal.metrics.executorCpuTime","Value":1457000,"Internal":true,"Count Failed Values":true},{"ID":4699,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4705,"Name":"internal.metrics.executorRunTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4698,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4725,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4707,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":154,"Completion Time":1629344528431,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":77,"time":1629344528431}
{"Event":"SparkListenerJobStart","Job ID":155,"Submission Time":1629344528459,"Stage Infos":[{"Stage ID":155,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":703,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1554\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[702],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":700,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1551\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[699],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":702,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1553\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[701],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":701,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1550\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[700],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":699,"Name":"FileScanRDD","Scope":"{\"id\":\"1551\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[155],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1555\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":155,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":703,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1554\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[702],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":700,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1551\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[699],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":702,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1553\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[701],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":701,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1550\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[700],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":699,"Name":"FileScanRDD","Scope":"{\"id\":\"1551\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528459,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1555\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":155,"Stage Attempt ID":0,"Task Info":{"Task ID":155,"Index":0,"Attempt":0,"Launch Time":1629344528462,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":155,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":155,"Index":0,"Attempt":0,"Launch Time":1629344528462,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344528480,"Failed":false,"Killed":false,"Accumulables":[{"ID":4728,"Name":"number of output rows","Update":"1689","Value":"1689","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4732,"Name":"duration total (min, med, max)","Update":"13","Value":"12","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4755,"Name":"internal.metrics.input.recordsRead","Update":1689,"Value":1689,"Internal":true,"Count Failed Values":true},{"ID":4754,"Name":"internal.metrics.input.bytesRead","Update":119765,"Value":119765,"Internal":true,"Count Failed Values":true},{"ID":4737,"Name":"internal.metrics.resultSize","Update":1485,"Value":1485,"Internal":true,"Count Failed Values":true},{"ID":4736,"Name":"internal.metrics.executorCpuTime","Update":12770000,"Value":12770000,"Internal":true,"Count Failed Values":true},{"ID":4735,"Name":"internal.metrics.executorRunTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":4734,"Name":"internal.metrics.executorDeserializeCpuTime","Update":955000,"Value":955000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":955000,"Executor Run Time":16,"Executor CPU Time":12770000,"Result Size":1485,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":119765,"Records Read":1689},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":155,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":703,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1554\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[702],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":700,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1551\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[699],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":702,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1553\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[701],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":701,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1550\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[700],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":699,"Name":"FileScanRDD","Scope":"{\"id\":\"1551\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528459,"Completion Time":1629344528480,"Accumulables":[{"ID":4754,"Name":"internal.metrics.input.bytesRead","Value":119765,"Internal":true,"Count Failed Values":true},{"ID":4736,"Name":"internal.metrics.executorCpuTime","Value":12770000,"Internal":true,"Count Failed Values":true},{"ID":4735,"Name":"internal.metrics.executorRunTime","Value":16,"Internal":true,"Count Failed Values":true},{"ID":4732,"Name":"duration total (min, med, max)","Value":"12","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4734,"Name":"internal.metrics.executorDeserializeCpuTime","Value":955000,"Internal":true,"Count Failed Values":true},{"ID":4728,"Name":"number of output rows","Value":"1689","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4755,"Name":"internal.metrics.input.recordsRead","Value":1689,"Internal":true,"Count Failed Values":true},{"ID":4737,"Name":"internal.metrics.resultSize","Value":1485,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":155,"Completion Time":1629344528480,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":78,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2893, None)) > 0)\n      +- Project [value#2893]\n         +- Relation[value#2893] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2893, None)) > 0)\n      +- Project [value#2893]\n         +- Relation[value#2893] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2893, None)) > 0)\n      +- Relation[value#2893] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2893, None)) > 0)\n   +- *(1) FileScan text [value#2893] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/neostock.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2893, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2893] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/neostock.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/neostock.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4760,"metricType":"sum"},{"name":"number of files","accumulatorId":4761,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4762,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4763,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4759,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4758,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344528537}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":78,"accumUpdates":[[4761,1],[4762,0]]}
{"Event":"SparkListenerJobStart","Job ID":156,"Submission Time":1629344528558,"Stage Infos":[{"Stage ID":156,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":707,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1565\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[706],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":704,"Name":"FileScanRDD","Scope":"{\"id\":\"1561\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":706,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1564\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[705],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":705,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1561\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[704],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[156],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"78","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":156,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":707,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1565\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[706],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":704,"Name":"FileScanRDD","Scope":"{\"id\":\"1561\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":706,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1564\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[705],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":705,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1561\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[704],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528558,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"78","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":156,"Stage Attempt ID":0,"Task Info":{"Task ID":156,"Index":0,"Attempt":0,"Launch Time":1629344528561,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":156,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":156,"Index":0,"Attempt":0,"Launch Time":1629344528561,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344528566,"Failed":false,"Killed":false,"Accumulables":[{"ID":4759,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4760,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4786,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4785,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4768,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":4767,"Name":"internal.metrics.executorCpuTime","Update":1364000,"Value":1364000,"Internal":true,"Count Failed Values":true},{"ID":4766,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":4765,"Name":"internal.metrics.executorDeserializeCpuTime","Update":728000,"Value":728000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":728000,"Executor Run Time":4,"Executor CPU Time":1364000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":156,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":707,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1565\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[706],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":704,"Name":"FileScanRDD","Scope":"{\"id\":\"1561\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":706,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1564\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[705],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":705,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1561\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[704],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528558,"Completion Time":1629344528566,"Accumulables":[{"ID":4766,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":4760,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4759,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4786,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4768,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":4765,"Name":"internal.metrics.executorDeserializeCpuTime","Value":728000,"Internal":true,"Count Failed Values":true},{"ID":4785,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4767,"Name":"internal.metrics.executorCpuTime","Value":1364000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":156,"Completion Time":1629344528566,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":78,"time":1629344528567}
{"Event":"SparkListenerJobStart","Job ID":157,"Submission Time":1629344528593,"Stage Infos":[{"Stage ID":157,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":712,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1574\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[711],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":708,"Name":"FileScanRDD","Scope":"{\"id\":\"1571\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":711,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1573\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[710],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":709,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1571\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[708],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":710,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1570\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[709],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[157],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1575\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":157,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":712,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1574\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[711],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":708,"Name":"FileScanRDD","Scope":"{\"id\":\"1571\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":711,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1573\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[710],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":709,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1571\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[708],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":710,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1570\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[709],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528593,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1575\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":157,"Stage Attempt ID":0,"Task Info":{"Task ID":157,"Index":0,"Attempt":0,"Launch Time":1629344528597,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":157,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":157,"Index":0,"Attempt":0,"Launch Time":1629344528597,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344528702,"Failed":false,"Killed":false,"Accumulables":[{"ID":4789,"Name":"number of output rows","Update":"15543","Value":"15543","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4793,"Name":"duration total (min, med, max)","Update":"99","Value":"98","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4816,"Name":"internal.metrics.input.recordsRead","Update":15543,"Value":15543,"Internal":true,"Count Failed Values":true},{"ID":4815,"Name":"internal.metrics.input.bytesRead","Update":1135987,"Value":1135987,"Internal":true,"Count Failed Values":true},{"ID":4798,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4797,"Name":"internal.metrics.executorCpuTime","Update":97851000,"Value":97851000,"Internal":true,"Count Failed Values":true},{"ID":4796,"Name":"internal.metrics.executorRunTime","Update":101,"Value":101,"Internal":true,"Count Failed Values":true},{"ID":4795,"Name":"internal.metrics.executorDeserializeCpuTime","Update":947000,"Value":947000,"Internal":true,"Count Failed Values":true},{"ID":4794,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":947000,"Executor Run Time":101,"Executor CPU Time":97851000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1135987,"Records Read":15543},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":157,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":712,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1574\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[711],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":708,"Name":"FileScanRDD","Scope":"{\"id\":\"1571\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":711,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1573\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[710],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":709,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1571\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[708],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":710,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1570\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[709],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528593,"Completion Time":1629344528702,"Accumulables":[{"ID":4793,"Name":"duration total (min, med, max)","Value":"98","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4796,"Name":"internal.metrics.executorRunTime","Value":101,"Internal":true,"Count Failed Values":true},{"ID":4795,"Name":"internal.metrics.executorDeserializeCpuTime","Value":947000,"Internal":true,"Count Failed Values":true},{"ID":4789,"Name":"number of output rows","Value":"15543","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4816,"Name":"internal.metrics.input.recordsRead","Value":15543,"Internal":true,"Count Failed Values":true},{"ID":4798,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4794,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4815,"Name":"internal.metrics.input.bytesRead","Value":1135987,"Internal":true,"Count Failed Values":true},{"ID":4797,"Name":"internal.metrics.executorCpuTime","Value":97851000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":157,"Completion Time":1629344528702,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":79,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2930, None)) > 0)\n      +- Project [value#2930]\n         +- Relation[value#2930] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2930, None)) > 0)\n      +- Project [value#2930]\n         +- Relation[value#2930] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2930, None)) > 0)\n      +- Relation[value#2930] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2930, None)) > 0)\n   +- *(1) FileScan text [value#2930] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/jumper.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2930, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2930] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/jumper.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/jumper.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4821,"metricType":"sum"},{"name":"number of files","accumulatorId":4822,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4823,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4824,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4820,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4819,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344528778}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":79,"accumUpdates":[[4822,1],[4823,0]]}
{"Event":"SparkListenerJobStart","Job ID":158,"Submission Time":1629344528811,"Stage Infos":[{"Stage ID":158,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":716,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1585\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[715],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":714,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1581\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[713],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":715,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1584\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[714],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":713,"Name":"FileScanRDD","Scope":"{\"id\":\"1581\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[158],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"79","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":158,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":716,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1585\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[715],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":714,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1581\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[713],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":715,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1584\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[714],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":713,"Name":"FileScanRDD","Scope":"{\"id\":\"1581\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528811,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"79","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":158,"Stage Attempt ID":0,"Task Info":{"Task ID":158,"Index":0,"Attempt":0,"Launch Time":1629344528815,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":158,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":158,"Index":0,"Attempt":0,"Launch Time":1629344528815,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344528825,"Failed":false,"Killed":false,"Accumulables":[{"ID":4820,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4821,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4847,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4846,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4829,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4828,"Name":"internal.metrics.executorCpuTime","Update":3823000,"Value":3823000,"Internal":true,"Count Failed Values":true},{"ID":4827,"Name":"internal.metrics.executorRunTime","Update":7,"Value":7,"Internal":true,"Count Failed Values":true},{"ID":4826,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1916000,"Value":1916000,"Internal":true,"Count Failed Values":true},{"ID":4825,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1916000,"Executor Run Time":7,"Executor CPU Time":3823000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":158,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":716,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1585\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[715],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":714,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1581\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[713],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":715,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1584\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[714],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":713,"Name":"FileScanRDD","Scope":"{\"id\":\"1581\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528811,"Completion Time":1629344528826,"Accumulables":[{"ID":4826,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1916000,"Internal":true,"Count Failed Values":true},{"ID":4820,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4847,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4829,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4846,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4828,"Name":"internal.metrics.executorCpuTime","Value":3823000,"Internal":true,"Count Failed Values":true},{"ID":4825,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4827,"Name":"internal.metrics.executorRunTime","Value":7,"Internal":true,"Count Failed Values":true},{"ID":4821,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":158,"Completion Time":1629344528826,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":79,"time":1629344528826}
{"Event":"SparkListenerJobStart","Job ID":159,"Submission Time":1629344528883,"Stage Infos":[{"Stage ID":159,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":721,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1594\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[720],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":719,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1590\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[718],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":718,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1591\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[717],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":720,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1593\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[719],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":717,"Name":"FileScanRDD","Scope":"{\"id\":\"1591\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[159],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1595\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":159,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":721,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1594\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[720],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":719,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1590\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[718],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":718,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1591\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[717],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":720,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1593\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[719],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":717,"Name":"FileScanRDD","Scope":"{\"id\":\"1591\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528885,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1595\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":159,"Stage Attempt ID":0,"Task Info":{"Task ID":159,"Index":0,"Attempt":0,"Launch Time":1629344528891,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":159,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":159,"Index":0,"Attempt":0,"Launch Time":1629344528891,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344528927,"Failed":false,"Killed":false,"Accumulables":[{"ID":4850,"Name":"number of output rows","Update":"2265","Value":"2265","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4854,"Name":"duration total (min, med, max)","Update":"27","Value":"26","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4877,"Name":"internal.metrics.input.recordsRead","Update":2265,"Value":2265,"Internal":true,"Count Failed Values":true},{"ID":4876,"Name":"internal.metrics.input.bytesRead","Update":135825,"Value":135825,"Internal":true,"Count Failed Values":true},{"ID":4859,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4858,"Name":"internal.metrics.executorCpuTime","Update":26977000,"Value":26977000,"Internal":true,"Count Failed Values":true},{"ID":4857,"Name":"internal.metrics.executorRunTime","Update":30,"Value":30,"Internal":true,"Count Failed Values":true},{"ID":4856,"Name":"internal.metrics.executorDeserializeCpuTime","Update":2349000,"Value":2349000,"Internal":true,"Count Failed Values":true},{"ID":4855,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":2349000,"Executor Run Time":30,"Executor CPU Time":26977000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":135825,"Records Read":2265},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":159,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":721,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1594\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[720],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":719,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1590\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[718],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":718,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1591\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[717],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":720,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1593\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[719],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":717,"Name":"FileScanRDD","Scope":"{\"id\":\"1591\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344528885,"Completion Time":1629344528928,"Accumulables":[{"ID":4850,"Name":"number of output rows","Value":"2265","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4877,"Name":"internal.metrics.input.recordsRead","Value":2265,"Internal":true,"Count Failed Values":true},{"ID":4859,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4856,"Name":"internal.metrics.executorDeserializeCpuTime","Value":2349000,"Internal":true,"Count Failed Values":true},{"ID":4855,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":4876,"Name":"internal.metrics.input.bytesRead","Value":135825,"Internal":true,"Count Failed Values":true},{"ID":4858,"Name":"internal.metrics.executorCpuTime","Value":26977000,"Internal":true,"Count Failed Values":true},{"ID":4854,"Name":"duration total (min, med, max)","Value":"26","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4857,"Name":"internal.metrics.executorRunTime","Value":30,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":159,"Completion Time":1629344528928,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":80,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2967, None)) > 0)\n      +- Project [value#2967]\n         +- Relation[value#2967] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2967, None)) > 0)\n      +- Project [value#2967]\n         +- Relation[value#2967] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#2967, None)) > 0)\n      +- Relation[value#2967] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#2967, None)) > 0)\n   +- *(1) FileScan text [value#2967] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/car_new1.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#2967, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#2967] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/car_new1.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/car_new1.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4882,"metricType":"sum"},{"name":"number of files","accumulatorId":4883,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4884,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4885,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4881,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4880,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344529007}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":80,"accumUpdates":[[4883,1],[4884,0]]}
{"Event":"SparkListenerJobStart","Job ID":160,"Submission Time":1629344529032,"Stage Infos":[{"Stage ID":160,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":725,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1605\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[724],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":723,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1601\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[722],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":724,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1604\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[723],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":722,"Name":"FileScanRDD","Scope":"{\"id\":\"1601\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[160],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"80","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":160,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":725,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1605\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[724],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":723,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1601\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[722],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":724,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1604\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[723],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":722,"Name":"FileScanRDD","Scope":"{\"id\":\"1601\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529032,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"80","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":160,"Stage Attempt ID":0,"Task Info":{"Task ID":160,"Index":0,"Attempt":0,"Launch Time":1629344529035,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":160,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":160,"Index":0,"Attempt":0,"Launch Time":1629344529035,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344529040,"Failed":false,"Killed":false,"Accumulables":[{"ID":4881,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4882,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4908,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4907,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4890,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4889,"Name":"internal.metrics.executorCpuTime","Update":1466000,"Value":1466000,"Internal":true,"Count Failed Values":true},{"ID":4888,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":4887,"Name":"internal.metrics.executorDeserializeCpuTime","Update":732000,"Value":732000,"Internal":true,"Count Failed Values":true},{"ID":4886,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":732000,"Executor Run Time":3,"Executor CPU Time":1466000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":160,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":725,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1605\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[724],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":723,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1601\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[722],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":724,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1604\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[723],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":722,"Name":"FileScanRDD","Scope":"{\"id\":\"1601\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529032,"Completion Time":1629344529040,"Accumulables":[{"ID":4886,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4907,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4889,"Name":"internal.metrics.executorCpuTime","Value":1466000,"Internal":true,"Count Failed Values":true},{"ID":4888,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":4882,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4887,"Name":"internal.metrics.executorDeserializeCpuTime","Value":732000,"Internal":true,"Count Failed Values":true},{"ID":4881,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4908,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4890,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":160,"Completion Time":1629344529040,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":80,"time":1629344529041}
{"Event":"SparkListenerJobStart","Job ID":161,"Submission Time":1629344529068,"Stage Infos":[{"Stage ID":161,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":730,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1614\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[729],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":729,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1613\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[728],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":726,"Name":"FileScanRDD","Scope":"{\"id\":\"1611\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":728,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1610\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[727],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":727,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1611\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[726],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[161],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1615\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":161,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":730,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1614\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[729],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":729,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1613\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[728],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":726,"Name":"FileScanRDD","Scope":"{\"id\":\"1611\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":728,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1610\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[727],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":727,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1611\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[726],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529068,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1615\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":161,"Stage Attempt ID":0,"Task Info":{"Task ID":161,"Index":0,"Attempt":0,"Launch Time":1629344529070,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":161,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":161,"Index":0,"Attempt":0,"Launch Time":1629344529070,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344529136,"Failed":false,"Killed":false,"Accumulables":[{"ID":4911,"Name":"number of output rows","Update":"10773","Value":"10773","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4915,"Name":"duration total (min, med, max)","Update":"61","Value":"60","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4938,"Name":"internal.metrics.input.recordsRead","Update":10773,"Value":10773,"Internal":true,"Count Failed Values":true},{"ID":4937,"Name":"internal.metrics.input.bytesRead","Update":791401,"Value":791401,"Internal":true,"Count Failed Values":true},{"ID":4920,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4919,"Name":"internal.metrics.executorCpuTime","Update":62886000,"Value":62886000,"Internal":true,"Count Failed Values":true},{"ID":4918,"Name":"internal.metrics.executorRunTime","Update":63,"Value":63,"Internal":true,"Count Failed Values":true},{"ID":4917,"Name":"internal.metrics.executorDeserializeCpuTime","Update":941000,"Value":941000,"Internal":true,"Count Failed Values":true},{"ID":4916,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":941000,"Executor Run Time":63,"Executor CPU Time":62886000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":791401,"Records Read":10773},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":161,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":730,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1614\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[729],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":729,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1613\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[728],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":726,"Name":"FileScanRDD","Scope":"{\"id\":\"1611\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":728,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1610\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[727],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":727,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1611\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[726],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529068,"Completion Time":1629344529137,"Accumulables":[{"ID":4937,"Name":"internal.metrics.input.bytesRead","Value":791401,"Internal":true,"Count Failed Values":true},{"ID":4919,"Name":"internal.metrics.executorCpuTime","Value":62886000,"Internal":true,"Count Failed Values":true},{"ID":4916,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4915,"Name":"duration total (min, med, max)","Value":"60","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4918,"Name":"internal.metrics.executorRunTime","Value":63,"Internal":true,"Count Failed Values":true},{"ID":4911,"Name":"number of output rows","Value":"10773","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4938,"Name":"internal.metrics.input.recordsRead","Value":10773,"Internal":true,"Count Failed Values":true},{"ID":4920,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4917,"Name":"internal.metrics.executorDeserializeCpuTime","Value":941000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":161,"Completion Time":1629344529137,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":81,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3004, None)) > 0)\n      +- Project [value#3004]\n         +- Relation[value#3004] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3004, None)) > 0)\n      +- Project [value#3004]\n         +- Relation[value#3004] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3004, None)) > 0)\n      +- Relation[value#3004] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3004, None)) > 0)\n   +- *(1) FileScan text [value#3004] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/hanwhaeagles..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3004, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3004] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/hanwhaeagles..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/hanwhaeagles_new.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":4943,"metricType":"sum"},{"name":"number of files","accumulatorId":4944,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":4945,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":4946,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4942,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":4941,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344529194}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":81,"accumUpdates":[[4944,1],[4945,0]]}
{"Event":"SparkListenerJobStart","Job ID":162,"Submission Time":1629344529216,"Stage Infos":[{"Stage ID":162,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":734,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1625\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[733],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":731,"Name":"FileScanRDD","Scope":"{\"id\":\"1621\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":733,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1624\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[732],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":732,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1621\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[731],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[162],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"81","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":162,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":734,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1625\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[733],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":731,"Name":"FileScanRDD","Scope":"{\"id\":\"1621\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":733,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1624\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[732],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":732,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1621\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[731],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529216,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"81","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":162,"Stage Attempt ID":0,"Task Info":{"Task ID":162,"Index":0,"Attempt":0,"Launch Time":1629344529220,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":162,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":162,"Index":0,"Attempt":0,"Launch Time":1629344529220,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344529226,"Failed":false,"Killed":false,"Accumulables":[{"ID":4942,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4943,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4969,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":4968,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4951,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4950,"Name":"internal.metrics.executorCpuTime","Update":1558000,"Value":1558000,"Internal":true,"Count Failed Values":true},{"ID":4949,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":4948,"Name":"internal.metrics.executorDeserializeCpuTime","Update":625000,"Value":625000,"Internal":true,"Count Failed Values":true},{"ID":4947,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":625000,"Executor Run Time":4,"Executor CPU Time":1558000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":162,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":734,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1625\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[733],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":731,"Name":"FileScanRDD","Scope":"{\"id\":\"1621\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":733,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1624\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[732],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":732,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1621\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[731],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529216,"Completion Time":1629344529226,"Accumulables":[{"ID":4949,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":4948,"Name":"internal.metrics.executorDeserializeCpuTime","Value":625000,"Internal":true,"Count Failed Values":true},{"ID":4942,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4969,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4951,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":4947,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4968,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":4950,"Name":"internal.metrics.executorCpuTime","Value":1558000,"Internal":true,"Count Failed Values":true},{"ID":4943,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":162,"Completion Time":1629344529226,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":81,"time":1629344529226}
{"Event":"SparkListenerJobStart","Job ID":163,"Submission Time":1629344529253,"Stage Infos":[{"Stage ID":163,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":739,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1634\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[738],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":735,"Name":"FileScanRDD","Scope":"{\"id\":\"1631\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":738,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1633\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[737],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":737,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1630\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[736],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":736,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1631\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[735],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[163],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1635\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":163,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":739,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1634\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[738],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":735,"Name":"FileScanRDD","Scope":"{\"id\":\"1631\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":738,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1633\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[737],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":737,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1630\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[736],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":736,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1631\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[735],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529254,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1635\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":163,"Stage Attempt ID":0,"Task Info":{"Task ID":163,"Index":0,"Attempt":0,"Launch Time":1629344529256,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":163,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":163,"Index":0,"Attempt":0,"Launch Time":1629344529256,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344529315,"Failed":false,"Killed":false,"Accumulables":[{"ID":4972,"Name":"number of output rows","Update":"9347","Value":"9347","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4976,"Name":"duration total (min, med, max)","Update":"55","Value":"54","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4999,"Name":"internal.metrics.input.recordsRead","Update":9347,"Value":9347,"Internal":true,"Count Failed Values":true},{"ID":4998,"Name":"internal.metrics.input.bytesRead","Update":670191,"Value":670191,"Internal":true,"Count Failed Values":true},{"ID":4981,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4980,"Name":"internal.metrics.executorCpuTime","Update":56004000,"Value":56004000,"Internal":true,"Count Failed Values":true},{"ID":4979,"Name":"internal.metrics.executorRunTime","Update":56,"Value":56,"Internal":true,"Count Failed Values":true},{"ID":4978,"Name":"internal.metrics.executorDeserializeCpuTime","Update":901000,"Value":901000,"Internal":true,"Count Failed Values":true},{"ID":4977,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":901000,"Executor Run Time":56,"Executor CPU Time":56004000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":670191,"Records Read":9347},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":163,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":739,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1634\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[738],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":735,"Name":"FileScanRDD","Scope":"{\"id\":\"1631\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":738,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1633\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[737],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":737,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1630\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[736],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":736,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1631\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[735],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529254,"Completion Time":1629344529316,"Accumulables":[{"ID":4976,"Name":"duration total (min, med, max)","Value":"54","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4999,"Name":"internal.metrics.input.recordsRead","Value":9347,"Internal":true,"Count Failed Values":true},{"ID":4978,"Name":"internal.metrics.executorDeserializeCpuTime","Value":901000,"Internal":true,"Count Failed Values":true},{"ID":4972,"Name":"number of output rows","Value":"9347","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4981,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":4998,"Name":"internal.metrics.input.bytesRead","Value":670191,"Internal":true,"Count Failed Values":true},{"ID":4980,"Name":"internal.metrics.executorCpuTime","Value":56004000,"Internal":true,"Count Failed Values":true},{"ID":4977,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":4979,"Name":"internal.metrics.executorRunTime","Value":56,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":163,"Completion Time":1629344529316,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":82,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3041, None)) > 0)\n      +- Project [value#3041]\n         +- Relation[value#3041] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3041, None)) > 0)\n      +- Project [value#3041]\n         +- Relation[value#3041] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3041, None)) > 0)\n      +- Relation[value#3041] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3041, None)) > 0)\n   +- *(1) FileScan text [value#3041] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/sh_new.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3041, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3041] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/sh_new.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/sh_new.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5004,"metricType":"sum"},{"name":"number of files","accumulatorId":5005,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5006,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5007,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5003,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5002,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344529376}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":82,"accumUpdates":[[5005,1],[5006,0]]}
{"Event":"SparkListenerJobStart","Job ID":164,"Submission Time":1629344529397,"Stage Infos":[{"Stage ID":164,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":743,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1645\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[742],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":740,"Name":"FileScanRDD","Scope":"{\"id\":\"1641\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":742,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1644\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[741],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":741,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1641\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[740],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[164],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"82","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":164,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":743,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1645\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[742],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":740,"Name":"FileScanRDD","Scope":"{\"id\":\"1641\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":742,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1644\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[741],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":741,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1641\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[740],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529397,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"82","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":164,"Stage Attempt ID":0,"Task Info":{"Task ID":164,"Index":0,"Attempt":0,"Launch Time":1629344529400,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":164,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":164,"Index":0,"Attempt":0,"Launch Time":1629344529400,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344529405,"Failed":false,"Killed":false,"Accumulables":[{"ID":5003,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5004,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5030,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5029,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5012,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5011,"Name":"internal.metrics.executorCpuTime","Update":1332000,"Value":1332000,"Internal":true,"Count Failed Values":true},{"ID":5010,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":5009,"Name":"internal.metrics.executorDeserializeCpuTime","Update":622000,"Value":622000,"Internal":true,"Count Failed Values":true},{"ID":5008,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":622000,"Executor Run Time":3,"Executor CPU Time":1332000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":164,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":743,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1645\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[742],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":740,"Name":"FileScanRDD","Scope":"{\"id\":\"1641\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":742,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1644\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[741],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":741,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1641\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[740],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529397,"Completion Time":1629344529406,"Accumulables":[{"ID":5009,"Name":"internal.metrics.executorDeserializeCpuTime","Value":622000,"Internal":true,"Count Failed Values":true},{"ID":5008,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5029,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5011,"Name":"internal.metrics.executorCpuTime","Value":1332000,"Internal":true,"Count Failed Values":true},{"ID":5010,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":5004,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5003,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5030,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5012,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":164,"Completion Time":1629344529406,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":82,"time":1629344529406}
{"Event":"SparkListenerJobStart","Job ID":165,"Submission Time":1629344529433,"Stage Infos":[{"Stage ID":165,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":748,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1654\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[747],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":747,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1653\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[746],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":746,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1650\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[745],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":745,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1651\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[744],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":744,"Name":"FileScanRDD","Scope":"{\"id\":\"1651\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[165],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1655\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":165,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":748,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1654\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[747],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":747,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1653\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[746],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":746,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1650\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[745],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":745,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1651\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[744],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":744,"Name":"FileScanRDD","Scope":"{\"id\":\"1651\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529433,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1655\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":165,"Stage Attempt ID":0,"Task Info":{"Task ID":165,"Index":0,"Attempt":0,"Launch Time":1629344529437,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":165,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":165,"Index":0,"Attempt":0,"Launch Time":1629344529437,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344529488,"Failed":false,"Killed":false,"Accumulables":[{"ID":5033,"Name":"number of output rows","Update":"7362","Value":"7362","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5037,"Name":"duration total (min, med, max)","Update":"47","Value":"46","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5060,"Name":"internal.metrics.input.recordsRead","Update":7362,"Value":7362,"Internal":true,"Count Failed Values":true},{"ID":5059,"Name":"internal.metrics.input.bytesRead","Update":563893,"Value":563893,"Internal":true,"Count Failed Values":true},{"ID":5042,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5041,"Name":"internal.metrics.executorCpuTime","Update":46024000,"Value":46024000,"Internal":true,"Count Failed Values":true},{"ID":5040,"Name":"internal.metrics.executorRunTime","Update":49,"Value":49,"Internal":true,"Count Failed Values":true},{"ID":5039,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1009000,"Value":1009000,"Internal":true,"Count Failed Values":true},{"ID":5038,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1009000,"Executor Run Time":49,"Executor CPU Time":46024000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":563893,"Records Read":7362},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":165,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":748,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1654\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[747],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":747,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1653\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[746],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":746,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1650\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[745],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":745,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1651\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[744],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":744,"Name":"FileScanRDD","Scope":"{\"id\":\"1651\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529433,"Completion Time":1629344529489,"Accumulables":[{"ID":5059,"Name":"internal.metrics.input.bytesRead","Value":563893,"Internal":true,"Count Failed Values":true},{"ID":5038,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5041,"Name":"internal.metrics.executorCpuTime","Value":46024000,"Internal":true,"Count Failed Values":true},{"ID":5040,"Name":"internal.metrics.executorRunTime","Value":49,"Internal":true,"Count Failed Values":true},{"ID":5037,"Name":"duration total (min, med, max)","Value":"46","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5039,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1009000,"Internal":true,"Count Failed Values":true},{"ID":5033,"Name":"number of output rows","Value":"7362","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5060,"Name":"internal.metrics.input.recordsRead","Value":7362,"Internal":true,"Count Failed Values":true},{"ID":5042,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":165,"Completion Time":1629344529489,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":83,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3078, None)) > 0)\n      +- Project [value#3078]\n         +- Relation[value#3078] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3078, None)) > 0)\n      +- Project [value#3078]\n         +- Relation[value#3078] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3078, None)) > 0)\n      +- Relation[value#3078] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3078, None)) > 0)\n   +- *(1) FileScan text [value#3078] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/top12.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3078, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3078] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/top12.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/top12.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5065,"metricType":"sum"},{"name":"number of files","accumulatorId":5066,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5067,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5068,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5064,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5063,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344529549}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":83,"accumUpdates":[[5066,1],[5067,0]]}
{"Event":"SparkListenerJobStart","Job ID":166,"Submission Time":1629344529572,"Stage Infos":[{"Stage ID":166,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":752,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1665\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[751],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":751,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1664\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[750],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":749,"Name":"FileScanRDD","Scope":"{\"id\":\"1661\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":750,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1661\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[749],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[166],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"83","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":166,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":752,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1665\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[751],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":751,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1664\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[750],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":749,"Name":"FileScanRDD","Scope":"{\"id\":\"1661\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":750,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1661\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[749],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529572,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"83","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":166,"Stage Attempt ID":0,"Task Info":{"Task ID":166,"Index":0,"Attempt":0,"Launch Time":1629344529576,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":166,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":166,"Index":0,"Attempt":0,"Launch Time":1629344529576,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344529580,"Failed":false,"Killed":false,"Accumulables":[{"ID":5064,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5065,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5091,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5090,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5073,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5072,"Name":"internal.metrics.executorCpuTime","Update":1646000,"Value":1646000,"Internal":true,"Count Failed Values":true},{"ID":5071,"Name":"internal.metrics.executorRunTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5070,"Name":"internal.metrics.executorDeserializeCpuTime","Update":790000,"Value":790000,"Internal":true,"Count Failed Values":true},{"ID":5069,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":790000,"Executor Run Time":1,"Executor CPU Time":1646000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":166,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":752,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1665\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[751],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":751,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1664\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[750],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":749,"Name":"FileScanRDD","Scope":"{\"id\":\"1661\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":750,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1661\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[749],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529572,"Completion Time":1629344529581,"Accumulables":[{"ID":5071,"Name":"internal.metrics.executorRunTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5065,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5091,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5070,"Name":"internal.metrics.executorDeserializeCpuTime","Value":790000,"Internal":true,"Count Failed Values":true},{"ID":5064,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5073,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5090,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5072,"Name":"internal.metrics.executorCpuTime","Value":1646000,"Internal":true,"Count Failed Values":true},{"ID":5069,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":166,"Completion Time":1629344529581,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":83,"time":1629344529581}
{"Event":"SparkListenerJobStart","Job ID":167,"Submission Time":1629344529610,"Stage Infos":[{"Stage ID":167,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":757,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1674\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[756],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":754,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1671\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[753],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":756,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1673\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[755],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":753,"Name":"FileScanRDD","Scope":"{\"id\":\"1671\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":755,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1670\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[754],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[167],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1675\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":167,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":757,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1674\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[756],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":754,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1671\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[753],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":756,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1673\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[755],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":753,"Name":"FileScanRDD","Scope":"{\"id\":\"1671\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":755,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1670\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[754],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529611,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1675\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":167,"Stage Attempt ID":0,"Task Info":{"Task ID":167,"Index":0,"Attempt":0,"Launch Time":1629344529615,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":167,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":167,"Index":0,"Attempt":0,"Launch Time":1629344529615,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344529726,"Failed":false,"Killed":false,"Accumulables":[{"ID":5094,"Name":"number of output rows","Update":"11414","Value":"11414","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5098,"Name":"duration total (min, med, max)","Update":"106","Value":"105","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5121,"Name":"internal.metrics.input.recordsRead","Update":11414,"Value":11414,"Internal":true,"Count Failed Values":true},{"ID":5120,"Name":"internal.metrics.input.bytesRead","Update":879401,"Value":879401,"Internal":true,"Count Failed Values":true},{"ID":5103,"Name":"internal.metrics.resultSize","Update":1485,"Value":1485,"Internal":true,"Count Failed Values":true},{"ID":5102,"Name":"internal.metrics.executorCpuTime","Update":107349000,"Value":107349000,"Internal":true,"Count Failed Values":true},{"ID":5101,"Name":"internal.metrics.executorRunTime","Update":110,"Value":110,"Internal":true,"Count Failed Values":true},{"ID":5100,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1051000,"Value":1051000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":1051000,"Executor Run Time":110,"Executor CPU Time":107349000,"Result Size":1485,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":879401,"Records Read":11414},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":167,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":757,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1674\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[756],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":754,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1671\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[753],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":756,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1673\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[755],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":753,"Name":"FileScanRDD","Scope":"{\"id\":\"1671\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":755,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1670\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[754],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529611,"Completion Time":1629344529727,"Accumulables":[{"ID":5098,"Name":"duration total (min, med, max)","Value":"105","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5101,"Name":"internal.metrics.executorRunTime","Value":110,"Internal":true,"Count Failed Values":true},{"ID":5100,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1051000,"Internal":true,"Count Failed Values":true},{"ID":5094,"Name":"number of output rows","Value":"11414","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5121,"Name":"internal.metrics.input.recordsRead","Value":11414,"Internal":true,"Count Failed Values":true},{"ID":5103,"Name":"internal.metrics.resultSize","Value":1485,"Internal":true,"Count Failed Values":true},{"ID":5120,"Name":"internal.metrics.input.bytesRead","Value":879401,"Internal":true,"Count Failed Values":true},{"ID":5102,"Name":"internal.metrics.executorCpuTime","Value":107349000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":167,"Completion Time":1629344529727,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":84,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3115, None)) > 0)\n      +- Project [value#3115]\n         +- Relation[value#3115] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3115, None)) > 0)\n      +- Project [value#3115]\n         +- Relation[value#3115] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3115, None)) > 0)\n      +- Relation[value#3115] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3115, None)) > 0)\n   +- *(1) FileScan text [value#3115] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/baseball_ab2..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3115, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3115] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/baseball_ab2..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/baseball_ab2.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5126,"metricType":"sum"},{"name":"number of files","accumulatorId":5127,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5128,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5129,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5125,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5124,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344529852}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":84,"accumUpdates":[[5127,1],[5128,0]]}
{"Event":"SparkListenerJobStart","Job ID":168,"Submission Time":1629344529883,"Stage Infos":[{"Stage ID":168,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":761,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1685\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[760],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":760,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1684\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[759],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":758,"Name":"FileScanRDD","Scope":"{\"id\":\"1681\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":759,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1681\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[758],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[168],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"84","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":168,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":761,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1685\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[760],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":760,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1684\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[759],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":758,"Name":"FileScanRDD","Scope":"{\"id\":\"1681\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":759,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1681\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[758],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529884,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"84","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":168,"Stage Attempt ID":0,"Task Info":{"Task ID":168,"Index":0,"Attempt":0,"Launch Time":1629344529889,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":168,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":168,"Index":0,"Attempt":0,"Launch Time":1629344529889,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344529896,"Failed":false,"Killed":false,"Accumulables":[{"ID":5125,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5126,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5152,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5151,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5134,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5133,"Name":"internal.metrics.executorCpuTime","Update":2259000,"Value":2259000,"Internal":true,"Count Failed Values":true},{"ID":5132,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":5131,"Name":"internal.metrics.executorDeserializeCpuTime","Update":879000,"Value":879000,"Internal":true,"Count Failed Values":true},{"ID":5130,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":879000,"Executor Run Time":4,"Executor CPU Time":2259000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":168,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":761,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1685\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[760],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":760,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1684\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[759],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":758,"Name":"FileScanRDD","Scope":"{\"id\":\"1681\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":759,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1681\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[758],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529884,"Completion Time":1629344529897,"Accumulables":[{"ID":5131,"Name":"internal.metrics.executorDeserializeCpuTime","Value":879000,"Internal":true,"Count Failed Values":true},{"ID":5125,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5152,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5134,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5151,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5130,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5133,"Name":"internal.metrics.executorCpuTime","Value":2259000,"Internal":true,"Count Failed Values":true},{"ID":5132,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":5126,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":168,"Completion Time":1629344529897,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":84,"time":1629344529897}
{"Event":"SparkListenerJobStart","Job ID":169,"Submission Time":1629344529943,"Stage Infos":[{"Stage ID":169,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":766,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1694\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[765],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":762,"Name":"FileScanRDD","Scope":"{\"id\":\"1691\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":764,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1690\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[763],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":765,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1693\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[764],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":763,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1691\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[762],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[169],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1695\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":169,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":766,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1694\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[765],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":762,"Name":"FileScanRDD","Scope":"{\"id\":\"1691\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":764,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1690\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[763],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":765,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1693\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[764],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":763,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1691\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[762],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529943,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1695\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":169,"Stage Attempt ID":0,"Task Info":{"Task ID":169,"Index":0,"Attempt":0,"Launch Time":1629344529951,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":169,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":169,"Index":0,"Attempt":0,"Launch Time":1629344529951,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344530096,"Failed":false,"Killed":false,"Accumulables":[{"ID":5155,"Name":"number of output rows","Update":"22181","Value":"22181","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5159,"Name":"duration total (min, med, max)","Update":"139","Value":"138","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5182,"Name":"internal.metrics.input.recordsRead","Update":22181,"Value":22181,"Internal":true,"Count Failed Values":true},{"ID":5181,"Name":"internal.metrics.input.bytesRead","Update":1743212,"Value":1743212,"Internal":true,"Count Failed Values":true},{"ID":5164,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5163,"Name":"internal.metrics.executorCpuTime","Update":138826000,"Value":138826000,"Internal":true,"Count Failed Values":true},{"ID":5162,"Name":"internal.metrics.executorRunTime","Update":142,"Value":142,"Internal":true,"Count Failed Values":true},{"ID":5161,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1990000,"Value":1990000,"Internal":true,"Count Failed Values":true},{"ID":5160,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1990000,"Executor Run Time":142,"Executor CPU Time":138826000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1743212,"Records Read":22181},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":169,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":766,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1694\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[765],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":762,"Name":"FileScanRDD","Scope":"{\"id\":\"1691\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":764,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1690\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[763],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":765,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1693\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[764],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":763,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1691\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[762],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344529943,"Completion Time":1629344530096,"Accumulables":[{"ID":5155,"Name":"number of output rows","Value":"22181","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5182,"Name":"internal.metrics.input.recordsRead","Value":22181,"Internal":true,"Count Failed Values":true},{"ID":5164,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5161,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1990000,"Internal":true,"Count Failed Values":true},{"ID":5160,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5181,"Name":"internal.metrics.input.bytesRead","Value":1743212,"Internal":true,"Count Failed Values":true},{"ID":5163,"Name":"internal.metrics.executorCpuTime","Value":138826000,"Internal":true,"Count Failed Values":true},{"ID":5159,"Name":"duration total (min, med, max)","Value":"138","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5162,"Name":"internal.metrics.executorRunTime","Value":142,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":169,"Completion Time":1629344530096,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":85,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3152, None)) > 0)\n      +- Project [value#3152]\n         +- Relation[value#3152] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3152, None)) > 0)\n      +- Project [value#3152]\n         +- Relation[value#3152] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3152, None)) > 0)\n      +- Relation[value#3152] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3152, None)) > 0)\n   +- *(1) FileScan text [value#3152] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/tr.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3152, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3152] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/tr.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/tr.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5187,"metricType":"sum"},{"name":"number of files","accumulatorId":5188,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5189,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5190,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5186,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5185,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344530162}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":85,"accumUpdates":[[5188,1],[5189,0]]}
{"Event":"SparkListenerJobStart","Job ID":170,"Submission Time":1629344530185,"Stage Infos":[{"Stage ID":170,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":770,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1705\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[769],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":769,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1704\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[768],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":768,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1701\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[767],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":767,"Name":"FileScanRDD","Scope":"{\"id\":\"1701\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[170],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"85","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":170,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":770,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1705\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[769],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":769,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1704\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[768],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":768,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1701\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[767],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":767,"Name":"FileScanRDD","Scope":"{\"id\":\"1701\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530185,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"85","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":170,"Stage Attempt ID":0,"Task Info":{"Task ID":170,"Index":0,"Attempt":0,"Launch Time":1629344530188,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":170,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":170,"Index":0,"Attempt":0,"Launch Time":1629344530188,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344530194,"Failed":false,"Killed":false,"Accumulables":[{"ID":5186,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5187,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5213,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5212,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5195,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":5194,"Name":"internal.metrics.executorCpuTime","Update":1536000,"Value":1536000,"Internal":true,"Count Failed Values":true},{"ID":5193,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":5192,"Name":"internal.metrics.executorDeserializeCpuTime","Update":700000,"Value":700000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":700000,"Executor Run Time":4,"Executor CPU Time":1536000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":170,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":770,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1705\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[769],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":769,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1704\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[768],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":768,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1701\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[767],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":767,"Name":"FileScanRDD","Scope":"{\"id\":\"1701\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530185,"Completion Time":1629344530194,"Accumulables":[{"ID":5212,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5194,"Name":"internal.metrics.executorCpuTime","Value":1536000,"Internal":true,"Count Failed Values":true},{"ID":5187,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5193,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":5192,"Name":"internal.metrics.executorDeserializeCpuTime","Value":700000,"Internal":true,"Count Failed Values":true},{"ID":5186,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5213,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5195,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":170,"Completion Time":1629344530194,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":85,"time":1629344530194}
{"Event":"SparkListenerJobStart","Job ID":171,"Submission Time":1629344530220,"Stage Infos":[{"Stage ID":171,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":775,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1714\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[774],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":773,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1710\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[772],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":774,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1713\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[773],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":772,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1711\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[771],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":771,"Name":"FileScanRDD","Scope":"{\"id\":\"1711\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[171],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1715\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":171,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":775,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1714\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[774],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":773,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1710\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[772],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":774,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1713\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[773],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":772,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1711\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[771],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":771,"Name":"FileScanRDD","Scope":"{\"id\":\"1711\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530221,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1715\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":171,"Stage Attempt ID":0,"Task Info":{"Task ID":171,"Index":0,"Attempt":0,"Launch Time":1629344530223,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":171,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":171,"Index":0,"Attempt":0,"Launch Time":1629344530223,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344530270,"Failed":false,"Killed":false,"Accumulables":[{"ID":5216,"Name":"number of output rows","Update":"7243","Value":"7243","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5220,"Name":"duration total (min, med, max)","Update":"42","Value":"41","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5243,"Name":"internal.metrics.input.recordsRead","Update":7243,"Value":7243,"Internal":true,"Count Failed Values":true},{"ID":5242,"Name":"internal.metrics.input.bytesRead","Update":491333,"Value":491333,"Internal":true,"Count Failed Values":true},{"ID":5225,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5224,"Name":"internal.metrics.executorCpuTime","Update":43954000,"Value":43954000,"Internal":true,"Count Failed Values":true},{"ID":5223,"Name":"internal.metrics.executorRunTime","Update":45,"Value":45,"Internal":true,"Count Failed Values":true},{"ID":5222,"Name":"internal.metrics.executorDeserializeCpuTime","Update":920000,"Value":920000,"Internal":true,"Count Failed Values":true},{"ID":5221,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":920000,"Executor Run Time":45,"Executor CPU Time":43954000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":491333,"Records Read":7243},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":171,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":775,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1714\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[774],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":773,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1710\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[772],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":774,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1713\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[773],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":772,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1711\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[771],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":771,"Name":"FileScanRDD","Scope":"{\"id\":\"1711\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530221,"Completion Time":1629344530270,"Accumulables":[{"ID":5242,"Name":"internal.metrics.input.bytesRead","Value":491333,"Internal":true,"Count Failed Values":true},{"ID":5224,"Name":"internal.metrics.executorCpuTime","Value":43954000,"Internal":true,"Count Failed Values":true},{"ID":5221,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5220,"Name":"duration total (min, med, max)","Value":"41","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5223,"Name":"internal.metrics.executorRunTime","Value":45,"Internal":true,"Count Failed Values":true},{"ID":5243,"Name":"internal.metrics.input.recordsRead","Value":7243,"Internal":true,"Count Failed Values":true},{"ID":5225,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5222,"Name":"internal.metrics.executorDeserializeCpuTime","Value":920000,"Internal":true,"Count Failed Values":true},{"ID":5216,"Name":"number of output rows","Value":"7243","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":171,"Completion Time":1629344530270,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":86,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3189, None)) > 0)\n      +- Project [value#3189]\n         +- Relation[value#3189] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3189, None)) > 0)\n      +- Project [value#3189]\n         +- Relation[value#3189] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3189, None)) > 0)\n      +- Relation[value#3189] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3189, None)) > 0)\n   +- *(1) FileScan text [value#3189] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/rhythmgame_n..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3189, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3189] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/rhythmgame_n..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/rhythmgame_new1.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5248,"metricType":"sum"},{"name":"number of files","accumulatorId":5249,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5250,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5251,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5247,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5246,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344530332}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":86,"accumUpdates":[[5249,1],[5250,0]]}
{"Event":"SparkListenerJobStart","Job ID":172,"Submission Time":1629344530356,"Stage Infos":[{"Stage ID":172,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":779,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1725\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[778],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":777,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1721\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[776],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":776,"Name":"FileScanRDD","Scope":"{\"id\":\"1721\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":778,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1724\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[777],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[172],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"86","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":172,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":779,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1725\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[778],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":777,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1721\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[776],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":776,"Name":"FileScanRDD","Scope":"{\"id\":\"1721\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":778,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1724\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[777],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530357,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"86","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":172,"Stage Attempt ID":0,"Task Info":{"Task ID":172,"Index":0,"Attempt":0,"Launch Time":1629344530361,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":172,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":172,"Index":0,"Attempt":0,"Launch Time":1629344530361,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344530370,"Failed":false,"Killed":false,"Accumulables":[{"ID":5247,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5248,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5274,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5273,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5256,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":5255,"Name":"internal.metrics.executorCpuTime","Update":3745000,"Value":3745000,"Internal":true,"Count Failed Values":true},{"ID":5254,"Name":"internal.metrics.executorRunTime","Update":7,"Value":7,"Internal":true,"Count Failed Values":true},{"ID":5253,"Name":"internal.metrics.executorDeserializeCpuTime","Update":900000,"Value":900000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":900000,"Executor Run Time":7,"Executor CPU Time":3745000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":172,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":779,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1725\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[778],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":777,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1721\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[776],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":776,"Name":"FileScanRDD","Scope":"{\"id\":\"1721\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":778,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1724\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[777],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530357,"Completion Time":1629344530371,"Accumulables":[{"ID":5254,"Name":"internal.metrics.executorRunTime","Value":7,"Internal":true,"Count Failed Values":true},{"ID":5247,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5274,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5256,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":5253,"Name":"internal.metrics.executorDeserializeCpuTime","Value":900000,"Internal":true,"Count Failed Values":true},{"ID":5273,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5255,"Name":"internal.metrics.executorCpuTime","Value":3745000,"Internal":true,"Count Failed Values":true},{"ID":5248,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":172,"Completion Time":1629344530371,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":86,"time":1629344530372}
{"Event":"SparkListenerJobStart","Job ID":173,"Submission Time":1629344530413,"Stage Infos":[{"Stage ID":173,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":784,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1734\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[783],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":782,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1730\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[781],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":781,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1731\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[780],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":783,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1733\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[782],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":780,"Name":"FileScanRDD","Scope":"{\"id\":\"1731\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[173],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1735\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":173,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":784,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1734\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[783],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":782,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1730\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[781],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":781,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1731\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[780],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":783,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1733\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[782],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":780,"Name":"FileScanRDD","Scope":"{\"id\":\"1731\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530413,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1735\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":173,"Stage Attempt ID":0,"Task Info":{"Task ID":173,"Index":0,"Attempt":0,"Launch Time":1629344530416,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":173,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":173,"Index":0,"Attempt":0,"Launch Time":1629344530416,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344530437,"Failed":false,"Killed":false,"Accumulables":[{"ID":5277,"Name":"number of output rows","Update":"1619","Value":"1619","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5281,"Name":"duration total (min, med, max)","Update":"14","Value":"13","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5304,"Name":"internal.metrics.input.recordsRead","Update":1619,"Value":1619,"Internal":true,"Count Failed Values":true},{"ID":5303,"Name":"internal.metrics.input.bytesRead","Update":104493,"Value":104493,"Internal":true,"Count Failed Values":true},{"ID":5288,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5286,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":5285,"Name":"internal.metrics.executorCpuTime","Update":14504000,"Value":14504000,"Internal":true,"Count Failed Values":true},{"ID":5284,"Name":"internal.metrics.executorRunTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":5283,"Name":"internal.metrics.executorDeserializeCpuTime","Update":2331000,"Value":2331000,"Internal":true,"Count Failed Values":true},{"ID":5282,"Name":"internal.metrics.executorDeserializeTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":3,"Executor Deserialize CPU Time":2331000,"Executor Run Time":16,"Executor CPU Time":14504000,"Result Size":1571,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":104493,"Records Read":1619},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":173,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":784,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1734\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[783],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":782,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1730\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[781],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":781,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1731\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[780],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":783,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1733\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[782],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":780,"Name":"FileScanRDD","Scope":"{\"id\":\"1731\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530413,"Completion Time":1629344530438,"Accumulables":[{"ID":5281,"Name":"duration total (min, med, max)","Value":"13","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5283,"Name":"internal.metrics.executorDeserializeCpuTime","Value":2331000,"Internal":true,"Count Failed Values":true},{"ID":5277,"Name":"number of output rows","Value":"1619","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5304,"Name":"internal.metrics.input.recordsRead","Value":1619,"Internal":true,"Count Failed Values":true},{"ID":5286,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true},{"ID":5303,"Name":"internal.metrics.input.bytesRead","Value":104493,"Internal":true,"Count Failed Values":true},{"ID":5285,"Name":"internal.metrics.executorCpuTime","Value":14504000,"Internal":true,"Count Failed Values":true},{"ID":5288,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5282,"Name":"internal.metrics.executorDeserializeTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":5284,"Name":"internal.metrics.executorRunTime","Value":16,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":173,"Completion Time":1629344530438,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":87,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3226, None)) > 0)\n      +- Project [value#3226]\n         +- Relation[value#3226] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3226, None)) > 0)\n      +- Project [value#3226]\n         +- Relation[value#3226] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3226, None)) > 0)\n      +- Relation[value#3226] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3226, None)) > 0)\n   +- *(1) FileScan text [value#3226] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/redvelvet.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3226, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3226] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/redvelvet.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/redvelvet.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5309,"metricType":"sum"},{"name":"number of files","accumulatorId":5310,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5311,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5312,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5308,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5307,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344530521}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":87,"accumUpdates":[[5310,1],[5311,0]]}
{"Event":"SparkListenerJobStart","Job ID":174,"Submission Time":1629344530546,"Stage Infos":[{"Stage ID":174,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":788,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1745\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[787],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":785,"Name":"FileScanRDD","Scope":"{\"id\":\"1741\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":786,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1741\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[785],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":787,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1744\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[786],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[174],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"87","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":174,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":788,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1745\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[787],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":785,"Name":"FileScanRDD","Scope":"{\"id\":\"1741\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":786,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1741\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[785],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":787,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1744\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[786],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530546,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"87","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":174,"Stage Attempt ID":0,"Task Info":{"Task ID":174,"Index":0,"Attempt":0,"Launch Time":1629344530548,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":174,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":174,"Index":0,"Attempt":0,"Launch Time":1629344530548,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344530554,"Failed":false,"Killed":false,"Accumulables":[{"ID":5308,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5309,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5335,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5334,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5317,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5316,"Name":"internal.metrics.executorCpuTime","Update":1531000,"Value":1531000,"Internal":true,"Count Failed Values":true},{"ID":5315,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":5314,"Name":"internal.metrics.executorDeserializeCpuTime","Update":719000,"Value":719000,"Internal":true,"Count Failed Values":true},{"ID":5313,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":719000,"Executor Run Time":3,"Executor CPU Time":1531000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":174,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":788,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1745\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[787],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":785,"Name":"FileScanRDD","Scope":"{\"id\":\"1741\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":786,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1741\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[785],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":787,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1744\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[786],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530546,"Completion Time":1629344530554,"Accumulables":[{"ID":5314,"Name":"internal.metrics.executorDeserializeCpuTime","Value":719000,"Internal":true,"Count Failed Values":true},{"ID":5334,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5316,"Name":"internal.metrics.executorCpuTime","Value":1531000,"Internal":true,"Count Failed Values":true},{"ID":5313,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5315,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":5309,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5308,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5335,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5317,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":174,"Completion Time":1629344530554,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":87,"time":1629344530555}
{"Event":"SparkListenerJobStart","Job ID":175,"Submission Time":1629344530585,"Stage Infos":[{"Stage ID":175,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":793,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1754\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[792],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":790,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1751\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[789],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":792,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1753\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[791],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":789,"Name":"FileScanRDD","Scope":"{\"id\":\"1751\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":791,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1750\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[790],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[175],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1755\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":175,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":793,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1754\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[792],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":790,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1751\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[789],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":792,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1753\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[791],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":789,"Name":"FileScanRDD","Scope":"{\"id\":\"1751\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":791,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1750\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[790],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530585,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1755\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":175,"Stage Attempt ID":0,"Task Info":{"Task ID":175,"Index":0,"Attempt":0,"Launch Time":1629344530587,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":175,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":175,"Index":0,"Attempt":0,"Launch Time":1629344530587,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344530636,"Failed":false,"Killed":false,"Accumulables":[{"ID":5338,"Name":"number of output rows","Update":"7719","Value":"7719","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5342,"Name":"duration total (min, med, max)","Update":"44","Value":"43","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5365,"Name":"internal.metrics.input.recordsRead","Update":7719,"Value":7719,"Internal":true,"Count Failed Values":true},{"ID":5364,"Name":"internal.metrics.input.bytesRead","Update":519003,"Value":519003,"Internal":true,"Count Failed Values":true},{"ID":5347,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5346,"Name":"internal.metrics.executorCpuTime","Update":45735000,"Value":45735000,"Internal":true,"Count Failed Values":true},{"ID":5345,"Name":"internal.metrics.executorRunTime","Update":46,"Value":46,"Internal":true,"Count Failed Values":true},{"ID":5344,"Name":"internal.metrics.executorDeserializeCpuTime","Update":991000,"Value":991000,"Internal":true,"Count Failed Values":true},{"ID":5343,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":991000,"Executor Run Time":46,"Executor CPU Time":45735000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":519003,"Records Read":7719},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":175,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":793,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1754\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[792],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":790,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1751\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[789],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":792,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1753\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[791],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":789,"Name":"FileScanRDD","Scope":"{\"id\":\"1751\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":791,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1750\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[790],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530585,"Completion Time":1629344530637,"Accumulables":[{"ID":5343,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5364,"Name":"internal.metrics.input.bytesRead","Value":519003,"Internal":true,"Count Failed Values":true},{"ID":5346,"Name":"internal.metrics.executorCpuTime","Value":45735000,"Internal":true,"Count Failed Values":true},{"ID":5345,"Name":"internal.metrics.executorRunTime","Value":46,"Internal":true,"Count Failed Values":true},{"ID":5342,"Name":"duration total (min, med, max)","Value":"43","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5344,"Name":"internal.metrics.executorDeserializeCpuTime","Value":991000,"Internal":true,"Count Failed Values":true},{"ID":5338,"Name":"number of output rows","Value":"7719","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5365,"Name":"internal.metrics.input.recordsRead","Value":7719,"Internal":true,"Count Failed Values":true},{"ID":5347,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":175,"Completion Time":1629344530637,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":88,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3263, None)) > 0)\n      +- Project [value#3263]\n         +- Relation[value#3263] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3263, None)) > 0)\n      +- Project [value#3263]\n         +- Relation[value#3263] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3263, None)) > 0)\n      +- Relation[value#3263] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3263, None)) > 0)\n   +- *(1) FileScan text [value#3263] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lgbt.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3263, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3263] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lgbt.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/lgbt.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5370,"metricType":"sum"},{"name":"number of files","accumulatorId":5371,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5372,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5373,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5369,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5368,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344530705}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":88,"accumUpdates":[[5371,1],[5372,0]]}
{"Event":"SparkListenerJobStart","Job ID":176,"Submission Time":1629344530726,"Stage Infos":[{"Stage ID":176,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":797,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1765\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[796],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":794,"Name":"FileScanRDD","Scope":"{\"id\":\"1761\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":796,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1764\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[795],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":795,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1761\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[794],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[176],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"88","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":176,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":797,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1765\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[796],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":794,"Name":"FileScanRDD","Scope":"{\"id\":\"1761\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":796,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1764\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[795],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":795,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1761\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[794],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530727,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"88","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":176,"Stage Attempt ID":0,"Task Info":{"Task ID":176,"Index":0,"Attempt":0,"Launch Time":1629344530731,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":176,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":176,"Index":0,"Attempt":0,"Launch Time":1629344530731,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344530737,"Failed":false,"Killed":false,"Accumulables":[{"ID":5369,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5370,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5396,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5395,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5378,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":5377,"Name":"internal.metrics.executorCpuTime","Update":1488000,"Value":1488000,"Internal":true,"Count Failed Values":true},{"ID":5376,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":5375,"Name":"internal.metrics.executorDeserializeCpuTime","Update":690000,"Value":690000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":690000,"Executor Run Time":4,"Executor CPU Time":1488000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":176,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":797,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1765\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[796],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":794,"Name":"FileScanRDD","Scope":"{\"id\":\"1761\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":796,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1764\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[795],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":795,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1761\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[794],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530727,"Completion Time":1629344530737,"Accumulables":[{"ID":5376,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":5370,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5396,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5375,"Name":"internal.metrics.executorDeserializeCpuTime","Value":690000,"Internal":true,"Count Failed Values":true},{"ID":5369,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5378,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":5395,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5377,"Name":"internal.metrics.executorCpuTime","Value":1488000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":176,"Completion Time":1629344530737,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":88,"time":1629344530737}
{"Event":"SparkListenerJobStart","Job ID":177,"Submission Time":1629344530764,"Stage Infos":[{"Stage ID":177,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":802,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1774\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[801],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":799,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1771\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[798],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":798,"Name":"FileScanRDD","Scope":"{\"id\":\"1771\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":801,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1773\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[800],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":800,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1770\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[799],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[177],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1775\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":177,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":802,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1774\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[801],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":799,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1771\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[798],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":798,"Name":"FileScanRDD","Scope":"{\"id\":\"1771\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":801,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1773\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[800],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":800,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1770\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[799],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530765,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1775\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":177,"Stage Attempt ID":0,"Task Info":{"Task ID":177,"Index":0,"Attempt":0,"Launch Time":1629344530769,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":177,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":177,"Index":0,"Attempt":0,"Launch Time":1629344530769,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344530813,"Failed":false,"Killed":false,"Accumulables":[{"ID":5399,"Name":"number of output rows","Update":"5131","Value":"5131","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5403,"Name":"duration total (min, med, max)","Update":"40","Value":"39","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5426,"Name":"internal.metrics.input.recordsRead","Update":5131,"Value":5131,"Internal":true,"Count Failed Values":true},{"ID":5425,"Name":"internal.metrics.input.bytesRead","Update":340490,"Value":340490,"Internal":true,"Count Failed Values":true},{"ID":5408,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5407,"Name":"internal.metrics.executorCpuTime","Update":38905000,"Value":38905000,"Internal":true,"Count Failed Values":true},{"ID":5406,"Name":"internal.metrics.executorRunTime","Update":42,"Value":42,"Internal":true,"Count Failed Values":true},{"ID":5405,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1135000,"Value":1135000,"Internal":true,"Count Failed Values":true},{"ID":5404,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1135000,"Executor Run Time":42,"Executor CPU Time":38905000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":340490,"Records Read":5131},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":177,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":802,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1774\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[801],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":799,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1771\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[798],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":798,"Name":"FileScanRDD","Scope":"{\"id\":\"1771\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":801,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1773\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[800],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":800,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1770\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[799],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530765,"Completion Time":1629344530814,"Accumulables":[{"ID":5403,"Name":"duration total (min, med, max)","Value":"39","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5406,"Name":"internal.metrics.executorRunTime","Value":42,"Internal":true,"Count Failed Values":true},{"ID":5405,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1135000,"Internal":true,"Count Failed Values":true},{"ID":5399,"Name":"number of output rows","Value":"5131","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5426,"Name":"internal.metrics.input.recordsRead","Value":5131,"Internal":true,"Count Failed Values":true},{"ID":5408,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5404,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5425,"Name":"internal.metrics.input.bytesRead","Value":340490,"Internal":true,"Count Failed Values":true},{"ID":5407,"Name":"internal.metrics.executorCpuTime","Value":38905000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":177,"Completion Time":1629344530814,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":89,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3300, None)) > 0)\n      +- Project [value#3300]\n         +- Relation[value#3300] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3300, None)) > 0)\n      +- Project [value#3300]\n         +- Relation[value#3300] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3300, None)) > 0)\n      +- Relation[value#3300] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3300, None)) > 0)\n   +- *(1) FileScan text [value#3300] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/shadowverse...., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3300, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3300] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/shadowverse...., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/shadowverse.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5431,"metricType":"sum"},{"name":"number of files","accumulatorId":5432,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5433,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5434,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5430,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5429,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344530877}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":89,"accumUpdates":[[5432,1],[5433,0]]}
{"Event":"SparkListenerJobStart","Job ID":178,"Submission Time":1629344530900,"Stage Infos":[{"Stage ID":178,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":806,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1785\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[805],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":804,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1781\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[803],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":805,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1784\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[804],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":803,"Name":"FileScanRDD","Scope":"{\"id\":\"1781\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[178],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"89","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":178,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":806,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1785\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[805],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":804,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1781\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[803],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":805,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1784\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[804],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":803,"Name":"FileScanRDD","Scope":"{\"id\":\"1781\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530900,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"89","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":178,"Stage Attempt ID":0,"Task Info":{"Task ID":178,"Index":0,"Attempt":0,"Launch Time":1629344530903,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":178,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":178,"Index":0,"Attempt":0,"Launch Time":1629344530903,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344530908,"Failed":false,"Killed":false,"Accumulables":[{"ID":5430,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5431,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5457,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5456,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5439,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":5438,"Name":"internal.metrics.executorCpuTime","Update":1455000,"Value":1455000,"Internal":true,"Count Failed Values":true},{"ID":5437,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":5436,"Name":"internal.metrics.executorDeserializeCpuTime","Update":778000,"Value":778000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":778000,"Executor Run Time":4,"Executor CPU Time":1455000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":178,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":806,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1785\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[805],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":804,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1781\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[803],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":805,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1784\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[804],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":803,"Name":"FileScanRDD","Scope":"{\"id\":\"1781\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530900,"Completion Time":1629344530909,"Accumulables":[{"ID":5436,"Name":"internal.metrics.executorDeserializeCpuTime","Value":778000,"Internal":true,"Count Failed Values":true},{"ID":5430,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5457,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5439,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":5456,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5438,"Name":"internal.metrics.executorCpuTime","Value":1455000,"Internal":true,"Count Failed Values":true},{"ID":5437,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":5431,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":178,"Completion Time":1629344530909,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":89,"time":1629344530909}
{"Event":"SparkListenerJobStart","Job ID":179,"Submission Time":1629344530936,"Stage Infos":[{"Stage ID":179,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":811,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1794\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[810],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":807,"Name":"FileScanRDD","Scope":"{\"id\":\"1791\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":810,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1793\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[809],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":808,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1791\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[807],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":809,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1790\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[808],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[179],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1795\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":179,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":811,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1794\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[810],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":807,"Name":"FileScanRDD","Scope":"{\"id\":\"1791\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":810,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1793\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[809],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":808,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1791\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[807],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":809,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1790\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[808],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530937,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1795\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":179,"Stage Attempt ID":0,"Task Info":{"Task ID":179,"Index":0,"Attempt":0,"Launch Time":1629344530940,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":179,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":179,"Index":0,"Attempt":0,"Launch Time":1629344530940,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344530959,"Failed":false,"Killed":false,"Accumulables":[{"ID":5460,"Name":"number of output rows","Update":"2188","Value":"2188","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5464,"Name":"duration total (min, med, max)","Update":"15","Value":"14","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5487,"Name":"internal.metrics.input.recordsRead","Update":2188,"Value":2188,"Internal":true,"Count Failed Values":true},{"ID":5486,"Name":"internal.metrics.input.bytesRead","Update":152666,"Value":152666,"Internal":true,"Count Failed Values":true},{"ID":5471,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5469,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":5468,"Name":"internal.metrics.executorCpuTime","Update":14281000,"Value":14281000,"Internal":true,"Count Failed Values":true},{"ID":5467,"Name":"internal.metrics.executorRunTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":5466,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1008000,"Value":1008000,"Internal":true,"Count Failed Values":true},{"ID":5465,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1008000,"Executor Run Time":17,"Executor CPU Time":14281000,"Result Size":1571,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":152666,"Records Read":2188},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":179,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":811,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1794\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[810],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":807,"Name":"FileScanRDD","Scope":"{\"id\":\"1791\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":810,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1793\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[809],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":808,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1791\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[807],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":809,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1790\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[808],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344530937,"Completion Time":1629344530959,"Accumulables":[{"ID":5460,"Name":"number of output rows","Value":"2188","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5487,"Name":"internal.metrics.input.recordsRead","Value":2188,"Internal":true,"Count Failed Values":true},{"ID":5469,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true},{"ID":5466,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1008000,"Internal":true,"Count Failed Values":true},{"ID":5465,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5486,"Name":"internal.metrics.input.bytesRead","Value":152666,"Internal":true,"Count Failed Values":true},{"ID":5468,"Name":"internal.metrics.executorCpuTime","Value":14281000,"Internal":true,"Count Failed Values":true},{"ID":5471,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5464,"Name":"duration total (min, med, max)","Value":"14","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5467,"Name":"internal.metrics.executorRunTime","Value":17,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":179,"Completion Time":1629344530959,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":90,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3337, None)) > 0)\n      +- Project [value#3337]\n         +- Relation[value#3337] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3337, None)) > 0)\n      +- Project [value#3337]\n         +- Relation[value#3337] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3337, None)) > 0)\n      +- Relation[value#3337] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3337, None)) > 0)\n   +- *(1) FileScan text [value#3337] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/majak.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3337, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3337] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/majak.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/majak.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5492,"metricType":"sum"},{"name":"number of files","accumulatorId":5493,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5494,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5495,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5491,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5490,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344531027}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":90,"accumUpdates":[[5493,1],[5494,0]]}
{"Event":"SparkListenerJobStart","Job ID":180,"Submission Time":1629344531048,"Stage Infos":[{"Stage ID":180,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":815,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1805\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[814],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":814,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1804\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[813],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":812,"Name":"FileScanRDD","Scope":"{\"id\":\"1801\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":813,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1801\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[812],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[180],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"90","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":180,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":815,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1805\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[814],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":814,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1804\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[813],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":812,"Name":"FileScanRDD","Scope":"{\"id\":\"1801\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":813,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1801\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[812],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344531048,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"90","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":180,"Stage Attempt ID":0,"Task Info":{"Task ID":180,"Index":0,"Attempt":0,"Launch Time":1629344531050,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":180,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":180,"Index":0,"Attempt":0,"Launch Time":1629344531050,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344531055,"Failed":false,"Killed":false,"Accumulables":[{"ID":5491,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5492,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5518,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5517,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5500,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5499,"Name":"internal.metrics.executorCpuTime","Update":1339000,"Value":1339000,"Internal":true,"Count Failed Values":true},{"ID":5498,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":5497,"Name":"internal.metrics.executorDeserializeCpuTime","Update":694000,"Value":694000,"Internal":true,"Count Failed Values":true},{"ID":5496,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":694000,"Executor Run Time":3,"Executor CPU Time":1339000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":180,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":815,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1805\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[814],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":814,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1804\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[813],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":812,"Name":"FileScanRDD","Scope":"{\"id\":\"1801\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":813,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1801\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[812],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344531048,"Completion Time":1629344531056,"Accumulables":[{"ID":5496,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5517,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5499,"Name":"internal.metrics.executorCpuTime","Value":1339000,"Internal":true,"Count Failed Values":true},{"ID":5492,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5498,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":5497,"Name":"internal.metrics.executorDeserializeCpuTime","Value":694000,"Internal":true,"Count Failed Values":true},{"ID":5491,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5518,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5500,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":180,"Completion Time":1629344531056,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":90,"time":1629344531056}
{"Event":"SparkListenerJobStart","Job ID":181,"Submission Time":1629344531090,"Stage Infos":[{"Stage ID":181,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":820,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1814\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[819],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":819,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1813\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[818],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":818,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1810\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[817],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":817,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1811\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[816],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":816,"Name":"FileScanRDD","Scope":"{\"id\":\"1811\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[181],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1815\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":181,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":820,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1814\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[819],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":819,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1813\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[818],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":818,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1810\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[817],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":817,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1811\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[816],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":816,"Name":"FileScanRDD","Scope":"{\"id\":\"1811\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344531090,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1815\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":181,"Stage Attempt ID":0,"Task Info":{"Task ID":181,"Index":0,"Attempt":0,"Launch Time":1629344531095,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":181,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":181,"Index":0,"Attempt":0,"Launch Time":1629344531095,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344531110,"Failed":false,"Killed":false,"Accumulables":[{"ID":5521,"Name":"number of output rows","Update":"1387","Value":"1387","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5525,"Name":"duration total (min, med, max)","Update":"11","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5548,"Name":"internal.metrics.input.recordsRead","Update":1387,"Value":1387,"Internal":true,"Count Failed Values":true},{"ID":5547,"Name":"internal.metrics.input.bytesRead","Update":83455,"Value":83455,"Internal":true,"Count Failed Values":true},{"ID":5530,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5529,"Name":"internal.metrics.executorCpuTime","Update":11032000,"Value":11032000,"Internal":true,"Count Failed Values":true},{"ID":5528,"Name":"internal.metrics.executorRunTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":5527,"Name":"internal.metrics.executorDeserializeCpuTime","Update":987000,"Value":987000,"Internal":true,"Count Failed Values":true},{"ID":5526,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":987000,"Executor Run Time":13,"Executor CPU Time":11032000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":83455,"Records Read":1387},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":181,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":820,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1814\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[819],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":819,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1813\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[818],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":818,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1810\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[817],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":817,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1811\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[816],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":816,"Name":"FileScanRDD","Scope":"{\"id\":\"1811\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344531090,"Completion Time":1629344531110,"Accumulables":[{"ID":5547,"Name":"internal.metrics.input.bytesRead","Value":83455,"Internal":true,"Count Failed Values":true},{"ID":5529,"Name":"internal.metrics.executorCpuTime","Value":11032000,"Internal":true,"Count Failed Values":true},{"ID":5526,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5525,"Name":"duration total (min, med, max)","Value":"10","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5528,"Name":"internal.metrics.executorRunTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":5548,"Name":"internal.metrics.input.recordsRead","Value":1387,"Internal":true,"Count Failed Values":true},{"ID":5527,"Name":"internal.metrics.executorDeserializeCpuTime","Value":987000,"Internal":true,"Count Failed Values":true},{"ID":5521,"Name":"number of output rows","Value":"1387","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5530,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":181,"Completion Time":1629344531110,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":91,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3374, None)) > 0)\n      +- Project [value#3374]\n         +- Relation[value#3374] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3374, None)) > 0)\n      +- Project [value#3374]\n         +- Relation[value#3374] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3374, None)) > 0)\n      +- Relation[value#3374] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3374, None)) > 0)\n   +- *(1) FileScan text [value#3374] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/depression_n..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3374, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3374] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/depression_n..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/depression_new1.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5553,"metricType":"sum"},{"name":"number of files","accumulatorId":5554,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5555,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5556,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5552,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5551,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344531177}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":91,"accumUpdates":[[5554,1],[5555,0]]}
{"Event":"SparkListenerJobStart","Job ID":182,"Submission Time":1629344531200,"Stage Infos":[{"Stage ID":182,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":824,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1825\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[823],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":822,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1821\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[821],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":821,"Name":"FileScanRDD","Scope":"{\"id\":\"1821\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":823,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1824\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[822],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[182],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"91","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":182,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":824,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1825\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[823],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":822,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1821\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[821],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":821,"Name":"FileScanRDD","Scope":"{\"id\":\"1821\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":823,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1824\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[822],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344531200,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"91","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":182,"Stage Attempt ID":0,"Task Info":{"Task ID":182,"Index":0,"Attempt":0,"Launch Time":1629344531203,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":182,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":182,"Index":0,"Attempt":0,"Launch Time":1629344531203,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344531208,"Failed":false,"Killed":false,"Accumulables":[{"ID":5552,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5553,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5579,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5578,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5561,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":5560,"Name":"internal.metrics.executorCpuTime","Update":1466000,"Value":1466000,"Internal":true,"Count Failed Values":true},{"ID":5559,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":5558,"Name":"internal.metrics.executorDeserializeCpuTime","Update":674000,"Value":674000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":674000,"Executor Run Time":4,"Executor CPU Time":1466000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":182,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":824,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1825\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[823],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":822,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1821\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[821],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":821,"Name":"FileScanRDD","Scope":"{\"id\":\"1821\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":823,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1824\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[822],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344531200,"Completion Time":1629344531208,"Accumulables":[{"ID":5559,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":5553,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5552,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5579,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5561,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":5558,"Name":"internal.metrics.executorDeserializeCpuTime","Value":674000,"Internal":true,"Count Failed Values":true},{"ID":5578,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5560,"Name":"internal.metrics.executorCpuTime","Value":1466000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":182,"Completion Time":1629344531208,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":91,"time":1629344531209}
{"Event":"SparkListenerJobStart","Job ID":183,"Submission Time":1629344531238,"Stage Infos":[{"Stage ID":183,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":829,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1834\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[828],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":827,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1830\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[826],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":826,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1831\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[825],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":828,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1833\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[827],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":825,"Name":"FileScanRDD","Scope":"{\"id\":\"1831\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[183],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1835\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":183,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":829,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1834\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[828],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":827,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1830\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[826],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":826,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1831\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[825],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":828,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1833\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[827],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":825,"Name":"FileScanRDD","Scope":"{\"id\":\"1831\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344531238,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1835\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":183,"Stage Attempt ID":0,"Task Info":{"Task ID":183,"Index":0,"Attempt":0,"Launch Time":1629344531242,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":183,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":183,"Index":0,"Attempt":0,"Launch Time":1629344531242,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344531353,"Failed":false,"Killed":false,"Accumulables":[{"ID":5582,"Name":"number of output rows","Update":"16359","Value":"16359","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5586,"Name":"duration total (min, med, max)","Update":"105","Value":"104","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5609,"Name":"internal.metrics.input.recordsRead","Update":16359,"Value":16359,"Internal":true,"Count Failed Values":true},{"ID":5608,"Name":"internal.metrics.input.bytesRead","Update":1054061,"Value":1054061,"Internal":true,"Count Failed Values":true},{"ID":5591,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5590,"Name":"internal.metrics.executorCpuTime","Update":104695000,"Value":104695000,"Internal":true,"Count Failed Values":true},{"ID":5589,"Name":"internal.metrics.executorRunTime","Update":107,"Value":107,"Internal":true,"Count Failed Values":true},{"ID":5588,"Name":"internal.metrics.executorDeserializeCpuTime","Update":941000,"Value":941000,"Internal":true,"Count Failed Values":true},{"ID":5587,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":941000,"Executor Run Time":107,"Executor CPU Time":104695000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1054061,"Records Read":16359},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":183,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":829,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1834\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[828],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":827,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1830\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[826],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":826,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1831\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[825],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":828,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1833\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[827],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":825,"Name":"FileScanRDD","Scope":"{\"id\":\"1831\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344531238,"Completion Time":1629344531353,"Accumulables":[{"ID":5586,"Name":"duration total (min, med, max)","Value":"104","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5588,"Name":"internal.metrics.executorDeserializeCpuTime","Value":941000,"Internal":true,"Count Failed Values":true},{"ID":5582,"Name":"number of output rows","Value":"16359","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5609,"Name":"internal.metrics.input.recordsRead","Value":16359,"Internal":true,"Count Failed Values":true},{"ID":5591,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5608,"Name":"internal.metrics.input.bytesRead","Value":1054061,"Internal":true,"Count Failed Values":true},{"ID":5587,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5590,"Name":"internal.metrics.executorCpuTime","Value":104695000,"Internal":true,"Count Failed Values":true},{"ID":5589,"Name":"internal.metrics.executorRunTime","Value":107,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":183,"Completion Time":1629344531354,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":92,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3411, None)) > 0)\n      +- Project [value#3411]\n         +- Relation[value#3411] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3411, None)) > 0)\n      +- Project [value#3411]\n         +- Relation[value#3411] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3411, None)) > 0)\n      +- Relation[value#3411] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3411, None)) > 0)\n   +- *(1) FileScan text [value#3411] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/comic_new2.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3411, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3411] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/comic_new2.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/comic_new2.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5614,"metricType":"sum"},{"name":"number of files","accumulatorId":5615,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5616,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5617,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5613,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5612,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344531433}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":92,"accumUpdates":[[5615,1],[5616,0]]}
{"Event":"SparkListenerJobStart","Job ID":184,"Submission Time":1629344531461,"Stage Infos":[{"Stage ID":184,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":833,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1845\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[832],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":830,"Name":"FileScanRDD","Scope":"{\"id\":\"1841\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":831,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1841\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[830],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":832,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1844\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[831],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[184],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"92","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":184,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":833,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1845\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[832],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":830,"Name":"FileScanRDD","Scope":"{\"id\":\"1841\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":831,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1841\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[830],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":832,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1844\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[831],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344531461,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"92","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":184,"Stage Attempt ID":0,"Task Info":{"Task ID":184,"Index":0,"Attempt":0,"Launch Time":1629344531464,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":184,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":184,"Index":0,"Attempt":0,"Launch Time":1629344531464,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344531470,"Failed":false,"Killed":false,"Accumulables":[{"ID":5613,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5614,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5640,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5639,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5622,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5621,"Name":"internal.metrics.executorCpuTime","Update":2101000,"Value":2101000,"Internal":true,"Count Failed Values":true},{"ID":5620,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":5619,"Name":"internal.metrics.executorDeserializeCpuTime","Update":733000,"Value":733000,"Internal":true,"Count Failed Values":true},{"ID":5618,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":733000,"Executor Run Time":4,"Executor CPU Time":2101000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":184,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":833,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1845\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[832],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":830,"Name":"FileScanRDD","Scope":"{\"id\":\"1841\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":831,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1841\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[830],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":832,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1844\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[831],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344531461,"Completion Time":1629344531471,"Accumulables":[{"ID":5619,"Name":"internal.metrics.executorDeserializeCpuTime","Value":733000,"Internal":true,"Count Failed Values":true},{"ID":5613,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5639,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5621,"Name":"internal.metrics.executorCpuTime","Value":2101000,"Internal":true,"Count Failed Values":true},{"ID":5618,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5620,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":5614,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5640,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5622,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":184,"Completion Time":1629344531471,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":92,"time":1629344531471}
{"Event":"SparkListenerJobStart","Job ID":185,"Submission Time":1629344531503,"Stage Infos":[{"Stage ID":185,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":838,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1854\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[837],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":836,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1850\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[835],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":835,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1851\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[834],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":837,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1853\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[836],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":834,"Name":"FileScanRDD","Scope":"{\"id\":\"1851\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[185],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1855\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":185,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":838,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1854\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[837],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":836,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1850\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[835],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":835,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1851\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[834],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":837,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1853\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[836],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":834,"Name":"FileScanRDD","Scope":"{\"id\":\"1851\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344531504,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1855\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":185,"Stage Attempt ID":0,"Task Info":{"Task ID":185,"Index":0,"Attempt":0,"Launch Time":1629344531507,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":185,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":185,"Index":0,"Attempt":0,"Launch Time":1629344531507,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344531844,"Failed":false,"Killed":false,"Accumulables":[{"ID":5643,"Name":"number of output rows","Update":"46693","Value":"46693","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5647,"Name":"duration total (min, med, max)","Update":"332","Value":"331","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5670,"Name":"internal.metrics.input.recordsRead","Update":46693,"Value":46693,"Internal":true,"Count Failed Values":true},{"ID":5669,"Name":"internal.metrics.input.bytesRead","Update":3381812,"Value":3381812,"Internal":true,"Count Failed Values":true},{"ID":5653,"Name":"internal.metrics.jvmGCTime","Update":18,"Value":18,"Internal":true,"Count Failed Values":true},{"ID":5652,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":5651,"Name":"internal.metrics.executorCpuTime","Update":303820000,"Value":303820000,"Internal":true,"Count Failed Values":true},{"ID":5650,"Name":"internal.metrics.executorRunTime","Update":333,"Value":333,"Internal":true,"Count Failed Values":true},{"ID":5649,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1063000,"Value":1063000,"Internal":true,"Count Failed Values":true},{"ID":5648,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1063000,"Executor Run Time":333,"Executor CPU Time":303820000,"Result Size":1571,"JVM GC Time":18,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":3381812,"Records Read":46693},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":185,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":838,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1854\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[837],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":836,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1850\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[835],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":835,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1851\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[834],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":837,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1853\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[836],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":834,"Name":"FileScanRDD","Scope":"{\"id\":\"1851\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344531504,"Completion Time":1629344531844,"Accumulables":[{"ID":5648,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5669,"Name":"internal.metrics.input.bytesRead","Value":3381812,"Internal":true,"Count Failed Values":true},{"ID":5651,"Name":"internal.metrics.executorCpuTime","Value":303820000,"Internal":true,"Count Failed Values":true},{"ID":5653,"Name":"internal.metrics.jvmGCTime","Value":18,"Internal":true,"Count Failed Values":true},{"ID":5647,"Name":"duration total (min, med, max)","Value":"331","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5650,"Name":"internal.metrics.executorRunTime","Value":333,"Internal":true,"Count Failed Values":true},{"ID":5649,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1063000,"Internal":true,"Count Failed Values":true},{"ID":5643,"Name":"number of output rows","Value":"46693","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5670,"Name":"internal.metrics.input.recordsRead","Value":46693,"Internal":true,"Count Failed Values":true},{"ID":5652,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":185,"Completion Time":1629344531844,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":93,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3448, None)) > 0)\n      +- Project [value#3448]\n         +- Relation[value#3448] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3448, None)) > 0)\n      +- Project [value#3448]\n         +- Relation[value#3448] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3448, None)) > 0)\n      +- Relation[value#3448] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3448, None)) > 0)\n   +- *(1) FileScan text [value#3448] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/idolmaster.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3448, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3448] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/idolmaster.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/idolmaster.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5675,"metricType":"sum"},{"name":"number of files","accumulatorId":5676,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5677,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5678,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5674,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5673,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344531925}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":93,"accumUpdates":[[5676,1],[5677,0]]}
{"Event":"SparkListenerJobStart","Job ID":186,"Submission Time":1629344531956,"Stage Infos":[{"Stage ID":186,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":842,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1865\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[841],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":841,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1864\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[840],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":839,"Name":"FileScanRDD","Scope":"{\"id\":\"1861\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":840,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1861\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[839],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[186],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"93","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":186,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":842,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1865\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[841],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":841,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1864\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[840],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":839,"Name":"FileScanRDD","Scope":"{\"id\":\"1861\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":840,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1861\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[839],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344531957,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"93","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":186,"Stage Attempt ID":0,"Task Info":{"Task ID":186,"Index":0,"Attempt":0,"Launch Time":1629344531960,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":186,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":186,"Index":0,"Attempt":0,"Launch Time":1629344531960,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344531975,"Failed":false,"Killed":false,"Accumulables":[{"ID":5674,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5675,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5701,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5700,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5683,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5682,"Name":"internal.metrics.executorCpuTime","Update":2780000,"Value":2780000,"Internal":true,"Count Failed Values":true},{"ID":5681,"Name":"internal.metrics.executorRunTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true},{"ID":5680,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1772000,"Value":1772000,"Internal":true,"Count Failed Values":true},{"ID":5679,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1772000,"Executor Run Time":5,"Executor CPU Time":2780000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":186,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":842,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1865\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[841],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":841,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1864\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[840],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":839,"Name":"FileScanRDD","Scope":"{\"id\":\"1861\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":840,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1861\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[839],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344531957,"Completion Time":1629344531976,"Accumulables":[{"ID":5681,"Name":"internal.metrics.executorRunTime","Value":5,"Internal":true,"Count Failed Values":true},{"ID":5675,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5680,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1772000,"Internal":true,"Count Failed Values":true},{"ID":5674,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5701,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5683,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5700,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5682,"Name":"internal.metrics.executorCpuTime","Value":2780000,"Internal":true,"Count Failed Values":true},{"ID":5679,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":186,"Completion Time":1629344531976,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":93,"time":1629344531977}
{"Event":"SparkListenerJobStart","Job ID":187,"Submission Time":1629344532024,"Stage Infos":[{"Stage ID":187,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":847,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1874\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[846],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":846,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1873\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[845],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":844,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1871\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[843],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":843,"Name":"FileScanRDD","Scope":"{\"id\":\"1871\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":845,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1870\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[844],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[187],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1875\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":187,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":847,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1874\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[846],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":846,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1873\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[845],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":844,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1871\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[843],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":843,"Name":"FileScanRDD","Scope":"{\"id\":\"1871\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":845,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1870\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[844],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532025,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1875\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":187,"Stage Attempt ID":0,"Task Info":{"Task ID":187,"Index":0,"Attempt":0,"Launch Time":1629344532030,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":187,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":187,"Index":0,"Attempt":0,"Launch Time":1629344532030,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344532198,"Failed":false,"Killed":false,"Accumulables":[{"ID":5704,"Name":"number of output rows","Update":"22060","Value":"22060","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5708,"Name":"duration total (min, med, max)","Update":"163","Value":"162","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5731,"Name":"internal.metrics.input.recordsRead","Update":22060,"Value":22060,"Internal":true,"Count Failed Values":true},{"ID":5730,"Name":"internal.metrics.input.bytesRead","Update":1573867,"Value":1573867,"Internal":true,"Count Failed Values":true},{"ID":5713,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5712,"Name":"internal.metrics.executorCpuTime","Update":159542000,"Value":159542000,"Internal":true,"Count Failed Values":true},{"ID":5711,"Name":"internal.metrics.executorRunTime","Update":165,"Value":165,"Internal":true,"Count Failed Values":true},{"ID":5710,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1487000,"Value":1487000,"Internal":true,"Count Failed Values":true},{"ID":5709,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1487000,"Executor Run Time":165,"Executor CPU Time":159542000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1573867,"Records Read":22060},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":187,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":847,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1874\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[846],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":846,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1873\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[845],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":844,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1871\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[843],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":843,"Name":"FileScanRDD","Scope":"{\"id\":\"1871\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":845,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1870\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[844],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532025,"Completion Time":1629344532199,"Accumulables":[{"ID":5708,"Name":"duration total (min, med, max)","Value":"162","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5711,"Name":"internal.metrics.executorRunTime","Value":165,"Internal":true,"Count Failed Values":true},{"ID":5704,"Name":"number of output rows","Value":"22060","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5731,"Name":"internal.metrics.input.recordsRead","Value":22060,"Internal":true,"Count Failed Values":true},{"ID":5713,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5710,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1487000,"Internal":true,"Count Failed Values":true},{"ID":5709,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":5730,"Name":"internal.metrics.input.bytesRead","Value":1573867,"Internal":true,"Count Failed Values":true},{"ID":5712,"Name":"internal.metrics.executorCpuTime","Value":159542000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":187,"Completion Time":1629344532199,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":94,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3485, None)) > 0)\n      +- Project [value#3485]\n         +- Relation[value#3485] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3485, None)) > 0)\n      +- Project [value#3485]\n         +- Relation[value#3485] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3485, None)) > 0)\n      +- Relation[value#3485] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3485, None)) > 0)\n   +- *(1) FileScan text [value#3485] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/fifaonline.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3485, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3485] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/fifaonline.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/fifaonline.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5736,"metricType":"sum"},{"name":"number of files","accumulatorId":5737,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5738,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5739,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5735,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5734,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344532264}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":94,"accumUpdates":[[5737,1],[5738,0]]}
{"Event":"SparkListenerJobStart","Job ID":188,"Submission Time":1629344532285,"Stage Infos":[{"Stage ID":188,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":851,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1885\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[850],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":850,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1884\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[849],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":849,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1881\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[848],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":848,"Name":"FileScanRDD","Scope":"{\"id\":\"1881\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[188],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"94","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":188,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":851,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1885\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[850],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":850,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1884\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[849],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":849,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1881\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[848],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":848,"Name":"FileScanRDD","Scope":"{\"id\":\"1881\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532285,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"94","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":188,"Stage Attempt ID":0,"Task Info":{"Task ID":188,"Index":0,"Attempt":0,"Launch Time":1629344532290,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":188,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":188,"Index":0,"Attempt":0,"Launch Time":1629344532290,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344532293,"Failed":false,"Killed":false,"Accumulables":[{"ID":5735,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5736,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5762,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5761,"Name":"internal.metrics.input.bytesRead","Update":4910,"Value":4910,"Internal":true,"Count Failed Values":true},{"ID":5744,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5743,"Name":"internal.metrics.executorCpuTime","Update":1456000,"Value":1456000,"Internal":true,"Count Failed Values":true},{"ID":5742,"Name":"internal.metrics.executorRunTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5741,"Name":"internal.metrics.executorDeserializeCpuTime","Update":700000,"Value":700000,"Internal":true,"Count Failed Values":true},{"ID":5740,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":700000,"Executor Run Time":1,"Executor CPU Time":1456000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":4910,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":188,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":851,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1885\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[850],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":850,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1884\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[849],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":849,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1881\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[848],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":848,"Name":"FileScanRDD","Scope":"{\"id\":\"1881\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532285,"Completion Time":1629344532294,"Accumulables":[{"ID":5741,"Name":"internal.metrics.executorDeserializeCpuTime","Value":700000,"Internal":true,"Count Failed Values":true},{"ID":5735,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5762,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5744,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5740,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5761,"Name":"internal.metrics.input.bytesRead","Value":4910,"Internal":true,"Count Failed Values":true},{"ID":5743,"Name":"internal.metrics.executorCpuTime","Value":1456000,"Internal":true,"Count Failed Values":true},{"ID":5742,"Name":"internal.metrics.executorRunTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5736,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"}]}}
{"Event":"SparkListenerJobEnd","Job ID":188,"Completion Time":1629344532294,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":94,"time":1629344532294}
{"Event":"SparkListenerJobStart","Job ID":189,"Submission Time":1629344532323,"Stage Infos":[{"Stage ID":189,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":856,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1894\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[855],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":853,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1891\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[852],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":855,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1893\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[854],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":854,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1890\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[853],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":852,"Name":"FileScanRDD","Scope":"{\"id\":\"1891\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[189],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1895\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":189,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":856,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1894\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[855],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":853,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1891\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[852],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":855,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1893\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[854],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":854,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1890\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[853],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":852,"Name":"FileScanRDD","Scope":"{\"id\":\"1891\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532323,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1895\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":189,"Stage Attempt ID":0,"Task Info":{"Task ID":189,"Index":0,"Attempt":0,"Launch Time":1629344532326,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":189,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":189,"Index":0,"Attempt":0,"Launch Time":1629344532326,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344532330,"Failed":false,"Killed":false,"Accumulables":[{"ID":5765,"Name":"number of output rows","Update":"76","Value":"76","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5769,"Name":"duration total (min, med, max)","Update":"0","Value":"-1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5792,"Name":"internal.metrics.input.recordsRead","Update":76,"Value":76,"Internal":true,"Count Failed Values":true},{"ID":5791,"Name":"internal.metrics.input.bytesRead","Update":4910,"Value":4910,"Internal":true,"Count Failed Values":true},{"ID":5776,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5774,"Name":"internal.metrics.resultSize","Update":1571,"Value":1571,"Internal":true,"Count Failed Values":true},{"ID":5773,"Name":"internal.metrics.executorCpuTime","Update":2085000,"Value":2085000,"Internal":true,"Count Failed Values":true},{"ID":5772,"Name":"internal.metrics.executorRunTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true},{"ID":5771,"Name":"internal.metrics.executorDeserializeCpuTime","Update":957000,"Value":957000,"Internal":true,"Count Failed Values":true},{"ID":5770,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":957000,"Executor Run Time":2,"Executor CPU Time":2085000,"Result Size":1571,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":4910,"Records Read":76},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":189,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":856,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1894\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[855],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":853,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1891\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[852],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":855,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1893\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[854],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":854,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1890\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[853],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":852,"Name":"FileScanRDD","Scope":"{\"id\":\"1891\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532323,"Completion Time":1629344532330,"Accumulables":[{"ID":5765,"Name":"number of output rows","Value":"76","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5792,"Name":"internal.metrics.input.recordsRead","Value":76,"Internal":true,"Count Failed Values":true},{"ID":5774,"Name":"internal.metrics.resultSize","Value":1571,"Internal":true,"Count Failed Values":true},{"ID":5771,"Name":"internal.metrics.executorDeserializeCpuTime","Value":957000,"Internal":true,"Count Failed Values":true},{"ID":5791,"Name":"internal.metrics.input.bytesRead","Value":4910,"Internal":true,"Count Failed Values":true},{"ID":5773,"Name":"internal.metrics.executorCpuTime","Value":2085000,"Internal":true,"Count Failed Values":true},{"ID":5776,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5770,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5769,"Name":"duration total (min, med, max)","Value":"-1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5772,"Name":"internal.metrics.executorRunTime","Value":2,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":189,"Completion Time":1629344532330,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":95,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3522, None)) > 0)\n      +- Project [value#3522]\n         +- Relation[value#3522] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3522, None)) > 0)\n      +- Project [value#3522]\n         +- Relation[value#3522] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3522, None)) > 0)\n      +- Relation[value#3522] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3522, None)) > 0)\n   +- *(1) FileScan text [value#3522] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/elsword.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3522, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3522] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/elsword.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/elsword.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5797,"metricType":"sum"},{"name":"number of files","accumulatorId":5798,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5799,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5800,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5796,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5795,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344532403}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":95,"accumUpdates":[[5798,1],[5799,0]]}
{"Event":"SparkListenerJobStart","Job ID":190,"Submission Time":1629344532431,"Stage Infos":[{"Stage ID":190,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":860,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1905\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[859],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":859,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1904\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[858],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":858,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1901\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[857],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":857,"Name":"FileScanRDD","Scope":"{\"id\":\"1901\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[190],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"95","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":190,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":860,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1905\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[859],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":859,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1904\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[858],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":858,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1901\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[857],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":857,"Name":"FileScanRDD","Scope":"{\"id\":\"1901\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532431,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"95","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":190,"Stage Attempt ID":0,"Task Info":{"Task ID":190,"Index":0,"Attempt":0,"Launch Time":1629344532436,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":190,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":190,"Index":0,"Attempt":0,"Launch Time":1629344532436,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344532441,"Failed":false,"Killed":false,"Accumulables":[{"ID":5796,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5797,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5823,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5822,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5805,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5804,"Name":"internal.metrics.executorCpuTime","Update":1758000,"Value":1758000,"Internal":true,"Count Failed Values":true},{"ID":5803,"Name":"internal.metrics.executorRunTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5802,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1231000,"Value":1231000,"Internal":true,"Count Failed Values":true},{"ID":5801,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1231000,"Executor Run Time":1,"Executor CPU Time":1758000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":190,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":860,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1905\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[859],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":859,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1904\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[858],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":858,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1901\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[857],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":857,"Name":"FileScanRDD","Scope":"{\"id\":\"1901\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532431,"Completion Time":1629344532442,"Accumulables":[{"ID":5801,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":5822,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5804,"Name":"internal.metrics.executorCpuTime","Value":1758000,"Internal":true,"Count Failed Values":true},{"ID":5797,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5803,"Name":"internal.metrics.executorRunTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5802,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1231000,"Internal":true,"Count Failed Values":true},{"ID":5796,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5823,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5805,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":190,"Completion Time":1629344532442,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":95,"time":1629344532442}
{"Event":"SparkListenerJobStart","Job ID":191,"Submission Time":1629344532469,"Stage Infos":[{"Stage ID":191,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":865,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1914\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[864],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":864,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1913\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[863],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":861,"Name":"FileScanRDD","Scope":"{\"id\":\"1911\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":862,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1911\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[861],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":863,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1910\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[862],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[191],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1915\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":191,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":865,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1914\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[864],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":864,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1913\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[863],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":861,"Name":"FileScanRDD","Scope":"{\"id\":\"1911\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":862,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1911\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[861],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":863,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1910\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[862],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532469,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1915\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":191,"Stage Attempt ID":0,"Task Info":{"Task ID":191,"Index":0,"Attempt":0,"Launch Time":1629344532471,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":191,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":191,"Index":0,"Attempt":0,"Launch Time":1629344532471,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344532547,"Failed":false,"Killed":false,"Accumulables":[{"ID":5826,"Name":"number of output rows","Update":"12311","Value":"12311","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5830,"Name":"duration total (min, med, max)","Update":"71","Value":"70","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5853,"Name":"internal.metrics.input.recordsRead","Update":12311,"Value":12311,"Internal":true,"Count Failed Values":true},{"ID":5852,"Name":"internal.metrics.input.bytesRead","Update":865385,"Value":865385,"Internal":true,"Count Failed Values":true},{"ID":5835,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5834,"Name":"internal.metrics.executorCpuTime","Update":72493000,"Value":72493000,"Internal":true,"Count Failed Values":true},{"ID":5833,"Name":"internal.metrics.executorRunTime","Update":72,"Value":72,"Internal":true,"Count Failed Values":true},{"ID":5832,"Name":"internal.metrics.executorDeserializeCpuTime","Update":871000,"Value":871000,"Internal":true,"Count Failed Values":true},{"ID":5831,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":871000,"Executor Run Time":72,"Executor CPU Time":72493000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":865385,"Records Read":12311},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":191,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":865,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1914\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[864],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":864,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1913\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[863],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":861,"Name":"FileScanRDD","Scope":"{\"id\":\"1911\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":862,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1911\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[861],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":863,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1910\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[862],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532469,"Completion Time":1629344532547,"Accumulables":[{"ID":5852,"Name":"internal.metrics.input.bytesRead","Value":865385,"Internal":true,"Count Failed Values":true},{"ID":5834,"Name":"internal.metrics.executorCpuTime","Value":72493000,"Internal":true,"Count Failed Values":true},{"ID":5831,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5833,"Name":"internal.metrics.executorRunTime","Value":72,"Internal":true,"Count Failed Values":true},{"ID":5830,"Name":"duration total (min, med, max)","Value":"70","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5832,"Name":"internal.metrics.executorDeserializeCpuTime","Value":871000,"Internal":true,"Count Failed Values":true},{"ID":5826,"Name":"number of output rows","Value":"12311","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5853,"Name":"internal.metrics.input.recordsRead","Value":12311,"Internal":true,"Count Failed Values":true},{"ID":5835,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":191,"Completion Time":1629344532547,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":96,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3559, None)) > 0)\n      +- Project [value#3559]\n         +- Relation[value#3559] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3559, None)) > 0)\n      +- Project [value#3559]\n         +- Relation[value#3559] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3559, None)) > 0)\n      +- Relation[value#3559] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3559, None)) > 0)\n   +- *(1) FileScan text [value#3559] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ncdinos.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3559, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3559] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ncdinos.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/ncdinos.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5858,"metricType":"sum"},{"name":"number of files","accumulatorId":5859,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5860,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5861,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5857,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5856,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344532622}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":96,"accumUpdates":[[5859,1],[5860,0]]}
{"Event":"SparkListenerJobStart","Job ID":192,"Submission Time":1629344532644,"Stage Infos":[{"Stage ID":192,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":869,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1925\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[868],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":867,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1921\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[866],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":866,"Name":"FileScanRDD","Scope":"{\"id\":\"1921\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":868,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1924\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[867],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[192],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"96","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":192,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":869,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1925\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[868],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":867,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1921\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[866],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":866,"Name":"FileScanRDD","Scope":"{\"id\":\"1921\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":868,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1924\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[867],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532644,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"96","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":192,"Stage Attempt ID":0,"Task Info":{"Task ID":192,"Index":0,"Attempt":0,"Launch Time":1629344532647,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":192,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":192,"Index":0,"Attempt":0,"Launch Time":1629344532647,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344532652,"Failed":false,"Killed":false,"Accumulables":[{"ID":5857,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5858,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5884,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5883,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5866,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":5865,"Name":"internal.metrics.executorCpuTime","Update":1430000,"Value":1430000,"Internal":true,"Count Failed Values":true},{"ID":5864,"Name":"internal.metrics.executorRunTime","Update":4,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":5863,"Name":"internal.metrics.executorDeserializeCpuTime","Update":676000,"Value":676000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":676000,"Executor Run Time":4,"Executor CPU Time":1430000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":192,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":869,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1925\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[868],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":867,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1921\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[866],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":866,"Name":"FileScanRDD","Scope":"{\"id\":\"1921\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":868,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1924\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[867],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532644,"Completion Time":1629344532652,"Accumulables":[{"ID":5864,"Name":"internal.metrics.executorRunTime","Value":4,"Internal":true,"Count Failed Values":true},{"ID":5858,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5857,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5884,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5866,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":5863,"Name":"internal.metrics.executorDeserializeCpuTime","Value":676000,"Internal":true,"Count Failed Values":true},{"ID":5883,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5865,"Name":"internal.metrics.executorCpuTime","Value":1430000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":192,"Completion Time":1629344532652,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":96,"time":1629344532653}
{"Event":"SparkListenerJobStart","Job ID":193,"Submission Time":1629344532680,"Stage Infos":[{"Stage ID":193,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":874,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1934\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[873],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":873,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1933\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[872],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":870,"Name":"FileScanRDD","Scope":"{\"id\":\"1931\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":871,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1931\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[870],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":872,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1930\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[871],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[193],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1935\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":193,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":874,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1934\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[873],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":873,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1933\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[872],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":870,"Name":"FileScanRDD","Scope":"{\"id\":\"1931\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":871,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1931\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[870],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":872,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1930\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[871],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532680,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1935\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":193,"Stage Attempt ID":0,"Task Info":{"Task ID":193,"Index":0,"Attempt":0,"Launch Time":1629344532683,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":193,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":193,"Index":0,"Attempt":0,"Launch Time":1629344532683,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344532707,"Failed":false,"Killed":false,"Accumulables":[{"ID":5887,"Name":"number of output rows","Update":"2914","Value":"2914","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5891,"Name":"duration total (min, med, max)","Update":"19","Value":"18","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5914,"Name":"internal.metrics.input.recordsRead","Update":2914,"Value":2914,"Internal":true,"Count Failed Values":true},{"ID":5913,"Name":"internal.metrics.input.bytesRead","Update":193138,"Value":193138,"Internal":true,"Count Failed Values":true},{"ID":5896,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5895,"Name":"internal.metrics.executorCpuTime","Update":19033000,"Value":19033000,"Internal":true,"Count Failed Values":true},{"ID":5894,"Name":"internal.metrics.executorRunTime","Update":21,"Value":21,"Internal":true,"Count Failed Values":true},{"ID":5893,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1231000,"Value":1231000,"Internal":true,"Count Failed Values":true},{"ID":5892,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1231000,"Executor Run Time":21,"Executor CPU Time":19033000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":193138,"Records Read":2914},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":193,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":874,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1934\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[873],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":873,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1933\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[872],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":870,"Name":"FileScanRDD","Scope":"{\"id\":\"1931\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":871,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1931\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[870],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":872,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1930\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[871],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532680,"Completion Time":1629344532707,"Accumulables":[{"ID":5891,"Name":"duration total (min, med, max)","Value":"18","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5893,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1231000,"Internal":true,"Count Failed Values":true},{"ID":5887,"Name":"number of output rows","Value":"2914","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5914,"Name":"internal.metrics.input.recordsRead","Value":2914,"Internal":true,"Count Failed Values":true},{"ID":5896,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5913,"Name":"internal.metrics.input.bytesRead","Value":193138,"Internal":true,"Count Failed Values":true},{"ID":5892,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5895,"Name":"internal.metrics.executorCpuTime","Value":19033000,"Internal":true,"Count Failed Values":true},{"ID":5894,"Name":"internal.metrics.executorRunTime","Value":21,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":193,"Completion Time":1629344532707,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":97,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3596, None)) > 0)\n      +- Project [value#3596]\n         +- Relation[value#3596] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3596, None)) > 0)\n      +- Project [value#3596]\n         +- Relation[value#3596] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3596, None)) > 0)\n      +- Relation[value#3596] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3596, None)) > 0)\n   +- *(1) FileScan text [value#3596] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/baseball_new..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3596, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3596] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/baseball_new..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/baseball_new10.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5919,"metricType":"sum"},{"name":"number of files","accumulatorId":5920,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5921,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5922,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5918,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5917,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344532775}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":97,"accumUpdates":[[5920,1],[5921,0]]}
{"Event":"SparkListenerJobStart","Job ID":194,"Submission Time":1629344532798,"Stage Infos":[{"Stage ID":194,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":878,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1945\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[877],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":876,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1941\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[875],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":875,"Name":"FileScanRDD","Scope":"{\"id\":\"1941\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":877,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1944\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[876],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[194],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"97","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":194,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":878,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1945\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[877],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":876,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1941\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[875],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":875,"Name":"FileScanRDD","Scope":"{\"id\":\"1941\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":877,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1944\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[876],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532798,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"97","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":194,"Stage Attempt ID":0,"Task Info":{"Task ID":194,"Index":0,"Attempt":0,"Launch Time":1629344532803,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":194,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":194,"Index":0,"Attempt":0,"Launch Time":1629344532803,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344532810,"Failed":false,"Killed":false,"Accumulables":[{"ID":5918,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5919,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5945,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":5944,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5927,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5926,"Name":"internal.metrics.executorCpuTime","Update":1802000,"Value":1802000,"Internal":true,"Count Failed Values":true},{"ID":5925,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":5924,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1026000,"Value":1026000,"Internal":true,"Count Failed Values":true},{"ID":5923,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":1026000,"Executor Run Time":3,"Executor CPU Time":1802000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":194,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":878,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1945\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[877],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":876,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1941\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[875],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":875,"Name":"FileScanRDD","Scope":"{\"id\":\"1941\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":877,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1944\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[876],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532798,"Completion Time":1629344532810,"Accumulables":[{"ID":5924,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1026000,"Internal":true,"Count Failed Values":true},{"ID":5918,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5927,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":5944,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5926,"Name":"internal.metrics.executorCpuTime","Value":1802000,"Internal":true,"Count Failed Values":true},{"ID":5923,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5925,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":5919,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5945,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":194,"Completion Time":1629344532810,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":97,"time":1629344532810}
{"Event":"SparkListenerJobStart","Job ID":195,"Submission Time":1629344532845,"Stage Infos":[{"Stage ID":195,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":883,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1954\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[882],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":882,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1953\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[881],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":879,"Name":"FileScanRDD","Scope":"{\"id\":\"1951\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":880,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1951\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[879],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":881,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1950\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[880],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[195],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1955\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":195,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":883,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1954\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[882],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":882,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1953\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[881],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":879,"Name":"FileScanRDD","Scope":"{\"id\":\"1951\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":880,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1951\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[879],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":881,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1950\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[880],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532846,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1955\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":195,"Stage Attempt ID":0,"Task Info":{"Task ID":195,"Index":0,"Attempt":0,"Launch Time":1629344532849,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":195,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":195,"Index":0,"Attempt":0,"Launch Time":1629344532849,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344532883,"Failed":false,"Killed":false,"Accumulables":[{"ID":5948,"Name":"number of output rows","Update":"3860","Value":"3860","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5952,"Name":"duration total (min, med, max)","Update":"29","Value":"28","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5975,"Name":"internal.metrics.input.recordsRead","Update":3860,"Value":3860,"Internal":true,"Count Failed Values":true},{"ID":5974,"Name":"internal.metrics.input.bytesRead","Update":265067,"Value":265067,"Internal":true,"Count Failed Values":true},{"ID":5957,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":5956,"Name":"internal.metrics.executorCpuTime","Update":28704000,"Value":28704000,"Internal":true,"Count Failed Values":true},{"ID":5955,"Name":"internal.metrics.executorRunTime","Update":30,"Value":30,"Internal":true,"Count Failed Values":true},{"ID":5954,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1235000,"Value":1235000,"Internal":true,"Count Failed Values":true},{"ID":5953,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1235000,"Executor Run Time":30,"Executor CPU Time":28704000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":265067,"Records Read":3860},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":195,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":883,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1954\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[882],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":882,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1953\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[881],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":879,"Name":"FileScanRDD","Scope":"{\"id\":\"1951\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":880,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1951\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[879],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":881,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1950\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[880],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532846,"Completion Time":1629344532883,"Accumulables":[{"ID":5953,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":5974,"Name":"internal.metrics.input.bytesRead","Value":265067,"Internal":true,"Count Failed Values":true},{"ID":5956,"Name":"internal.metrics.executorCpuTime","Value":28704000,"Internal":true,"Count Failed Values":true},{"ID":5952,"Name":"duration total (min, med, max)","Value":"28","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5955,"Name":"internal.metrics.executorRunTime","Value":30,"Internal":true,"Count Failed Values":true},{"ID":5954,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1235000,"Internal":true,"Count Failed Values":true},{"ID":5948,"Name":"number of output rows","Value":"3860","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5975,"Name":"internal.metrics.input.recordsRead","Value":3860,"Internal":true,"Count Failed Values":true},{"ID":5957,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":195,"Completion Time":1629344532883,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":98,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3633, None)) > 0)\n      +- Project [value#3633]\n         +- Relation[value#3633] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3633, None)) > 0)\n      +- Project [value#3633]\n         +- Relation[value#3633] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3633, None)) > 0)\n      +- Relation[value#3633] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3633, None)) > 0)\n   +- *(1) FileScan text [value#3633] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/twice_new.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3633, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3633] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/twice_new.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/twice_new.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":5980,"metricType":"sum"},{"name":"number of files","accumulatorId":5981,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":5982,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":5983,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":5979,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":5978,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344532963}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":98,"accumUpdates":[[5981,1],[5982,0]]}
{"Event":"SparkListenerJobStart","Job ID":196,"Submission Time":1629344532988,"Stage Infos":[{"Stage ID":196,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":887,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1965\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[886],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":886,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1964\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[885],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":884,"Name":"FileScanRDD","Scope":"{\"id\":\"1961\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":885,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1961\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[884],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[196],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"98","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":196,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":887,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1965\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[886],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":886,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1964\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[885],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":884,"Name":"FileScanRDD","Scope":"{\"id\":\"1961\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":885,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1961\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[884],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532988,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"98","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":196,"Stage Attempt ID":0,"Task Info":{"Task ID":196,"Index":0,"Attempt":0,"Launch Time":1629344532991,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":196,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":196,"Index":0,"Attempt":0,"Launch Time":1629344532991,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344532997,"Failed":false,"Killed":false,"Accumulables":[{"ID":5979,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5980,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":6006,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":6005,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":5988,"Name":"internal.metrics.resultSize","Update":1238,"Value":1238,"Internal":true,"Count Failed Values":true},{"ID":5987,"Name":"internal.metrics.executorCpuTime","Update":1322000,"Value":1322000,"Internal":true,"Count Failed Values":true},{"ID":5986,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":5985,"Name":"internal.metrics.executorDeserializeCpuTime","Update":627000,"Value":627000,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":627000,"Executor Run Time":3,"Executor CPU Time":1322000,"Result Size":1238,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":196,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":887,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1965\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[886],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":886,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1964\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[885],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":884,"Name":"FileScanRDD","Scope":"{\"id\":\"1961\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":885,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1961\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[884],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344532988,"Completion Time":1629344532998,"Accumulables":[{"ID":5987,"Name":"internal.metrics.executorCpuTime","Value":1322000,"Internal":true,"Count Failed Values":true},{"ID":5986,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":5980,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":5985,"Name":"internal.metrics.executorDeserializeCpuTime","Value":627000,"Internal":true,"Count Failed Values":true},{"ID":5979,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":6006,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":5988,"Name":"internal.metrics.resultSize","Value":1238,"Internal":true,"Count Failed Values":true},{"ID":6005,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":196,"Completion Time":1629344532998,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":98,"time":1629344532998}
{"Event":"SparkListenerJobStart","Job ID":197,"Submission Time":1629344533030,"Stage Infos":[{"Stage ID":197,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":892,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1974\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[891],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":888,"Name":"FileScanRDD","Scope":"{\"id\":\"1971\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":890,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1970\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[889],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":891,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1973\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[890],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":889,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1971\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[888],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[197],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1975\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":197,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":892,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1974\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[891],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":888,"Name":"FileScanRDD","Scope":"{\"id\":\"1971\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":890,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1970\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[889],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":891,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1973\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[890],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":889,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1971\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[888],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344533031,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1975\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":197,"Stage Attempt ID":0,"Task Info":{"Task ID":197,"Index":0,"Attempt":0,"Launch Time":1629344533033,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":197,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":197,"Index":0,"Attempt":0,"Launch Time":1629344533033,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344533057,"Failed":false,"Killed":false,"Accumulables":[{"ID":6009,"Name":"number of output rows","Update":"2252","Value":"2252","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":6013,"Name":"duration total (min, med, max)","Update":"18","Value":"17","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":6036,"Name":"internal.metrics.input.recordsRead","Update":2252,"Value":2252,"Internal":true,"Count Failed Values":true},{"ID":6035,"Name":"internal.metrics.input.bytesRead","Update":161599,"Value":161599,"Internal":true,"Count Failed Values":true},{"ID":6018,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":6017,"Name":"internal.metrics.executorCpuTime","Update":17909000,"Value":17909000,"Internal":true,"Count Failed Values":true},{"ID":6016,"Name":"internal.metrics.executorRunTime","Update":20,"Value":20,"Internal":true,"Count Failed Values":true},{"ID":6015,"Name":"internal.metrics.executorDeserializeCpuTime","Update":2155000,"Value":2155000,"Internal":true,"Count Failed Values":true},{"ID":6014,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":2155000,"Executor Run Time":20,"Executor CPU Time":17909000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":161599,"Records Read":2252},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":197,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":892,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1974\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[891],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":888,"Name":"FileScanRDD","Scope":"{\"id\":\"1971\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":890,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1970\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[889],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":891,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1973\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[890],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":889,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1971\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[888],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344533031,"Completion Time":1629344533058,"Accumulables":[{"ID":6013,"Name":"duration total (min, med, max)","Value":"17","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":6016,"Name":"internal.metrics.executorRunTime","Value":20,"Internal":true,"Count Failed Values":true},{"ID":6009,"Name":"number of output rows","Value":"2252","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":6036,"Name":"internal.metrics.input.recordsRead","Value":2252,"Internal":true,"Count Failed Values":true},{"ID":6018,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":6015,"Name":"internal.metrics.executorDeserializeCpuTime","Value":2155000,"Internal":true,"Count Failed Values":true},{"ID":6014,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":6035,"Name":"internal.metrics.input.bytesRead","Value":161599,"Internal":true,"Count Failed Values":true},{"ID":6017,"Name":"internal.metrics.executorCpuTime","Value":17909000,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":197,"Completion Time":1629344533058,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":99,"description":"csv at AnalyzeDCApp.scala:91","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3670, None)) > 0)\n      +- Project [value#3670]\n         +- Relation[value#3670] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3670, None)) > 0)\n      +- Project [value#3670]\n         +- Relation[value#3670] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#3670, None)) > 0)\n      +- Relation[value#3670] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#3670, None)) > 0)\n   +- *(1) FileScan text [value#3670] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/hiphop.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen","simpleString":"WholeStageCodegen","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#3670, None)) > 0)","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#3670] Batched: false, Format: Text, Location: InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/hiphop.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/jinju/Documents/study/ss-spark/project/output/20210816/hiphop.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]"},"metrics":[{"name":"number of output rows","accumulatorId":6041,"metricType":"sum"},{"name":"number of files","accumulatorId":6042,"metricType":"sum"},{"name":"metadata time (ms)","accumulatorId":6043,"metricType":"sum"},{"name":"scan time total (min, med, max)","accumulatorId":6044,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":6040,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration total (min, med, max)","accumulatorId":6039,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1629344533141}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":99,"accumUpdates":[[6042,1],[6043,0]]}
{"Event":"SparkListenerJobStart","Job ID":198,"Submission Time":1629344533164,"Stage Infos":[{"Stage ID":198,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":896,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1985\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[895],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":894,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1981\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[893],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":893,"Name":"FileScanRDD","Scope":"{\"id\":\"1981\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":895,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1984\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[894],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[198],"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"99","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":198,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":896,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1985\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[895],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":894,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1981\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[893],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":893,"Name":"FileScanRDD","Scope":"{\"id\":\"1981\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":895,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1984\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[894],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344533164,"Accumulables":[]},"Properties":{"spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.driver.host":"172.30.1.16","spark.eventLog.enabled":"true","spark.driver.port":"65255","spark.app.name":"AnalyzeDC","spark.driver.memory":"1g","spark.executor.id":"driver","spark.master":"local","spark.eventLog.dir":"/Users/jinju/Documents/study/ss-spark/project/analyze_dc/log","spark.sql.execution.id":"99","spark.excutor.memory":"2g","spark.app.id":"local-1629344507389"}}
{"Event":"SparkListenerTaskStart","Stage ID":198,"Stage Attempt ID":0,"Task Info":{"Task ID":198,"Index":0,"Attempt":0,"Launch Time":1629344533167,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":198,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":198,"Index":0,"Attempt":0,"Launch Time":1629344533167,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344533173,"Failed":false,"Killed":false,"Accumulables":[{"ID":6040,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":6041,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":6067,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":6066,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":6049,"Name":"internal.metrics.resultSize","Update":1281,"Value":1281,"Internal":true,"Count Failed Values":true},{"ID":6048,"Name":"internal.metrics.executorCpuTime","Update":1438000,"Value":1438000,"Internal":true,"Count Failed Values":true},{"ID":6047,"Name":"internal.metrics.executorRunTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":6046,"Name":"internal.metrics.executorDeserializeCpuTime","Update":636000,"Value":636000,"Internal":true,"Count Failed Values":true},{"ID":6045,"Name":"internal.metrics.executorDeserializeTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":1,"Executor Deserialize CPU Time":636000,"Executor Run Time":3,"Executor CPU Time":1438000,"Result Size":1281,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":198,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":896,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1985\",\"name\":\"map\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[895],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":894,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1981\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[893],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":893,"Name":"FileScanRDD","Scope":"{\"id\":\"1981\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":895,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1984\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[894],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344533164,"Completion Time":1629344533173,"Accumulables":[{"ID":6046,"Name":"internal.metrics.executorDeserializeCpuTime","Value":636000,"Internal":true,"Count Failed Values":true},{"ID":6040,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":6067,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":6049,"Name":"internal.metrics.resultSize","Value":1281,"Internal":true,"Count Failed Values":true},{"ID":6045,"Name":"internal.metrics.executorDeserializeTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":6066,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":6048,"Name":"internal.metrics.executorCpuTime","Value":1438000,"Internal":true,"Count Failed Values":true},{"ID":6041,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":6047,"Name":"internal.metrics.executorRunTime","Value":3,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":198,"Completion Time":1629344533173,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":99,"time":1629344533173}
{"Event":"SparkListenerJobStart","Job ID":199,"Submission Time":1629344533201,"Stage Infos":[{"Stage ID":199,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":901,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1994\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[900],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":899,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1990\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[898],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":897,"Name":"FileScanRDD","Scope":"{\"id\":\"1991\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":900,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1993\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[899],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":898,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1991\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[897],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Accumulables":[]}],"Stage IDs":[199],"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1995\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":199,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":901,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1994\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[900],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":899,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1990\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[898],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":897,"Name":"FileScanRDD","Scope":"{\"id\":\"1991\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":900,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1993\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[899],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":898,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1991\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[897],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344533201,"Accumulables":[]},"Properties":{"spark.rdd.scope.noOverride":"true","spark.rdd.scope":"{\"id\":\"1995\",\"name\":\"aggregate\"}"}}
{"Event":"SparkListenerTaskStart","Stage ID":199,"Stage Attempt ID":0,"Task Info":{"Task ID":199,"Index":0,"Attempt":0,"Launch Time":1629344533204,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":199,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":199,"Index":0,"Attempt":0,"Launch Time":1629344533204,"Executor ID":"driver","Host":"localhost","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1629344533248,"Failed":false,"Killed":false,"Accumulables":[{"ID":6070,"Name":"number of output rows","Update":"5907","Value":"5907","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":6074,"Name":"duration total (min, med, max)","Update":"39","Value":"38","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":6097,"Name":"internal.metrics.input.recordsRead","Update":5907,"Value":5907,"Internal":true,"Count Failed Values":true},{"ID":6096,"Name":"internal.metrics.input.bytesRead","Update":429806,"Value":429806,"Internal":true,"Count Failed Values":true},{"ID":6079,"Name":"internal.metrics.resultSize","Update":1528,"Value":1528,"Internal":true,"Count Failed Values":true},{"ID":6078,"Name":"internal.metrics.executorCpuTime","Update":38527000,"Value":38527000,"Internal":true,"Count Failed Values":true},{"ID":6077,"Name":"internal.metrics.executorRunTime","Update":40,"Value":40,"Internal":true,"Count Failed Values":true},{"ID":6076,"Name":"internal.metrics.executorDeserializeCpuTime","Update":1117000,"Value":1117000,"Internal":true,"Count Failed Values":true},{"ID":6075,"Name":"internal.metrics.executorDeserializeTime","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Metrics":{"Executor Deserialize Time":2,"Executor Deserialize CPU Time":1117000,"Executor Run Time":40,"Executor CPU Time":38527000,"Result Size":1528,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":429806,"Records Read":5907},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":199,"Stage Attempt ID":0,"Stage Name":"csv at AnalyzeDCApp.scala:91","Number of Tasks":1,"RDD Info":[{"RDD ID":901,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1994\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[900],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":899,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1990\",\"name\":\"DeserializeToObject\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[898],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":897,"Name":"FileScanRDD","Scope":"{\"id\":\"1991\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":900,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1993\",\"name\":\"mapPartitions\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[899],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":898,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1991\",\"name\":\"WholeStageCodegen\"}","Callsite":"csv at AnalyzeDCApp.scala:91","Parent IDs":[897],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:467)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:91)\nAnalyzeDCApp$$anonfun$makeGalTitlesOverPeriodDF$1.apply(AnalyzeDCApp.scala:85)\nscala.collection.immutable.List.foreach(List.scala:392)\nAnalyzeDCApp$.makeGalTitlesOverPeriodDF(AnalyzeDCApp.scala:85)\nAnalyzeDCApp$.startAnalyze(AnalyzeDCApp.scala:236)\nAnalyzeDCApp$.main(AnalyzeDCApp.scala:259)\nAnalyzeDCApp.main(AnalyzeDCApp.scala)","Submission Time":1629344533201,"Completion Time":1629344533248,"Accumulables":[{"ID":6097,"Name":"internal.metrics.input.recordsRead","Value":5907,"Internal":true,"Count Failed Values":true},{"ID":6079,"Name":"internal.metrics.resultSize","Value":1528,"Internal":true,"Count Failed Values":true},{"ID":6076,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1117000,"Internal":true,"Count Failed Values":true},{"ID":6070,"Name":"number of output rows","Value":"5907","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":6096,"Name":"internal.metrics.input.bytesRead","Value":429806,"Internal":true,"Count Failed Values":true},{"ID":6078,"Name":"internal.metrics.executorCpuTime","Value":38527000,"Internal":true,"Count Failed Values":true},{"ID":6075,"Name":"internal.metrics.executorDeserializeTime","Value":2,"Internal":true,"Count Failed Values":true},{"ID":6074,"Name":"duration total (min, med, max)","Value":"38","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":6077,"Name":"internal.metrics.executorRunTime","Value":40,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":199,"Completion Time":1629344533248,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerApplicationEnd","Timestamp":1629344533370}
